{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"2023_Kronensicherung_Plesse_001_Versuchsablauf\"\n",
    "author: \"Kyell Jensen\"\n",
    "date: \"2024-08-06\"\n",
    "format: pdf\n",
    "editor: visual\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2023_Kronensicherung_Plesse_Kraefte_Schwingungen\n",
    "## Baumdaten, Gerädeanordung und Versuchsaufzeichung\n",
    "\n",
    "Nutze eine geeignete Python 3.11 Umgebung (z. B. virtuelle Environment) und installiere die Pakete linescale3 (LS3) und treeqinetic (PTQ) inklusive kj_core und kj_logger und weiteren requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Arbeitsumgebung vorbereiten\n",
    "\n",
    "Es werden zuerst benötigte Standard-Pakete importiert. Nachfolgend die zwei extra geschriebenen Pakete LS3 und PTQ. Fehler beim Import dieser zwei Pakete sind ggf. Bugs. Beide Pakete nutzen eine gemeinsame CodeBasis in den Paketen kj_core (Core-Package) und kj_logger (individualisiertes Logging des Verarbeitungs-Prozesses). Diese sollte i. d. R. über die requirements mit installiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### IMPORT: Importieren von Standardbibliotheken\n",
    "\n",
    "Die folgenden Bibliotheken werden importiert, um grundlegende Funktionen für Strukturierung, Datenverarbeitung, Plotting und statistische Auswertung bereit zu stellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:39.502030200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Struktur\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "# Datenverarbeitung\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from slugify import slugify  # Slugify ums strings in standard Formate zu überführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:34.379448500Z",
     "start_time": "2025-03-26T09:00:32.936922Z"
    }
   },
   "source": [
    "Lade allgemeine Export-Funktionen, um die Daten als Latex-Tabellen zu exportieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from kj_core.utils.latex_export import (\n",
    "    save_latex_table,\n",
    "    build_data_dict_df\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:39.524201100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORT: Importieren von eigenen Modulen\n",
    "\n",
    "Lege Pfade für Daten-Importe, Daten-Exporte etc. fest (ggf. anpassen an eigene Verzeichnisstruktur), ausgelagert in gemeinsame Config für verschiedene Notebooks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Importiere alle Einstellungen aus der project_config.py\n",
    "from project_config import (\n",
    "    analyse_name,\n",
    "    data_path,\n",
    "    working_directory,\n",
    "    data_export_directory,\n",
    "    latex_export_directory\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:39.987718900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vorbemerkung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Daten wurden während des Versuchs als GoogleSheet erfasst und abschließend als CSV-Dateien exportiert, um ein einfaches Einlesen zur ermöglichen.\n",
    "Nachfolgend werden Datentypen für alle Spalten explizit in den *_data_dict.json angegeben, da es teils durch Python-Pandas zu Fehlerkennungen kommt.\n",
    "Zusätzlich werden teils Spaltennamen vereinheitlicht oder benannt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Daten des Versuchsbaums (tree_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:56:04.307311Z",
     "start_time": "2025-03-26T08:56:03.209060Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORT: Daten und Datendokumentation\n",
    "\n",
    "Die `tree.csv` liefert spezifische Informationen über den Versuchsbaum. Da nur ein Versuchsbaum, sind hier Daten und Datendokumentation in einer Datei."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tree_df = pd.read_csv(\n",
    "    data_path / 'tree.csv',\n",
    "    sep=';', decimal=',',\n",
    "    na_values='NA',\n",
    "    dtype='string'  # alle Spalten als string\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:39.994995100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ANALYSE: Explorative Datenanalyse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#tree_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.016410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|    | Variable            | Kategorie   | Zeichen                | Deutsch                        | Datentyp   | Einheit   | Beschreibung                        | Wert            |\n|----|---------------------|-------------|------------------------|--------------------------------|------------|-----------|-------------------------------------|-----------------|\n|  0 | baumart             | tree        | Baumart                | Baumart                        | string     | -         | Art des Baumes                      | Fagus silvatica |\n|  1 | belaubung           | tree        | Belaubung              | Belaubung                      | string     | -         | Belaubungszustand zur Messung       | unbelaubt       |\n|  2 | vitalitaet          | tree        | Vitalitaet             | Vitalität nach A. Roloff       | Int64      | Stufe     | Vitalitätsstufe nach Andreas Roloff | 1               |\n|  3 | h_st_a              | tree        | $h_{\\mathrm{StA}}$     | Höhe Stämmling A               | float64    | m         | Gesamthöhe des Stämmlings A         | 26.15           |\n|  4 | h_st_b              | tree        | $h_{\\mathrm{StB}}$     | Höhe Stämmling B               | float64    | m         | Gesamthöhe des Stämmlings B         | 27.20           |\n|  5 | u_1m                | tree        | $u_{1\\,\\mathrm{m}}$    | Umfang auf 1~m                 | float64    | cm        | Stammumfang auf 1~m Höhe            | 140.00          |\n|  6 | h_zwiesel           | tree        | $h_{\\mathrm{Zwiesel}}$ | Höhe Zwiesel                   | float64    | m         | Höhe des Zwiesels über Boden        | 10.31           |\n|  7 | h_ks                | tree        | $h_{\\mathrm{KS}}$      | Höhe Kronensicherung           | float64    | m         | Höhe der KS-Anbringung über Boden   | 17.40           |\n|  8 | l_ks                | tree        | $l_{\\mathrm{KS}}$      | Länge Kronensicherung          | float64    | cm        | Länge der eingebauten KS            | 135.00          |\n|  9 | u_st_a_h_ks         | tree        | $u_{\\mathrm{StA,KS}}$  | Umfang Stämmling A auf Höhe KS | float64    | cm        | Stammumfang von A auf Höhe der KS   | 58.00           |\n| 10 | u_st_b_h_ks         | tree        | $u_{\\mathrm{StB,KS}}$  | Umfang Stämmling B auf Höhe KS | float64    | cm        | Stammumfang von B auf Höhe der KS   | 48.00           |\n| 11 | standort_h_nn       | tree        | $h_{\\mathrm{NN}}$      | Standort Höhe über n. N.       | float64    | m         | Standorthöhe über Normalnull        | 352.00          |\n| 12 | standort_geo_breite | tree        | $\\varphi$              | Standort Geo. Breite           | float64    | Grad      | Geografische Breite des Standorts   | 51.589476       |\n| 13 | standort_geo_laenge | tree        | $\\lambda$              | Standort Geo. Länge            | float64    | Grad      | Geografische Länge des Standorts    | 9.985242        |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In Markdown umwandeln und anzeigen\n",
    "md_text = tree_df.to_markdown(tablefmt=\"github\")\n",
    "display(Markdown(md_text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.016410Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EXPORT: Daten exportieren für Weiterverarbeitung (.feather, .csv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:34.780202300Z",
     "start_time": "2025-03-26T09:00:33.131722200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# DataFrame als Feather\n",
    "tree_df.to_feather(data_export_directory / \"tree.feather\")\n",
    "tree_df.to_csv(data_export_directory / \"tree.csv\", sep=\";\", index=False, encoding=\"utf-8\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.037591800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LATEX-EXPORT: Daten und Datendokumentation als Latex-Tabelle exportieren (.tex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content saved to: C:\\kyellsen\\005_Projekte\\2024_BA\\032_Feldversuch_2023_Plesse\\030_Analysen\\2023_Kronensicherung_Plesse_Kraefte_Schwingungen\\working_directory\\export_latex\\feldversuch_2_daten_des_versuchsbaums.tex\n"
     ]
    }
   ],
   "source": [
    "select_data_fields = [\"Zeichen\", \"Deutsch\", \"Wert\", \"Datentyp\", \"Einheit\"]\n",
    "tree_df_latex = tree_df[select_data_fields].copy()\n",
    "\n",
    "latex_string = tree_df_latex.to_latex(index=False, escape=False, column_format=\"llrrr\",\n",
    "                                      float_format=\"{:0.2f}\".format)\n",
    "caption = \"Feldversuch 2 - Daten des Versuchsbaums\"\n",
    "\n",
    "save_latex_table(latex_string, caption, latex_export_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.066370900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Daten der Geräteanordnung am Baum (sensor_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORT: Daten und Datendokumentation\n",
    "\n",
    "Die Datendokumentation ergibt sich aus `sensor_position_data_dict.json`.\n",
    "\n",
    "Die `sensor_position.csv` enthält detaillierte Informationen zur Anordnung der Sensoren an den Bäumen im Rahmen des Experiments. Jede Zeile beschreibt die Platzierung eines Sensors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Lade das Dictionary mit der Daten Dokumentation\n",
    "with open(data_path/ \"sensor_position_data_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sensor_data_dict = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.223875100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Erzeuge dtype_dict dynamisch aus dem der Daten Dokumentation\n",
    "dtype_dict = {key: value[\"Datentyp\"] for key, value in sensor_data_dict.items()\n",
    "    if value[\"Datentyp\"] not in [None, \"\"]\n",
    "}\n",
    "\n",
    "# CSV einlesen mit dynamischen Datentypen\n",
    "sensor_file = data_path / 'sensor_position.csv'\n",
    "sensor_df = pd.read_csv(sensor_file, sep=';', decimal=',', na_values='NA',dtype=dtype_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.249417900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ANALYSE: Explorative Datenanalyse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T09:10:25.653588300Z",
     "start_time": "2025-03-26T09:10:24.461482200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|    | Variable      | Kategorie       | Zeichen       | Deutsch     | Datentyp   | Einheit   | Beschreibung                             |\n|----|---------------|-----------------|---------------|-------------|------------|-----------|------------------------------------------|\n|  0 | location      | sensor_position | location      | Position    | string     | -         | Position des Sensors am Stamm            |\n|  1 | height        | sensor_position | $h$           | Höhe        | Float64    | m         | Höhe des Sensors am Stamm                |\n|  2 | diameter      | sensor_position | $d$           | Durchmesser | Float64    | cm        | Durchmesser des Stammes                  |\n|  3 | direction     | sensor_position | direction     | Richtung    | string     | -         | Zug- oder Druckseite                     |\n|  4 | type          | sensor_position | type          | Typ         | category   | -         | Typ des Sensors                          |\n|  5 | sensor_id     | sensor_position | sensor\\_id    | Sensor ID   | category   | -         | ID des Sensors                           |\n|  6 | circumference | sensor_position | $u$           | Umfang      | Float64    | m         | Umfang des Stammes am Sensor             |\n|  7 | position_id   | sensor_position | $position_\\id | Position ID | Int64      | -         | Eindeutige ID für Sensorposition am Baum |\n|  8 | note          | sensor_position | note          | Anmerkung   | string     | -         | Anmerkung zur Sensorposition             |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In DataFrame umwandeln\n",
    "sensor_data_dict_df = build_data_dict_df(sensor_data_dict)\n",
    "\n",
    "# In Markdown umwandeln und anzeigen\n",
    "md_text = sensor_data_dict_df.to_markdown(tablefmt=\"github\")\n",
    "display(Markdown(md_text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.275976800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   position_id  type sensor_id location  height  circumference direction  \\\n0            1   LS3  14:BF:E6     rope    18.3           <NA>      <NA>   \n1            2   LS3  14:99:1E    cable    17.4           <NA>      <NA>   \n2            3  TMS1       015      StA    18.0           0.45      west   \n3            4  TMS1       014      StB    18.0            0.4      west   \n4            5  TMS1       013      StA    15.0           0.67      west   \n\n   note  diameter  \n0  <NA>      <NA>  \n1  <NA>      <NA>  \n2  <NA>  0.143239  \n3  <NA>  0.127324  \n4  <NA>  0.213268  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>position_id</th>\n      <th>type</th>\n      <th>sensor_id</th>\n      <th>location</th>\n      <th>height</th>\n      <th>circumference</th>\n      <th>direction</th>\n      <th>note</th>\n      <th>diameter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>LS3</td>\n      <td>14:BF:E6</td>\n      <td>rope</td>\n      <td>18.3</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>LS3</td>\n      <td>14:99:1E</td>\n      <td>cable</td>\n      <td>17.4</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>TMS1</td>\n      <td>015</td>\n      <td>StA</td>\n      <td>18.0</td>\n      <td>0.45</td>\n      <td>west</td>\n      <td>&lt;NA&gt;</td>\n      <td>0.143239</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>TMS1</td>\n      <td>014</td>\n      <td>StB</td>\n      <td>18.0</td>\n      <td>0.4</td>\n      <td>west</td>\n      <td>&lt;NA&gt;</td>\n      <td>0.127324</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>TMS1</td>\n      <td>013</td>\n      <td>StA</td>\n      <td>15.0</td>\n      <td>0.67</td>\n      <td>west</td>\n      <td>&lt;NA&gt;</td>\n      <td>0.213268</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_df[\"height\"] = sensor_df[\"height\"] / 100\n",
    "sensor_df[\"circumference\"] = sensor_df[\"circumference\"] / 100\n",
    "sensor_df[\"diameter\"] = sensor_df[\"circumference\"] / np.pi\n",
    "\n",
    "sensor_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.290543800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EXPORT: Daten exportieren für Weiterverarbeitung (.feather, .csv, .json)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# DataFrame als Feather\n",
    "sensor_df.to_feather(data_export_directory / \"sensor.feather\")\n",
    "sensor_df.to_csv(data_export_directory / \"sensor.csv\", sep=\";\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Dict als JSON (UTF-8, sauber eingerückt)\n",
    "with open(data_export_directory / \"sensor_data_dict.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sensor_data_dict, f,  indent=4, ensure_ascii=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.322666600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LATEX-EXPORT: Daten und Datendokumentation als Latex-Tabelle exportieren (.tex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "sensor_select_variables = [\"type\", \"sensor_id\", \"location\", \"direction\", \"height\", \"circumference\", \"diameter\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.339783700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content saved to: C:\\kyellsen\\005_Projekte\\2024_BA\\032_Feldversuch_2023_Plesse\\030_Analysen\\2023_Kronensicherung_Plesse_Kraefte_Schwingungen\\working_directory\\export_latex\\feldversuch_2_gerateanordnung.tex\n"
     ]
    }
   ],
   "source": [
    "sensor_df_latex = sensor_df.copy()[sensor_select_variables]\n",
    "\n",
    "# Ersetze Spaltennamen durch Formelzeichen\n",
    "sensor_df_latex.columns = [sensor_data_dict[col][\"Zeichen\"] for col in sensor_select_variables]\n",
    "\n",
    "latex_string = sensor_df_latex.to_latex(index=False, escape=False, column_format=\"lllrrrr\",\n",
    "    float_format=\"{:0.2f}\".format)\n",
    "\n",
    "caption = \"Feldversuch 2 - Geräteanordnung\"\n",
    "save_latex_table(latex_string, caption, latex_export_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.339783700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content saved to: C:\\kyellsen\\005_Projekte\\2024_BA\\032_Feldversuch_2023_Plesse\\030_Analysen\\2023_Kronensicherung_Plesse_Kraefte_Schwingungen\\working_directory\\export_latex\\feldversuch_2_gerateanordnung_daten_dokumentation.tex\n"
     ]
    }
   ],
   "source": [
    "sensor_data_dict_df = build_data_dict_df(sensor_data_dict, keys=sensor_select_variables, escape_index=True, select_latex_fields=True)\n",
    "latex_string = sensor_data_dict_df.to_latex(index=False, escape=False)\n",
    "caption = \"Feldversuch 2 - Geräteanordnung Daten Dokumentation\"\n",
    "\n",
    "save_latex_table(latex_string, caption, latex_export_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.352233900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Daten des Versuchsablaufs (series_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORT: Daten und Datendokumentation\n",
    "\n",
    "Die Datendokumentation ergibt sich aus `series_data_dict.json`.\n",
    "\n",
    "Die `series.csv` enthält das Protokoll des Versuchsablaufes der einzelnen Messungen. Jede Zeile repräsentiert eine einzelne Messung. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Lade das Dictionary mit der Daten Dokumentation\n",
    "with open(data_path/ \"series_data_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    series_data_dict = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.364006Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Erzeuge dtype_dict dynamisch aus dem der Daten Dokumentation\n",
    "dtype_dict = {key: value[\"Datentyp\"] for key, value in series_data_dict.items()\n",
    "    if value[\"Datentyp\"] not in [None, \"\"]\n",
    "}\n",
    "\n",
    "# CSV einlesen mit dynamischen Datentypen\n",
    "series_file = data_path / 'series.csv'\n",
    "series_df = pd.read_csv(series_file, sep=';', decimal=',', na_values='NA', dtype=dtype_dict)\n",
    "\n",
    "# Zeitspalte in Uhrzeit umwandeln\n",
    "series_df[\"time\"] = pd.to_datetime(series_df[\"time\"], format=\"%H:%M:%S\").dt.time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.382667500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Behandlungskategorien sortiert definieren\n",
    "treatment_order = ['free', 'gefa_dynamic', 'cobra_static', 'cobra_static_slack']\n",
    "treatment_category = CategoricalDtype(categories=treatment_order, ordered=True)\n",
    "series_df[\"treatment\"] = series_df[\"treatment\"].astype(treatment_category)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.406081700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ANALYSE: Explorative Datenanalyse\n",
    "\n",
    "Behandlungsvariante/Kronensicherung Kategorien:\n",
    "\n",
    "- **`free`**: Der Baum konnte frei ohne Kronensicherung nach dem Release ausschwingen.\n",
    "  \n",
    "- **`gefa_dynamic`**: In ca. 2/3 der Baumhöhe wurde ein dynamisches Gefa Gurtband 4t dynamisch nach ZTV-Baumpflege mit leichtem Durchhang installiert. Das Ausschwingen wurde durch die KS abgedämpft. Da die Sicherung ohne Vorspannung installiert wurde, zeigen die Plots (/ls3/plots/force_vs_time_1/) von '14:99:1E' sowohl am Anfang als auch am Ende ca. 0 kN Kraft an (LogNr 1 bis 9).\n",
    "\n",
    "- **`cobra_static`**: In ca. 2/3 der Baumhöhe wurde eine statische Cobra ultrastatic 7t (Dyneema) Sicherung installiert. Die Vorspannung betrug ca. 0,4 kN, wie sich in den Plots (/ls3/plots/force_vs_time_1/) von '14:99:1E' gut erkennen lässt. Durch das Zusammenziehen der Stämmlinge ist die Kronensicherung vor dem Release vollständig lastfrei (0 kN). Nach dem Release pendelt sich die Kraft ca. bei 0,4 kN ein (LogNr 10-18).\n",
    "\n",
    "- **`cobra_static_slack`**: Ähnlich der `cobra_static`, jedoch wurde die Vorspannung entfernt. Aufgrund von Regen wurde nur eine Messung durchgeführt und die Serie frühzeitig abgebrochen.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|    | Variable             | Kategorie   | Zeichen                               | Deutsch            | Datentyp   | Einheit   | Beschreibung                                                              |\n|----|----------------------|-------------|---------------------------------------|--------------------|------------|-----------|---------------------------------------------------------------------------|\n|  0 | treatment            | series      | treatment                             | Behandlung         | category   | -         | Art der KS: \\texttt{free}, \\texttt{gefa\\_dynamic}, \\texttt{cobra\\_static} |\n|  1 | release_force_target | series      | $F_{\\mathrm{release,target}}$         | Vorspannkraft-Soll | float64    | kN        | Geplante Vorspannkraft im Zugseil bei Release                             |\n|  2 | id                   | series      | id                                    | ID Messung         | Int64      | -         | ID der Messung / Beobachtung                                              |\n|  3 | time                 | series      | $t$                                   | Zeit               | string     | Zeit      | ca. Uhrzeit Beginn                                                        |\n|  4 | 14:BF:E6             | series      | $\\mathrm{LogNr\\ LS3}_{\\mathrm{Seil}}$ | LogNr. LS3 Zugseil | Int64      | -         | LogNr. LineScale3 im Zugseil                                              |\n|  5 | 14:99:1E             | series      | $\\mathrm{LogNr\\ LS3}_{\\mathrm{KS}}$   | LogNr. LS3 KS      | Int64      | -         | LogNr. LineScale3 in KS                                                   |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In DataFrame umwandeln\n",
    "series_data_dict_df = build_data_dict_df(series_data_dict)\n",
    "\n",
    "# In Markdown umwandeln und anzeigen\n",
    "md_text = series_data_dict_df.to_markdown(tablefmt=\"github\")\n",
    "display(Markdown(md_text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.406081700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "   id      time  release_force_target treatment  14:BF:E6  14:99:1E\n0   1  10:10:00                   2.5      free         1      <NA>\n1   2  10:20:00                   2.8      free         2      <NA>\n2   3  10:28:00                   2.8      free         3      <NA>\n3   4  10:47:00                   2.8      free         4      <NA>\n4   5  10:53:00                   2.4      free         5      <NA>",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>time</th>\n      <th>release_force_target</th>\n      <th>treatment</th>\n      <th>14:BF:E6</th>\n      <th>14:99:1E</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>10:10:00</td>\n      <td>2.5</td>\n      <td>free</td>\n      <td>1</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>10:20:00</td>\n      <td>2.8</td>\n      <td>free</td>\n      <td>2</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>10:28:00</td>\n      <td>2.8</td>\n      <td>free</td>\n      <td>3</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>10:47:00</td>\n      <td>2.8</td>\n      <td>free</td>\n      <td>4</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>10:53:00</td>\n      <td>2.4</td>\n      <td>free</td>\n      <td>5</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.415285600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EXPORT: Daten exportieren für Weiterverarbeitung (.feather, .csv, .json)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# DataFrame als Feather\n",
    "series_df.to_feather(data_export_directory / \"series.feather\")\n",
    "series_df.to_csv(data_export_directory / \"series.csv\", sep=\";\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Dict als JSON (UTF-8, sauber eingerückt)\n",
    "with open(data_export_directory / \"series_data_dict.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(series_data_dict, f,  indent=4, ensure_ascii=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.426874900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LATEX-EXPORT: Daten und Datendokumentation als Latex-Tabelle exportieren (.tex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "series_select_variables = [\"id\", \"time\", \"release_force_target\", \"treatment\", \"14:BF:E6\", \"14:99:1E\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.625975100Z",
     "start_time": "2025-04-21T10:39:40.443442800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content saved to: C:\\kyellsen\\005_Projekte\\2024_BA\\032_Feldversuch_2023_Plesse\\030_Analysen\\2023_Kronensicherung_Plesse_Kraefte_Schwingungen\\working_directory\\export_latex\\feldversuch_2_versuchsablauf.tex\n"
     ]
    }
   ],
   "source": [
    "series_df_latex = series_df.copy()[series_select_variables]\n",
    "\n",
    "# Ersetze Spaltennamen durch Formelzeichen\n",
    "series_df_latex.columns = [series_data_dict[col][\"Zeichen\"] for col in series_select_variables]\n",
    "\n",
    "series_df_latex[\"treatment\"] = series_df_latex[\"treatment\"].apply(\n",
    "    lambda x: \"\\\\texttt{\" + str(x).replace(\"_\", \"\\\\_\") + \"}\"\n",
    ")\n",
    "\n",
    "latex_string = series_df_latex.to_latex(index=False, escape=False, column_format=\"llrlrr\",\n",
    "                                        float_format=\"{:0.2f}\".format)\n",
    "\n",
    "caption = \"Feldversuch 2 - Versuchsablauf\"\n",
    "caption_long = \"Feldversuch 2 - Versuchsablauf\"\n",
    "\n",
    "save_latex_table(latex_string, caption, latex_export_directory, caption_long=caption_long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.657752700Z",
     "start_time": "2025-04-21T10:39:40.443442800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content saved to: C:\\kyellsen\\005_Projekte\\2024_BA\\032_Feldversuch_2023_Plesse\\030_Analysen\\2023_Kronensicherung_Plesse_Kraefte_Schwingungen\\working_directory\\export_latex\\feldversuch_2_versuchsablauf_daten_dokumentation.tex\n"
     ]
    }
   ],
   "source": [
    "series_data_dict_df = build_data_dict_df(series_data_dict, keys=series_select_variables, escape_index=True, select_latex_fields=True)\n",
    "\n",
    "latex_string = series_data_dict_df.to_latex(index=False, escape=False)\n",
    "caption = \"Feldversuch 2 - Versuchsablauf Daten Dokumentation\"\n",
    "\n",
    "save_latex_table(latex_string, caption, latex_export_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.657752700Z",
     "start_time": "2025-04-21T10:39:40.458696100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CUT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined: Latex-Export von Daten für Anhang"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def generate_grouped_latex_tables(df_latex: pd.DataFrame, caption: str, column_format: str, group_by: str, latex_export_directory: Path) -> None:\n",
    "    \"\"\"\n",
    "    Generate grouped LaTeX tables for each unique value in a specified column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df_latex (pd.DataFrame): The DataFrame with already formatted columns.\n",
    "        caption (str): The caption for the LaTeX tables.\n",
    "        column_format (str): The format for the LaTeX tables.\n",
    "        group_by (str): The column name to group by.\n",
    "        latex_export_directory (Path): The directory to save the LaTeX tables.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # DataFrame grouped by specified column\n",
    "        grouped = df_latex.groupby(group_by, observed=True)\n",
    "\n",
    "        # LaTeX tables to be combined in a single file\n",
    "        combined_tables = []\n",
    "\n",
    "        for group, group_df in grouped:\n",
    "            # Drop the group_by column\n",
    "            group_df = group_df.drop(columns=[group_by])\n",
    "\n",
    "            # Format 'id' column as string if it exists\n",
    "            if 'id' in group_df.columns:\n",
    "                group_df['id'] = group_df['id'].astype(str)\n",
    "\n",
    "            # Calculate statistics\n",
    "            mean_row = group_df.mean(numeric_only=True).rename('Mean')\n",
    "            median_row = group_df.median(numeric_only=True).rename('Median')\n",
    "            sd_row = group_df.std(numeric_only=True).rename('SD')\n",
    "\n",
    "            # Combine stats with original DataFrame\n",
    "            stats_df = pd.concat([group_df, mean_row.to_frame().T, median_row.to_frame().T, sd_row.to_frame().T])\n",
    "\n",
    "            # Generate LaTeX string from DataFrame\n",
    "            df_latex_string = stats_df.to_latex(\n",
    "                index=True,\n",
    "                escape=False,\n",
    "                column_format=column_format,\n",
    "                float_format=\"{:0.2f}\".format\n",
    "            )\n",
    "\n",
    "            # Create caption and label for the group\n",
    "            caption_text = create_caption(caption, f\"{caption} für {slugify(group, separator=' ')}\")\n",
    "            label_clean = create_label(caption=caption, additional_label=group)\n",
    "\n",
    "            # Generate LaTeX table\n",
    "            latex_table = generate_latex_table(df_latex_string, caption_text, label_clean)\n",
    "\n",
    "            combined_tables.append(latex_table)\n",
    "\n",
    "        # Combine all tables and save to a single file\n",
    "        if combined_tables:\n",
    "            final_output = \"\\n\\n\".join(combined_tables)\n",
    "            file_name = create_label(caption) + \".tex\"\n",
    "            save_to_file(final_output, latex_export_directory / file_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating grouped LaTeX tables: {e}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:40.657752700Z",
     "start_time": "2025-04-21T10:39:40.470501600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m variables \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtreatment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msensor_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocation\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheight\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiameter\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrope_release\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_strain\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcalc_max_strain\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrain_difference\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# DataFrame kopieren und die gewünschten Spalten auswählen\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m df_latex \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mcopy()[variables]\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\u001B[39;00m\n\u001B[0;32m      8\u001B[0m df_latex \u001B[38;5;241m=\u001B[39m df_latex\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{var: data_dict[var][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mZeichen\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m var \u001B[38;5;129;01min\u001B[39;00m variables})\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Liste der benötigten Variablen\n",
    "variables = [\"id\", \"treatment\", \"sensor_name\", \"location\", \"height\", \"diameter\", \"rope_release\", \"max_strain\", \"calc_max_strain\", \"strain_difference\"]\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Vergleich gemessene und rechnerische Faserdehnung\",\n",
    "    column_format=\"lll|lrrr|rrr\",\n",
    "    group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:41.206849200Z",
     "start_time": "2025-04-21T10:39:40.481253500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variables = ['id', 'sensor_name', 'treatment', 'release_force_target', 'rope_release', 'cable_max', 'max_strain', 'max_compression',]\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Kräfte und Dehnungen\",\n",
    "    column_format=\"lrl|rrr|rr\",\n",
    "        group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.142489200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variables_2 = ['id', 'sensor_name', 'treatment', 'm_amplitude', 'm_amplitude_2', 'initial_amplitude', 'damping_coeff', 'damping_ratio', 'frequency_damped', 'frequency_undamped', 'y_shift', 'pearson_r', 'nmae']\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables_2]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables_2})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Schwingungsparameter\",\n",
    "    column_format=\"lrl|rrr|rr|rr|r|rr\",\n",
    "    group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.163416600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PTQ: Analyse der Schwingungsparameter\n",
    "\n",
    "In diesem Abschnitt werden die Schwingungsparameter statistisch ausgewertet. Ziel ist es, den Einfluss verschiedener Behandlungsvarianten (treatment) auf die gemessenen Schwingungsparameter zu untersuchen und dabei auch den potenziellen Einfluss der Vorspannung (rope_release) und Sensorposition (sensor_name) zu berücksichtigen.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'm_amplitude', \n",
    "    'm_amplitude_2',\n",
    "    'max_strain',\n",
    "    'max_compression',\n",
    "    'initial_amplitude',\n",
    "    'damping_coeff', \n",
    "    'damping_ratio', \n",
    "    'frequency_damped', \n",
    "    'frequency_undamped',\n",
    "    'pearson_r',\n",
    "    #'nrmse', \n",
    "    'nmae'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.169409400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Systematischer Einfluss der Sensorposition\n",
    "\n",
    "Ziel: Visuell erkennen, ob unterschiedliche Sensoren konsistent andere Werte liefern und ob dieser Effekt die Interpretation der treatment-Effekte erschwert."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "for var in variables:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"sensor_name\", y=var, data=df, hue=\"treatment\", palette=treatment_color_dict,  dodge=True)\n",
    "    # Stripplot: Punkte zur Veranschaulichung der Verteilung\n",
    "    sns.stripplot(x=\"sensor_name\", y=var, data=df, hue=\"treatment\", palette=treatment_color_dict, dodge=True, alpha=1, jitter=True, size=5, legend=False)\n",
    "    # Titel und Achsentitel setzen\n",
    "    plt.title(f\"Einfluss von treatment auf {var} gruppiert über sensor_name\")\n",
    "    plt.xlabel(\"Sensor Name\")\n",
    "    plt.ylabel(var)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_sensor_treatment_{var}\", subdir=\"combined/sensor\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.175068400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Systematischer Einfluss der Behandlungsvariante\n",
    "\n",
    "Ziel: Feststellen, ob die Variation durch unterschiedliche Behandlungen relativ zur sensorbedingten Variation unterscheidbar ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "for var in variables:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"treatment\", y=var, data=df, palette=sensor_color_dict, hue='sensor_name')\n",
    "    sns.stripplot(x=\"treatment\", y=var, data=df, palette=sensor_color_dict, hue='sensor_name', dodge=True, alpha=1, jitter=True, size=5, legend=False)\n",
    "    plt.title(f\"Einfluss von sensor_name auf {var} gruppiert über treatment\")\n",
    "    plt.xlabel(\"treatment\")\n",
    "    plt.ylabel(var)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_treatment_sensor_{var}\", subdir=\"combined/treatment\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.180058400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Versuche Mixed-Linear Model\n",
    "Die Daten sind hierarchisch: Mehrere Messungen (vier Sensoren) pro Beobachtungseinheit (`id`). Ein Mixed-Effects Modell könnte diese Struktur abbilden, indem zufällige Effekte für `id` und feste Effekte für `treatment` sowie `sensor_name` genutzt werden. Zusätzlich könnte `rope_release` als Kovariate eingeführt werden.\n",
    "\n",
    "Diese Modelle wären theoretisch präziser, aber aufgrund der geringen Stichprobengröße und der komplexen Datenstruktur treten Konvergenzprobleme auf.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ergebnisse als Dictionary speichern\n",
    "results_dict = {}\n",
    "\n",
    "for var in variables:\n",
    "    # Formel für MixedLM: Parameter ~ C(treatment) + C(sensor_name) + rope_release + (1|id)\n",
    "    formula = f\"{var} ~ C(treatment) + C(sensor_name)\" #  +  rope_release\n",
    "    model = smf.mixedlm(formula, data=df, groups=df[\"id\"])\n",
    "    \n",
    "    # Modell fitten\n",
    "    fit = model.fit(reml=True)  # REML ist Standard für gemischte Modelle\n",
    "    \n",
    "    # Ergebnisse ausgeben\n",
    "    print(f\"\\n### Ergebnisse für {var} ###\")\n",
    "    print(fit.summary())\n",
    "    \n",
    "    # Überprüfen, ob das Modell konvergiert ist\n",
    "    if not fit.converged:\n",
    "        print(\"Achtung: Das Modell ist nicht konvergiert. Erwägen Sie Anpassungen (z.B. Skalierung der Daten).\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.185058800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vereinfachtes Vorgehen durch Aggregation (Mittelung über Sensoren)\n",
    "\n",
    "Um dennoch aussagekräftige Aussagen zu erhalten, werden die Messungen pro `id` über alle Sensoren gemittelt. Dadurch geht zwar die Variation aufgrund unterschiedlicher Sensoren verloren, aber es entsteht ein stabileres Datenset, in dem jede `id` einen aggregierten Wert pro Parameter hat.\n",
    "\n",
    "Auf dieser Basis können einfache OLS-Modelle geschätzt werden, z. B. `Parameter ~ C(treatment) + rope_release`. Diese Modelle sind einfacher und sollten stabil konvergieren."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Placeholder for results\n",
    "results = {}\n",
    "\n",
    "# Step 1: Compute the mean of each variable for each id\n",
    "grouped_df = df.groupby(\"id\").agg(\n",
    "    {var: \"mean\" for var in variables}\n",
    ").reset_index()\n",
    "\n",
    "# Add additional variables (e.g., treatment and rope_release) to the aggregated data\n",
    "grouped_df = grouped_df.merge(\n",
    "    df[[\"id\", \"treatment\", \"rope_release\"]].drop_duplicates(), on=\"id\"\n",
    ")\n",
    "\n",
    "# Step 2: Fit linear models to the aggregated data\n",
    "for var in variables:\n",
    "    try:\n",
    "        # Fit a linear model\n",
    "        model = smf.ols(f\"{var} ~ C(treatment) + rope_release\", grouped_df).fit()\n",
    "\n",
    "        # Store relevant results\n",
    "        results[var] = {\n",
    "            \"p_value_treatment\": model.pvalues.get(\"treatment[T.statisch]\", None),\n",
    "            \"p_value_rope_release\": model.pvalues.get(\"rope_release\", None),\n",
    "            \"summary\": model.summary()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        results[var] = {\"error\": str(e)}\n",
    "\n",
    "# Display results\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.191225500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nicht jeder Parameter wird durch `rope_release` beeinflusst. Nur für jene Parameter, bei denen ein signifikanter Einfluss von `rope_release` festgestellt wird, soll dieser Effekt herausgerechnet werden. Auf diese Weise entstehen \"bereinigte\" Werte, in denen der lineare Einfluss von `rope_release` entfernt ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Placeholder for results\n",
    "# Dieses Dictionary wird nun sowohl die Modellobjekte als auch die Kennwerte speichern.\n",
    "results = {}\n",
    "\n",
    "# Liste der Variablen, für die rope_release berücksichtigt wird\n",
    "relevant_vars_rope_release = ['m_amplitude', 'm_amplitude_2', 'max_strain', 'max_compression']\n",
    "\n",
    "# Step 1: Compute the mean of each variable for each id\n",
    "grouped_df = df.groupby(\"id\").agg(\n",
    "    {var: \"mean\" for var in variables}\n",
    ").reset_index()\n",
    "\n",
    "# Add additional variables (e.g., treatment and rope_release) to the aggregated data\n",
    "grouped_df = grouped_df.merge(\n",
    "    df[[\"id\", \"treatment\", \"rope_release\"]].drop_duplicates(), on=\"id\"\n",
    ")\n",
    "\n",
    "# Step 2: Fit linear models to the aggregated data and store model objects and p-Werte in results\n",
    "for var in variables:\n",
    "    # Formuliere das Modell dynamisch, abhängig davon, ob rope_release relevant ist\n",
    "    if var in relevant_vars_rope_release:\n",
    "        formula = f\"{var} ~ C(treatment) + rope_release\"\n",
    "    else:\n",
    "        formula = f\"{var} ~ C(treatment)\"\n",
    "\n",
    "    try:\n",
    "        # Fit a linear model\n",
    "        model = smf.ols(formula, grouped_df).fit()\n",
    "\n",
    "        # Store model and relevant results directly in results\n",
    "        results[var] = {\n",
    "            \"model\": model,\n",
    "            \"p_value_treatment\": model.pvalues.get(\"treatment[T.statisch]\", None),\n",
    "            \"p_value_rope_release\": model.pvalues.get(\"rope_release\", None) if var in relevant_vars_rope_release else None,\n",
    "            \"summary\": model.summary()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        results[var] = {\"error\": str(e)}\n",
    "\n",
    "# Display results\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.191225500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Beispiel für m_amplitude\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=grouped_df, x='rope_release', y='m_amplitude_2', hue='treatment', ci=95)\n",
    "plt.title('Einfluss von rope_release auf m_amplitude für verschiedene Treatments')\n",
    "plt.xlabel('rope_release (kN)')\n",
    "plt.ylabel('m_amplitude')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.191225500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=grouped_df, x='treatment', y='m_amplitude')\n",
    "plt.title('Vergleich von m_amplitude zwischen den Treatments')\n",
    "plt.xlabel('Treatment')\n",
    "plt.ylabel('m_amplitude')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.191225500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "\n",
    "# Liste der Variablen, die in die Tabelle übernommen werden sollen\n",
    "variables_spec = [\n",
    "    'm_amplitude_2',\n",
    "    'max_compression',\n",
    "    'damping_coeff',\n",
    "    'damping_ratio',\n",
    "    'frequency_damped',\n",
    "    'frequency_undamped',\n",
    "]\n",
    "\n",
    "# Umbenennung der Spalten für LaTeX-Notation\n",
    "column_rename_map = {\n",
    "    'm_amplitude_2': r'$mA_2$',\n",
    "    'max_compression': r'$\\text{max\\_C}$',\n",
    "    'damping_coeff': r'$\\delta$',\n",
    "    'damping_ratio': r'$D$',\n",
    "    'frequency_damped': r'$f_d$',\n",
    "    'frequency_undamped': r'$f_0$',\n",
    "}\n",
    "\n",
    "# Funktion zur Erstellung der Modellgüte-Kennzahlen für alle Variablen\n",
    "def create_model_metrics_table(variables, results):\n",
    "    metrics_data = {\n",
    "        \"Kennzahl\": [\"R²\", \"Adj. R²\", \"F-St.\", \"AIC\", \"N\"]\n",
    "    }\n",
    "\n",
    "    for var in variables:\n",
    "        col_name = column_rename_map.get(var, var)  # Verwende gekürzten Namen, falls vorhanden\n",
    "        if var not in results or 'error' in results[var]:\n",
    "            metrics_data[col_name] = [\"n/a\"] * 5\n",
    "        else:\n",
    "            model = results[var]['model']\n",
    "            metrics_data[col_name] = [\n",
    "                f\"{model.rsquared:.4f}\",\n",
    "                f\"{model.rsquared_adj:.4f}\",\n",
    "                f\"{model.fvalue:.4f}\",\n",
    "                f\"{model.aic:.4f}\",\n",
    "                f\"{model.nobs:.0f}\"\n",
    "            ]\n",
    "\n",
    "    # Erstelle die Tabelle mit tabulate\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    return tabulate(\n",
    "        metrics_df,\n",
    "        headers=\"keys\",\n",
    "        tablefmt=\"latex_raw\",\n",
    "        floatfmt=\".4f\",\n",
    "        showindex=False)\n",
    "\n",
    "# Funktion zur Erstellung einer LaTeX-Tabelle für die Koeffizienten einer Variable\n",
    "def create_latex_table_for_variable(var, results):\n",
    "    if var not in results:\n",
    "        return f\"%% Keine Ergebnisse für Variable {var} vorhanden.\"\n",
    "    \n",
    "    model_result = results[var]\n",
    "    if 'error' in model_result:\n",
    "        return f\"%% Fehler beim Anpassen des Modells für {var}: {model_result['error']}\"\n",
    "    \n",
    "    model = model_result['model']\n",
    "    summary = model.summary2().tables[1]  # Zugriff auf die Tabelle der Koeffizienten\n",
    "\n",
    "    # Erstelle eine LaTeX-Tabelle mit tabulate für die Koeffizienten\n",
    "    latex_table = tabulate(\n",
    "        summary,\n",
    "        headers=summary.columns,\n",
    "        tablefmt=\"latex_booktabs\",\n",
    "        floatfmt=\".4f\",\n",
    "        showindex=True\n",
    "    )\n",
    "\n",
    "    # Escape Unterstriche in der Variable für LaTeX\n",
    "    escaped_var = re.sub(r'_', r'\\_', var)\n",
    "    shortened_var = column_rename_map.get(var, escaped_var)\n",
    "\n",
    "    # Füge die LaTeX-Caption zur Tabelle hinzu\n",
    "    return f\"\"\"\n",
    "\\\\begin{{table}}[ht]\n",
    "    \\\\centering\n",
    "    \\\\caption{{Modellzusammenfassung für {escaped_var} ({shortened_var})}}\n",
    "    \\\\begin{{adjustbox}}{{max width=\\\\textwidth}}\n",
    "    {latex_table}\n",
    "    \\\\end{{adjustbox}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "# Erstelle die Modellgüte-Tabelle für alle Variablen\n",
    "latex_metrics_table = create_model_metrics_table(variables_spec, results)\n",
    "print(\"\"\"\n",
    "\\\\begin{table}[ht]\n",
    "    \\\\centering\n",
    "    \\\\caption{Modellgüte für alle Variablen}\n",
    "    \\\\begin{adjustbox}{max width=\\\\textwidth}\n",
    "\"\"\")\n",
    "print(latex_metrics_table)\n",
    "print(\"\"\"\n",
    "    \\\\end{adjustbox}\n",
    "\\\\end{table}\n",
    "\n",
    "\\\\vspace{1cm}\n",
    "\"\"\")\n",
    "\n",
    "# Erstelle und print die LaTeX-Tabellen für die Koeffizienten jeder Variable\n",
    "for var in variables_spec:\n",
    "    latex_output = create_latex_table_for_variable(var, results)\n",
    "    print(latex_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.206849200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables), 2, (len(variables) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_with_rope_release\", subdir=\"combined\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.222471700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Für die betroffenen Parameter wird der Einfluss von `rope_release` mithilfe der bereits angepassten Modelle (`Parameter ~ C(treatment) + rope_release`) entfernt. Dazu werden Vorhersagen für einen konstanten `rope_release`-Wert (den Mittelwert) berechnet und mit den tatsächlichen Werten verglichen. Die daraus resultierenden bereinigten Werte sind frei von Variation, die auf `rope_release` zurückzuführen wäre."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_adjusted_df = grouped_df.copy()\n",
    "\n",
    "# Bereinigung: Wir setzen rope_release auf seinen Mittelwert\n",
    "rope_mean = grouped_df[\"rope_release\"].mean()\n",
    "\n",
    "for var in relevant_vars_rope_release:\n",
    "    # Zugehöriges Modellobjekt abrufen\n",
    "    model = results[var][\"model\"]\n",
    "\n",
    "    # Vorhersage mit tatsächlichen rope_release-Werten\n",
    "    predicted_current = model.predict(grouped_df)\n",
    "\n",
    "    # Vorhersage, wenn rope_release = rope_mean gesetzt wird\n",
    "    df_mean_rope = grouped_df.copy()\n",
    "    df_mean_rope[\"rope_release\"] = rope_mean\n",
    "    predicted_mean = model.predict(df_mean_rope)\n",
    "\n",
    "    # Angepasste Werte berechnen:\n",
    "    actual = grouped_df[var].values\n",
    "    adjusted = actual + (predicted_mean - predicted_current)\n",
    "    grouped_adjusted_df[var] = adjusted"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.222471700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.222471700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_adjusted_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.238099500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Latex Tabelle Output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.238099500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DataFrame mit den relevanten Spalten erstellen\n",
    "variables_latex = [\n",
    "    'm_amplitude', \n",
    "    'm_amplitude_2',\n",
    "    'initial_amplitude',\n",
    "    'damping_coeff', \n",
    "    'damping_ratio', \n",
    "    'frequency_damped', \n",
    "    'frequency_undamped',\n",
    "    'pearson_r',\n",
    "    'nmae'\n",
    "]\n",
    "df_latex = grouped_adjusted_df[variables_latex + ['treatment']].copy()\n",
    "df_latex.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.238099500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Spaltennamen entsprechend der LaTeX-Notation umbenennen\n",
    "df_latex.rename(columns=data_dict, inplace=True)\n",
    "\n",
    "# Erstellung deskriptiver Statistiken für alle Beobachtungen\n",
    "overall_stats = df_latex.describe().drop(index=['count', '25%', '75%'])\n",
    "overall_stats.rename(index={'50%': 'median'}, inplace=True)\n",
    "\n",
    "# Erstellung der deskriptiven Statistiken für jede Gruppe\n",
    "grouped_stats = {\n",
    "    'overall': overall_stats\n",
    "}\n",
    "\n",
    "for treatment, group in df_latex.groupby('treatment', observed=True):\n",
    "    group_stats = group.describe().drop(index=['count', '25%', '75%'])\n",
    "    group_stats.rename(index={'50%': 'median'}, inplace=True)\n",
    "    grouped_stats[treatment] = group_stats\n",
    "\n",
    "# Zusammenführen der Statistiken in einer Tabelle\n",
    "combined_stats = pd.concat(grouped_stats, names=['Treatment'])\n",
    "\n",
    "# LaTeX-Export des kombinierten DataFrames\n",
    "df_latex_string = combined_stats.to_latex(\n",
    "    escape=False,\n",
    "    multirow=True,\n",
    "    multicolumn=True,\n",
    "    column_format=\"l|lrrrrrrrrr\", \n",
    "    float_format=\"{:0.2f}\".format\n",
    ")\n",
    "\n",
    "# LaTeX-Tabellencode erstellen\n",
    "latex_table = f\"\"\"\n",
    "\\\\begin{{table}}[h]\n",
    "    \\\\centering\n",
    "    \\\\caption{{Feldversuch 2 - Ergebnisse, Schwingungsparameter deskriptive Statistiken (Gesamt und gruppiert über Treatment), Amplituden korrigiert über \\\\texttt{{rope\\\\_release}}, 9 Beobachtung je Gruppe, jeweils Mittelwert für 4 Elastometer}}\n",
    "    \\\\begin{{adjustbox}}{{max width=\\\\textwidth}}\n",
    "    {df_latex_string}\n",
    "    \\\\end{{adjustbox}}\n",
    "    \\\\label{{tab:Feldversuch_2_Deskriptive_Statistiken_Schwingungsparameter}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.253730100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualisierung der bereinigten Ergebnisse\n",
    "\n",
    "Abschließend werden die bereinigten Werte grafisch dargestellt, um die Unterschiede zwischen den Behandlungen in Abwesenheit des `rope_release`-Einflusses zu verdeutlichen. Dies zeigt, wie sich die Treatments auf die Parameter auswirken würden, wenn für alle Einheiten die gleiche mittlere Vorspannung gelten würde."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "relevant_vars_rope_release = ['m_amplitude', 'm_amplitude_2', 'max_strain', 'max_compression']\n",
    "\n",
    "n_vars = len(relevant_vars_rope_release)\n",
    "n_cols = 2  # Links Original, rechts angepasst\n",
    "n_rows = n_vars  # Eine Zeile pro Variable\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "\n",
    "for i, var in enumerate(relevant_vars_rope_release):\n",
    "    # Linke Spalte: Original (grouped_df)\n",
    "    sns.boxplot(ax=axes[i,0], x=\"treatment\", y=var, data=grouped_df, \n",
    "                palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i,0], x=\"treatment\", y=var, data=grouped_df, \n",
    "                  dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i,0].set_title(f\"original: {var}\")\n",
    "    axes[i,0].set_ylabel(var)\n",
    "\n",
    "    # Rechte Spalte: Angepasst (grouped_adjusted_df)\n",
    "    sns.boxplot(ax=axes[i,1], x=\"treatment\", y=var, data=grouped_adjusted_df, \n",
    "                palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i,1], x=\"treatment\", y=var, data=grouped_adjusted_df, \n",
    "                  dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i,1].set_title(f\"adjusted : {var}\")\n",
    "    axes[i,1].set_ylabel(var)\n",
    "    \n",
    "    # Y-Limits von links holen\n",
    "    y_min, y_max = axes[i,0].get_ylim()\n",
    "    # Y-Limits auf rechts anwenden\n",
    "    axes[i,1].set_ylim(y_min, y_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_comparison\", subdir=\"combined\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.258743200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Schritt 2: Durchführung von Post-hoc-Tests\n",
    "\n",
    "Festzustellen welche paarweisen Unterschiede zwischen den Treatments signifikant sind."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Wir gehen davon aus, dass grouped_adjusted_df existiert und die Spalten 'treatment' sowie die Variablen aus 'variables' enthält.\n",
    "\n",
    "for var in variables_spec:\n",
    "    # Tukey HSD Test durchführen\n",
    "    # Annahme: Die Spalte 'treatment' enthält die Gruppennamen z.B. 'free', 'gefa_dynamic', 'cobra_static'\n",
    "    # pairwise_tukeyhsd benötigt die abhängige Variable und die Gruppen.\n",
    "    tukey_results = pairwise_tukeyhsd(endog=grouped_adjusted_df[var],\n",
    "                                      groups=grouped_adjusted_df['treatment'],\n",
    "                                      alpha=0.05)\n",
    "    \n",
    "    print(f\"--- Post-Hoc Test (Tukey HSD) für Variable: {var} ---\")\n",
    "    print(tukey_results.summary())\n",
    "    print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:41.321258300Z",
     "start_time": "2025-04-21T10:39:41.258743200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables_spec), 2, (len(variables_spec) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables_spec):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_without_rope_release\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.258743200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables_spec), 2, (len(variables_spec) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables_spec):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_without_rope_release_spec\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.258743200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vorhergesagte Werte extrahieren und Boxplots für die Sensoren erstellen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Vorhergesagte Werte aus den Modellen extrahieren\n",
    "for variable in variables:\n",
    "    df[f'predicted_{variable}'] = models[variable].fittedvalues\n",
    "\n",
    "# Boxplots erstellen mit den vorhergesagten Werten\n",
    "fig, axes = plt.subplots(4, 2, figsize=(8, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    sns.boxplot(ax=axes[i], x='treatment', y=f'predicted_{variable}', data=df, palette=treatment_color_dict, hue='treatment', dodge=False, legend=False)\n",
    "    axes[i].set_title(f'{variable} by Treatment')\n",
    "    axes[i].set_xlabel('Treatment')\n",
    "    axes[i].set_ylabel(f'Predicted {variable}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"predicted_effect_for_treatment\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.274385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def annotate_tukey(ax, tukey_result, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Fügt eine Textbox mit den Tukey-Test-Ergebnissen und dem festgelegten Signifikanzniveau in den Plot ein.\n",
    "    \n",
    "    Parameters:\n",
    "    ax (matplotlib.axes): Die Achse, auf der der Plot gezeichnet wird.\n",
    "    tukey_result (TukeyHSDResults): Die Ergebnisse des Tukey HSD Tests.\n",
    "    significance_level (float): Das Signifikanzniveau, standardmäßig 0.05.\n",
    "    \"\"\"\n",
    "    # Definiere die gewünschte Reihenfolge der Vergleiche\n",
    "    comparisons_order = [('free', 'gefa_dynamic'), ('free', 'cobra_static'), ('gefa_dynamic', 'cobra_static')]\n",
    "\n",
    "    # Text für die Annotation zusammenstellen\n",
    "    text_str = f\"Tukey HSD Results: \\n(Significance level = {significance_level:.2f})\\n\\n\"\n",
    "    \n",
    "    # Durchlaufe die gewünschte Vergleichsreihenfolge\n",
    "    for group1, group2 in comparisons_order:\n",
    "        # Filtere die korrekte Paarung aus den Tukey-Ergebnissen\n",
    "        for i in range(len(tukey_result._results_table.data[1:])):\n",
    "            pair = tukey_result._results_table.data[i + 1]\n",
    "            if (pair[0] == group1 and pair[1] == group2) or (pair[0] == group2 and pair[1] == group1):\n",
    "                p_value = tukey_result.pvalues[i]\n",
    "                significance = \"*\" if p_value < significance_level else \"n.s.\"\n",
    "                text_str += f\"\\n{group1} vs {group2}: \\np = {p_value:.4f} ({significance})\\n\\n\"\n",
    "    \n",
    "    # Textbox am Rand des Plots hinzufügen\n",
    "    ax.annotate(text_str, xy=(1.01, 0.1), xycoords='axes fraction', va='center', ha='left')\n",
    "\n",
    "# Einzelne Plots für jede Variable erstellen und speichern\n",
    "for variable in variables:\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    # Boxplot für die aktuelle Variable\n",
    "    sns.boxplot(ax=ax, x='treatment', y=f'predicted_{variable}', data=df, \n",
    "                palette=treatment_color_dict, hue='treatment', dodge=False, legend=False)\n",
    "    \n",
    "    # Tukey-Test für die aktuelle Variable\n",
    "    tukey_result = tukey_results[variable]\n",
    "    \n",
    "    # Tukey-Ergebnisse annotieren\n",
    "    annotate_tukey(ax, tukey_result)\n",
    "    \n",
    "    ax.set_title(f'{variable} by Treatment')\n",
    "    ax.set_xlabel('Treatment')\n",
    "    ax.set_ylabel(f'Predicted {variable}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot speichern\n",
    "    plot_filename = f\"{variable}_effect_for_treatment\"\n",
    "    PLOT_MANAGER.save_plot(fig, filename=plot_filename, subdir=\"osc_variables_box\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.274385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames nach 'treatment' und Entfernen unnötiger Spalten\n",
    "df_treatment_describe = (df.drop(['id', 'ptq_sensor_name'], axis=1)\n",
    "                         .groupby('treatment', observed=True)\n",
    "                         .describe())\n",
    "\n",
    "df_treatment_describe = df_treatment_describe.reset_index()\n",
    "df_treatment_describe.round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.274385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.274385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames nach 'treatment' und Entfernen unnötiger Spalten\n",
    "df_sensor = (df.drop(['id', 'release_force_target', 'ls3_rope_release', 'ls3_cable_max', 'location', 'height', 'diameter', 'direction'], axis=1).\n",
    "             groupby(['treatment', 'ptq_sensor_name'], observed=True).\n",
    "             mean())  #.T\n",
    "#df_sensor.round(4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.274385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.290008200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames und Anwenden von mean für ptq_sensor_name \n",
    "df_id = ((df.drop(['ptq_sensor_name', 'location', 'height', 'diameter', 'direction'], axis=1)\n",
    "          .groupby(['treatment', 'id'], observed=True)\n",
    "          .mean())\n",
    "         .reset_index())\n",
    "\n",
    "df_id.round(4).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zusammenhangsanalyse für LS3 und PTQ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.290008200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Auswahl der neuen Spaltennamen für die Korrelationsmatrix\n",
    "columns_corr = ['ptq_m_amplitude',\n",
    "                'ptq_m_amplitude_2',\n",
    "                'ptq_initial_amplitude',\n",
    "                'ptq_damping_coeff',\n",
    "                'ptq_angular_frequency',\n",
    "                'ptq_y_shift',\n",
    "                'ptq_pearson_r',\n",
    "                #'ptq_nrmse',\n",
    "                'ptq_nmae',\n",
    "                'release_force_target',\n",
    "                'ls3_rope_release',\n",
    "                'ls3_cable_max']\n",
    "df_corr = df_id.copy()[columns_corr]\n",
    "\n",
    "# Berechnung der Korrelationsmatrix\n",
    "correlation_matrix = df_corr.corr()\n",
    "\n",
    "# Visualisierung der Korrelationsmatrix mit Seaborn\n",
    "fig1, ax = plt.subplots(figsize=(8, 8))  # Anpassen der Größe der Grafik\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', ax=ax, annot_kws={'size': 10})\n",
    "\n",
    "# Titel und Schriftgrößen anpassen\n",
    "#plt.title('Correlation Matrix for LS3 and PTQ', fontsize=18)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=12, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize=12, rotation=45, ha='right')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig1, filename=\"correlation_matrix\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.290008200Z"
    }
   },
   "outputs": [],
   "source": [
    "# ANOVA für 'ls3_rope_release'\n",
    "model_rope_release = smf.ols('ls3_rope_release ~ treatment', data=df_id).fit()\n",
    "anova_rope_release = sm.stats.anova_lm(model_rope_release, typ=2)\n",
    "\n",
    "# ANOVA für 'ls3_cable_max'\n",
    "model_cable_max = smf.ols('ls3_cable_max ~ treatment', data=df_id).fit()\n",
    "anova_cable_max = sm.stats.anova_lm(model_cable_max, typ=2)\n",
    "\n",
    "# Zusammenfassungen der Modelle\n",
    "summary_rope_release = model_rope_release.summary()\n",
    "summary_cable_max = model_cable_max.summary()\n",
    "# Zusammenfassungen der Modelle\n",
    "summary_rope_release_latex = model_rope_release.summary().as_latex()\n",
    "summary_cable_max_latex = model_cable_max.summary().as_latex()\n",
    "\n",
    "#print(summary_rope_release_latex)\n",
    "#print(summary_cable_max_latex)\n",
    "\n",
    "anova_rope_release, summary_rope_release, anova_cable_max, summary_cable_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.290008200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung des Text-Strings für die statistischen Parameter\n",
    "def annotate_stats(x, y):\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "    text_str = f\"R = {r_value:.2f}\\nSlope = {slope:.2f}\\nIntercept = {intercept:.2f}\\np-value = {p_value:.2e}\\nStd Err = {std_err:.2f}\"\n",
    "    return text_str"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Zusammenhang Ziel- und Ist-Vorspannung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig2, ax1 = plt.subplots(figsize=(8, 5))\n",
    "sns.regplot(x='release_force_target', y='ls3_rope_release', data=df_id, ax=ax1, color='b', ci=95)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "stats_text = annotate_stats(df_id['release_force_target'], df_id['ls3_rope_release'])\n",
    "ax2.annotate(stats_text, xy=(1.01, 0.1), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Target and Actual Release Forces\"')\n",
    "ax1.set_xlabel('Release Force Target [kN]')\n",
    "ax1.set_ylabel('Release Force [kN]')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig2, filename=f\"release_force_target_vs_ls3_rope_release\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.290008200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Zusammenhang Vorspannung und resultierende Lastspitzen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.290008200Z"
    }
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ls3_cable_max'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ls3_cable_max', data=subset, ax=ax1, color=color, label=treatment, ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ls3_cable_max'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Peak Cable Force')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Peak Force in Cable [kN]')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"release_force_vs_ls3_cable_max\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.290008200Z"
    }
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ptq_m_amplitude'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ptq_m_amplitude', data=subset, ax=ax1, color=color, label=treatment,\n",
    "                ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ptq_m_amplitude'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Elongation Amplitude')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Elongation Amplitude [$\\mu$m] (mean for all Sensors)')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"ls3_release_force_vs_ptq_m_amplitude\", subdir=\"combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ptq_m_amplitude_2'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ptq_m_amplitude_2', data=subset, ax=ax1, color=color, label=treatment,\n",
    "                ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ptq_m_amplitude_2'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Elongation Amplitude 2')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Elongation Amplitude 2 [$\\mu$m] (mean for all Sensors)')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"ls3_release_force_vs_ptq_m_amplitude_2\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.305638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.305638Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funktion zur Durchführung des ANOVA-Tests und Berechnung der Effektstärke (Eta Squared)\n",
    "def perform_anova_and_effect_size(df: pd.DataFrame, variable: str, treatments: List[str]) -> str:\n",
    "    groups = [df[df['treatment'] == treatment][variable].dropna() for treatment in treatments]\n",
    "    f_stat, p_value = f_oneway(*groups)\n",
    "\n",
    "    # Berechnung der Effektstärke (Eta Squared)\n",
    "    n = sum([len(g) for g in groups])\n",
    "    ss_total = sum([(x - df[variable].mean()) ** 2 for g in groups for x in g])\n",
    "    eta_squared = f_stat * len(groups) / (f_stat * len(groups) + (n - len(groups)))\n",
    "\n",
    "    # Überprüfung der Signifikanz\n",
    "    significance = \"*\" if p_value < 0.05 else \"\"\n",
    "\n",
    "    return f\"{variable}: {significance}\\nF-statistic = {f_stat:.2f}\\np-value = {p_value:.2e}\\nEta Squared = {eta_squared:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung von Boxplots\n",
    "def create_boxplot(df: pd.DataFrame, variable: str, group_by: str, ax: plt.Axes, color_dict: Dict[str, str], perform_stats: bool) -> None:\n",
    "    valid_df = df.dropna(subset=[variable])\n",
    "    sns.boxplot(x=group_by, y=variable, hue=group_by, data=valid_df, ax=ax, palette=color_dict, dodge=False)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.axis('off')\n",
    "    if perform_stats:\n",
    "        stats_text = perform_anova_and_effect_size(valid_df, variable, valid_df[group_by].unique())\n",
    "        ax2.annotate(stats_text, xy=(1.01, 0.1), xycoords='axes fraction')\n",
    "    ax.set_title(f'Einfluss von {group_by} auf {variable}')\n",
    "    ax.set_xlabel(group_by)\n",
    "    ax.set_ylabel(variable)\n",
    "\n",
    "# Funktion zur Erstellung kombinierter Plots\n",
    "def create_combined_plot(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], num_columns: int = 3, perform_stats: bool = False) -> None:\n",
    "    num_rows = len(columns) // num_columns + (len(columns) % num_columns > 0)\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(16, 4 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, variable in enumerate(columns):\n",
    "        create_boxplot(df, variable, group_by, axes[idx], color_dict, perform_stats)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"combined_plot_{group_by}\", subdir=\"combined\")\n",
    "\n",
    "# Funktion zur Erstellung einzelner Plots\n",
    "def create_individual_plots(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], perform_stats: bool = False) -> None:\n",
    "    for variable in columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        create_boxplot(df, variable, group_by, ax, color_dict, perform_stats)\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        PLOT_MANAGER.save_plot(fig, filename=f\"{group_by}_{variable}\", subdir=\"individual_plots\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.305638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.305638Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['ptq_m_amplitude',\n",
    "           'ptq_m_amplitude_2',\n",
    "           'ptq_initial_amplitude',\n",
    "           'ptq_damping_coeff',\n",
    "           'ptq_angular_frequency',\n",
    "           'ptq_y_shift',\n",
    "           'ptq_pearson_r',\n",
    "           #'ptq_nrmse',\n",
    "           #'ptq_nmae',\n",
    "           #'release_force_target',\n",
    "           'ls3_rope_release',\n",
    "           'ls3_cable_max'\n",
    "           ]\n",
    "\n",
    "# Beispiel: Erstellen von Plots gruppiert nach 'treatment'\n",
    "create_combined_plot(df, columns, 'treatment', treatment_color_dict, perform_stats=True)\n",
    "create_individual_plots(df, columns, 'treatment', treatment_color_dict, perform_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.305638Z"
    }
   },
   "outputs": [],
   "source": [
    "# Beispiel: Erstellen von Plots gruppiert nach 'ptq_sensor_name'\n",
    "columns = ['ptq_m_amplitude', 'ptq_m_amplitude_2', 'ptq_initial_amplitude', 'ptq_damping_coeff', 'ptq_angular_frequency', 'ptq_pearson_r']\n",
    "\n",
    "create_combined_plot(df, columns, 'ptq_sensor_name', sensor_color_dict)\n",
    "create_individual_plots(df, columns, 'ptq_sensor_name', sensor_color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.305638Z"
    }
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ptq_m_amplitude_2'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ptq_m_amplitude_2', data=subset, ax=ax1, color=color, label=treatment,\n",
    "                ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ptq_m_amplitude_2'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Elongation Amplitude 2')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Elongation Amplitude 2 [$\\mu$m] (mean for all Sensors)')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"ls3_release_force_vs_ptq_m_amplitude_2\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Durchführung des ANOVA-Tests und Berechnung der Effektstärke (Eta Squared)\n",
    "def perform_anova_and_effect_size(df: pd.DataFrame, variable: str, treatments: List[str]) -> str:\n",
    "    groups = [df[df['treatment'] == treatment][variable].dropna() for treatment in treatments]\n",
    "    f_stat, p_value = f_oneway(*groups)\n",
    "\n",
    "    # Berechnung der Effektstärke (Eta Squared)\n",
    "    n = sum([len(g) for g in groups])\n",
    "    ss_total = sum([(x - df[variable].mean()) ** 2 for g in groups for x in g])\n",
    "    eta_squared = f_stat * len(groups) / (f_stat * len(groups) + (n - len(groups)))\n",
    "\n",
    "    # Überprüfung der Signifikanz\n",
    "    significance = \"*\" if p_value < 0.05 else \"\"\n",
    "\n",
    "    return f\"{variable}: {significance}\\nF-statistic = {f_stat:.2f}\\np-value = {p_value:.2e}\\nEta Squared = {eta_squared:.2f}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:39:41.437163Z",
     "start_time": "2025-04-21T10:39:41.321258300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung von Boxplots\n",
    "def create_boxplot(df: pd.DataFrame, variable: str, group_by: str, ax: plt.Axes, color_dict: Dict[str, str], perform_stats: bool) -> None:\n",
    "    valid_df = df.dropna(subset=[variable])\n",
    "    sns.boxplot(x=group_by, y=variable, hue=group_by, data=valid_df, ax=ax, palette=color_dict, dodge=False)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.axis('off')\n",
    "    if perform_stats:\n",
    "        stats_text = perform_anova_and_effect_size(valid_df, variable, valid_df[group_by].unique())\n",
    "        ax2.annotate(stats_text, xy=(1.01, 0.1), xycoords='axes fraction')\n",
    "    ax.set_title(f'Einfluss von {group_by} auf {variable}')\n",
    "    ax.set_xlabel(group_by)\n",
    "    ax.set_ylabel(variable)\n",
    "\n",
    "# Funktion zur Erstellung kombinierter Plots\n",
    "def create_combined_plot(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], num_columns: int = 3, perform_stats: bool = False) -> None:\n",
    "    num_rows = len(columns) // num_columns + (len(columns) % num_columns > 0)\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(16, 4 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, variable in enumerate(columns):\n",
    "        create_boxplot(df, variable, group_by, axes[idx], color_dict, perform_stats)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"combined_plot_{group_by}\", subdir=\"combined\")\n",
    "\n",
    "# Funktion zur Erstellung einzelner Plots\n",
    "def create_individual_plots(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], perform_stats: bool = False) -> None:\n",
    "    for variable in columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        create_boxplot(df, variable, group_by, ax, color_dict, perform_stats)\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        PLOT_MANAGER.save_plot(fig, filename=f\"{group_by}_{variable}\", subdir=\"individual_plots\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.321258300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.321258300Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['ptq_m_amplitude',\n",
    "           'ptq_m_amplitude_2',\n",
    "           'ptq_initial_amplitude',\n",
    "           'ptq_damping_coeff',\n",
    "           'ptq_angular_frequency',\n",
    "           'ptq_y_shift',\n",
    "           'ptq_pearson_r',\n",
    "           #'ptq_nrmse',\n",
    "           #'ptq_nmae',\n",
    "           #'release_force_target',\n",
    "           'ls3_rope_release',\n",
    "           'ls3_cable_max'\n",
    "           ]\n",
    "\n",
    "# Beispiel: Erstellen von Plots gruppiert nach 'treatment'\n",
    "create_combined_plot(df, columns, 'treatment', treatment_color_dict, perform_stats=True)\n",
    "create_individual_plots(df, columns, 'treatment', treatment_color_dict, perform_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-21T10:39:41.321258300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Beispiel: Erstellen von Plots gruppiert nach 'ptq_sensor_name'\n",
    "columns = ['ptq_m_amplitude', 'ptq_m_amplitude_2', 'ptq_initial_amplitude', 'ptq_damping_coeff', 'ptq_angular_frequency', 'ptq_pearson_r']\n",
    "\n",
    "create_combined_plot(df, columns, 'ptq_sensor_name', sensor_color_dict)\n",
    "create_individual_plots(df, columns, 'ptq_sensor_name', sensor_color_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
