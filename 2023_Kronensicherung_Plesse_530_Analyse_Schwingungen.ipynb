{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"2023_Kronensicherung_Plesse_Analyse\"\n",
    "author: \"Kyell Jensen\"\n",
    "date: \"2024-08-06\"\n",
    "format: pdf\n",
    "editor: visual\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2023_Kronensicherung_Plesse_Analyse\n",
    "\n",
    "## Kombinierte Analyse LineScale3, TreeQinetic und Versuchsaufzeichung\n",
    "\n",
    "Nutze eine geeignete Python 3.11 Umgebung (z. B. virtuelle Environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arbeitsumgebung vorbereiten\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORT: Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Struktur & Typen\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "# Datenverarbeitung\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from slugify import slugify  # Zum Vereinheitlichen von Strings\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Statistik\n",
    "from scipy.stats import linregress, f_oneway\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.multicomp as mc"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Eigene Module und Funktionen\n",
    "from kj_core.utils.latex_export import (\n",
    "    generate_latex_table,\n",
    "    generate_grouped_latex_tables,\n",
    "    save_latex_table,\n",
    "    build_data_dict_df\n",
    ")\n",
    "from kj_core.utils.labeling import (\n",
    "    get_label_from_dict,\n",
    "    get_color_dict\n",
    ")\n",
    "from kj_core import (\n",
    "    CoreConfig,\n",
    "    PlotManager,\n",
    "    get_logger\n",
    ")\n",
    "\n",
    "# Projekteinstellungen\n",
    "from project_config import (\n",
    "    working_directory,\n",
    "    data_export_directory,\n",
    "    latex_export_directory,\n",
    "    filename_clean_dataset,\n",
    "    filename_clean_data_dict\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORT: Manager Instanzen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)\n",
    "CONFIG = CoreConfig(working_directory=f\"{working_directory}/combined\")\n",
    "PLOT_MANAGER = PlotManager(CONFIG)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## IMPORT: Daten Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dateien laden\n",
    "df = pd.read_feather(data_export_directory / filename_clean_dataset)\n",
    "\n",
    "with open(data_export_directory / filename_clean_data_dict, \"r\", encoding=\"utf-8\") as f:\n",
    "    data_dict = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ANALYSE: Explorative Datenanalyse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### COMBINED: Definition von Darstellungsstandards\n",
    "Festlegen von Farbcodes für einheitliche Darstellung von Sensoren und Behandlungsvarianten für alle nachfolgenden Plots."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "color_palette = PLOT_MANAGER.color_palette_list\n",
    "\n",
    "# Für die Spalte \"treatment\":\n",
    "treatment_color_dict = get_color_dict(df, \"treatment\", PLOT_MANAGER.color_palette_list)\n",
    "# Für die Spalte \"sensor_name\":\n",
    "sensor_color_dict = get_color_dict(df, \"sensor_name\", PLOT_MANAGER.color_palette_list)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LATEX-EXPORT: Latex-Export von Daten für Anhang"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variables_2 = ['id', 'sensor_name', 'treatment', 'm_amplitude', 'm_amplitude_2', 'initial_amplitude', 'damping_coeff', 'damping_ratio', 'frequency_damped', 'frequency_undamped', 'y_shift', 'pearson_r', 'nmae']\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables_2]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables_2})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Schwingungsparameter vollständig\",\n",
    "    column_format=\"lrl|rrr|rr|rr|r|rr\",\n",
    "    group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PTQ: Analyse der Schwingungsparameter\n",
    "\n",
    "In diesem Abschnitt werden die Schwingungsparameter statistisch ausgewertet. Ziel ist es, den Einfluss verschiedener Behandlungsvarianten (treatment) auf die gemessenen Schwingungsparameter zu untersuchen und dabei auch den potenziellen Einfluss der Vorspannung (rope_release) und Sensorposition (sensor_name) zu berücksichtigen.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'm_amplitude', \n",
    "    'm_amplitude_2',\n",
    "    'max_strain',\n",
    "    'max_compression',\n",
    "    'initial_amplitude',\n",
    "    'damping_coeff', \n",
    "    'damping_ratio', \n",
    "    'frequency_damped', \n",
    "    'frequency_undamped',\n",
    "    'pearson_r',\n",
    "    #'nrmse', \n",
    "    'nmae'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Systematischer Einfluss der Sensorposition\n",
    "\n",
    "Ziel: Visuell erkennen, ob unterschiedliche Sensoren konsistent andere Werte liefern."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "for var in variables:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"sensor_name\", y=var, data=df, dodge=True)\n",
    "    # Titel und Achsentitel setzen\n",
    "    plt.title(f\"Einfluss der Sensoren auf {get_label_from_dict(var, data_dict, use_titel=True)}\")\n",
    "    plt.xlabel(\"Sensorname\")\n",
    "    plt.ylabel(get_label_from_dict(var, data_dict, use_full=True))\n",
    "    plt.tight_layout()\n",
    "    #plt.show(\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_sensor_{var}\", subdir=\"ptq_osc/sensor_only\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ziel: Feststellen, ob die Variation durch unterschiedliche Sensorpostion relativ zur behandlungsbedingten Variation relevant ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "for var in variables:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"sensor_name\", y=var, data=df, hue=\"treatment\", palette=treatment_color_dict,  dodge=True)\n",
    "    # Stripplot: Punkte zur Veranschaulichung der Verteilung\n",
    "    sns.stripplot(x=\"sensor_name\", y=var, data=df, hue=\"treatment\", palette=treatment_color_dict, dodge=True, alpha=1, jitter=True, size=5, legend=False)\n",
    "    # Titel und Achsentitel setzen\n",
    "    plt.title(f\"Einfluss der Behandlung auf {get_label_from_dict(var, data_dict, use_titel=True)} gruppiert über Sensoren\")\n",
    "    plt.xlabel(\"Sensorname\")\n",
    "    plt.ylabel(get_label_from_dict(var, data_dict, use_full=True))\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_sensor_treatment_{var}\", subdir=\"ptq_osc/sensor_treatment\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ziel: Feststellen, ob die Variation durch unterschiedliche Behandlungen relativ zur sensorbedingten Variation relevant ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "for var in variables:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"treatment\", y=var, data=df, palette=sensor_color_dict, hue='sensor_name')\n",
    "    sns.stripplot(x=\"treatment\", y=var, data=df, palette=sensor_color_dict, hue='sensor_name', dodge=True, alpha=1, jitter=True, size=5, legend=False)\n",
    "    plt.title(f\"Einfluss der Sensoren auf {get_label_from_dict(var, data_dict, use_titel=True)} gruppiert über Behandlung\")\n",
    "    plt.xlabel(\"Behandlungsvariante\")\n",
    "    plt.ylabel(get_label_from_dict(var, data_dict, use_full=True))\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_treatment_sensor_{var}\", subdir=\"ptq_osc/treatment_sensor\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Statistische Untersuchung des Effektes der Sensorposition innerhalb einer Beobachtung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Deskriptive Statistiken pro Sensor\n",
    "summary_by_sensor = df.groupby('sensor_name', observed=False)[variables].describe()\n",
    "summary_by_sensor"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. ANOVA: Teste, ob die Unterschiede zwischen den Sensoren signifikant sind\n",
    "print(\"\\nANOVA-Tests für Unterschiede zwischen den Sensoren:\")\n",
    "for var in variables:\n",
    "    # Fit eines linearen Modells mit sensor_name als Prädiktor\n",
    "    model = smf.ols(formula=f\"{var} ~ C(sensor_name)\", data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    print(f\"\\nANOVA für {var}:\")\n",
    "    print(anova_table)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Optimaler Ansatz: Versuche Mixed-Linear Model\n",
    "\n",
    "Die Daten sind hierarchisch: mehrere Messungen (vier Sensoren) pro Beobachtungseinheit (`id`). Ein Mixed-Effects Modell könnte diese Struktur abbilden, indem zufällige Effekte für `id` und feste Effekte für `treatment` sowie `sensor_name` berücksichtigt werden. Zusätzlich kann `rope_release` als Kovariate eingeführt werden. Dieser Ansatz wären theoretisch optimal, aber aufgrund der geringen Stichprobengröße und der komplexen Datenstruktur treten Konvergenzprobleme auf."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ergebnisse als Dictionary speichern\n",
    "results_dict = {}\n",
    "\n",
    "for var in variables:\n",
    "    model = smf.mixedlm(\n",
    "        f\"{var} ~ C(treatment) + C(sensor_name) + rope_release\", \n",
    "        data=df, \n",
    "        groups=df[\"id\"]\n",
    "    )\n",
    "    result = model.fit()\n",
    "    print(f\"\\n### Ergebnisse für {var}:\")\n",
    "    print(result.summary())\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Um dennoch aussagekräftige Ergebnisse zu erhalten, wird ein zweistufiges Verfahren genutzt.\n",
    "Zwei Varianten:\n",
    "- Mittlung über alle Sensoren innerhalb eine Beobachtung. Die Variation zwischen den Sensoren bleibt unberücksichtigt und verfälscht ggf. die Ergebnisse. Vorteil: Sehr einfach und stabil\n",
    "- Werte um Sensor-Effekt manuell adjustieren und dann aggregieren wie zuvor. Vorteile: Sensoren verfälschen nicht die Ergebnisse. Nachteil ist die höhere Komplexität und das die Gesamtvariation der Modell am ende verfälsch ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Alternative 1: Vereinfachtes Vorgehen durch Aggregation (Mittelwert)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mean = df.groupby(\"id\").agg({var: \"mean\" for var in variables}).reset_index()\n",
    "# Benenne die Spalten um, damit klar ist, dass es sich um Mittelwerte handelt.\n",
    "df_mean = df_mean.rename(columns={var: f\"{var}_mean\" for var in variables})\n",
    "\n",
    "# Füge zusätzliche Variablen (z.B. treatment und rope_release) hinzu.\n",
    "treatment_df = df[[\"id\", \"treatment\", \"rope_release\"]].drop_duplicates()\n",
    "df_mean = df_mean.merge(treatment_df, on=\"id\")\n",
    "df_mean.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Alternative 2: Werte um Sensor-Effekt und Vorspannung Adjustieren und dann Aggregieren (Mittelwert)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nicht jeder Parameter wird durch `rope_release` beeinflusst. Nur für jene Parameter, bei denen ein signifikanter Einfluss von `rope_release` festgestellt wird, soll dieser Effekt herausgerechnet werden. Auf diese Weise entstehen \"bereinigte\" Werte, in denen der lineare Einfluss von `rope_release` entfernt ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Definiere die Liste der Variablen, bei denen rope_release entfernt werden soll\n",
    "relevant_vars_rope_release = ['m_amplitude', 'm_amplitude_2', 'max_strain', 'max_compression']\n",
    "model_dict = {}\n",
    "# Erstelle eine Kopie des Original-DataFrames\n",
    "df_copy = df.copy()\n",
    "\n",
    "for var in variables:\n",
    "    try:\n",
    "        # Wähle die Modellformel abhängig davon, ob rope_release berücksichtigt werden soll\n",
    "        if var in relevant_vars_rope_release:\n",
    "            formula = f\"{var} ~ C(sensor_name) + rope_release\"\n",
    "        else:\n",
    "            formula = f\"{var} ~ C(sensor_name)\"\n",
    "            \n",
    "        model = smf.ols(formula, data=df).fit()\n",
    "        \n",
    "        # Speichere das Modell im Dictionary (so hast du per Variable die komplette Summary)\n",
    "        model_dict[var] = model\n",
    "        # Berechne adjustierte Werte:\n",
    "        # y_adj = y - (fitted effect - globaler Intercept)\n",
    "        df_copy[f\"{var}_adj\"] = df_copy[var] - (model.fittedvalues - model.params['Intercept'])\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei {var}: {e}\")\n",
    "\n",
    "# Aggregiere über die ID – hier wird der Mittelwert der adjustierten Werte berechnet.\n",
    "df_adj = df_copy.groupby(\"id\").agg({f\"{var}_adj\": \"mean\" for var in variables}).reset_index()\n",
    "# Ergänze zusätzliche Variablen (z.B. treatment und rope_release)\n",
    "treatment_df = df[[\"id\", \"treatment\", \"rope_release\"]].drop_duplicates()\n",
    "df_adj = df_adj.merge(treatment_df, on=\"id\")\n",
    "\n",
    "# Ausgabe der deskriptiven Statistik\n",
    "print(df_adj.describe())\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Zusammenführen beider Alternativen für Vergleich"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- Zusammenführen beider Ansätze ---\n",
    "# Beide DataFrames enthalten nun jeweils den Mittelwert pro ID:\n",
    "# - df_mean: direkte Mittelwerte mit Suffix _mean\n",
    "# - df_adj: sensor-adjustierte Mittelwerte mit Suffix _adj\n",
    "grouped_df = pd.merge(df_mean, df_adj, on=[\"id\", \"treatment\", \"rope_release\"], how=\"inner\")\n",
    "grouped_df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotten und Vergleich beider Ergebnisse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for var in variables:\n",
    "    # Transformiere die Daten in das Long-Format: \n",
    "    # Es werden die beiden Spalten f\"{var}_mean\" und f\"{var}_adj\" unter einer neuen Spalte \"aggregation\" zusammengeführt,\n",
    "    # und die Werte in der Spalte \"value\" gespeichert.\n",
    "    df_long = pd.melt(\n",
    "        grouped_df,\n",
    "        id_vars=[\"id\", \"treatment\", \"rope_release\"],\n",
    "        value_vars=[f\"{var}_mean\", f\"{var}_adj\"],\n",
    "        var_name=\"aggregation\",\n",
    "        value_name=\"value\"\n",
    "    )\n",
    "    # Kürze die Beschriftungen, sodass nur \"mean\" bzw. \"adj\" übrig bleiben\n",
    "    df_long[\"aggregation\"] = df_long[\"aggregation\"].str.replace(f\"{var}_\", \"\", regex=False)\n",
    "    \n",
    "    # Erstelle den Plot: Boxplots nach Behandlung, getrennt nach Aggregationsmethode\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"treatment\", y=\"value\", hue=\"aggregation\", data=df_long, dodge=True)\n",
    "    \n",
    "    # Titel und Achsentitel setzen\n",
    "    plt.title(f\"Einfluss der Behandlung auf {get_label_from_dict(var, data_dict, use_titel=True)}\")\n",
    "    plt.xlabel(\"Behandlung\")\n",
    "    plt.ylabel(get_label_from_dict(var, data_dict, use_full=True))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Speichere den Plot (ersetze PLOT_MANAGER.save_plot durch plt.show() oder deine eigene Funktion, falls nötig)\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_treatment_{var}\", subdir=\"ptq_osc/treatment_comparison\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_model_info(model):\n",
    "    \"\"\"\n",
    "    Extrahiert zentrale Kennzahlen aus einem OLS-Modell.\n",
    "    Liefert ein Dictionary mit R-squared, Adj. R-squared, sowie den Koeffizienten,\n",
    "    Standardfehler, t-Werten und p-Werten für alle Parameter.\n",
    "    \"\"\"\n",
    "    info = {\n",
    "        \"R²\": model.rsquared,\n",
    "        \"adj_R²\": model.rsquared_adj,\n",
    "    }\n",
    "    # Iteriere über alle Parameter im Modell\n",
    "    for param in model.params.index:\n",
    "        info[f\"coef_{param}\"] = model.params[param]\n",
    "        info[f\"std_err_{param}\"] = model.bse[param]\n",
    "        info[f\"t_{param}\"] = model.tvalues[param]\n",
    "        info[f\"p_{param}\"] = model.pvalues[param]\n",
    "    return info"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Erstelle eine Liste, in der pro Variable das extrahierte Dictionary gespeichert wird.\n",
    "model_info_list = []\n",
    "for var, model in model_dict.items():\n",
    "    info = extract_model_info(model)\n",
    "    info['variable'] = var  # Variable als Kennung hinzufügen\n",
    "    model_info_list.append(info)\n",
    "\n",
    "# Konvertiere die Liste in einen DataFrame und setze \"variable\" als Index\n",
    "df_model_info = pd.DataFrame(model_info_list).set_index(\"variable\")\n",
    "df_model_info.index.name = \"Statistik\"\n",
    "df_model_info = df_model_info.T"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def format_value(x):\n",
    "    # Prüfe, ob der Wert numerisch ist\n",
    "    if isinstance(x, (int, float, np.number)):\n",
    "        if abs(x) < 0.0001:\n",
    "            return f\"{x:.2e}\"\n",
    "        else:\n",
    "            return f\"{x:.2f}\"\n",
    "    return x\n",
    "\n",
    "# Wende die Funktion auf alle Zellen von df_model_info an\n",
    "df_model_info = df_model_info.applymap(format_value)\n",
    "df_model_info"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Manuelles Escapen der Unterstriche im Index\n",
    "df_model_info.index = df_model_info.index.astype(str).str.replace('(sensor_name)[T.', r'(sensor)[')\n",
    "df_model_info.index = df_model_info.index.astype(str).str.replace('_', r'\\_')\n",
    "\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_model_info = df_model_info.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables})\n",
    "\n",
    "column_format = \"l\" + \"r\" * (len(df_model_info.columns))\n",
    "latex_string = df_model_info.to_latex(index=True, escape=False, float_format=\"%.2f\", column_format=column_format)\n",
    "\n",
    "# Definiere Beschriftung und lange Beschriftung (Caption)\n",
    "caption = \"Feldversuch 2: Ergebnisse, Zusammenfassung der OLS-Modelle\"\n",
    "caption_long = \"Übersicht über zentrale Kennzahlen der OLS-Modelle: R², Adjusted R², Koeffizienten, Standardfehler, t-Werte und p-Werte für alle Parameter.\"\n",
    "\n",
    "# Funktion zum Speichern der LaTeX-Tabelle (du passt diese Funktion ggf. an deine Gegebenheiten an)\n",
    "save_latex_table(latex_string, caption, latex_export_directory, caption_long)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Auf dieser Basis können einfache OLS-Modelle geschätzt werden, z. B. `Parameter ~ C(treatment)`. Diese Modelle sind einfacher und sollten stabil konvergieren."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Systematischer Einfluss der Behandlungsvariante"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_adj.columns = df_adj.columns.str.replace('_adj$', '', regex=True)\n",
    "desired_order = ['id', 'treatment', 'rope_release']\n",
    "other_columns = [col for col in df_adj.columns if col not in desired_order]\n",
    "new_order = desired_order + other_columns\n",
    "df_adj = df_adj[new_order]\n",
    "df_adj"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "\n",
    "# Liste der Variablen, die in die Tabelle übernommen werden sollen\n",
    "variables_spec = [\n",
    "    'm_amplitude_2',\n",
    "    'max_compression',\n",
    "    'damping_coeff',\n",
    "    'damping_ratio',\n",
    "    'frequency_damped',\n",
    "    'frequency_undamped',\n",
    "]\n",
    "\n",
    "# Umbenennung der Spalten für LaTeX-Notation\n",
    "column_rename_map = {\n",
    "    'm_amplitude_2': r'$mA_2$',\n",
    "    'max_compression': r'$\\text{max\\_C}$',\n",
    "    'damping_coeff': r'$\\delta$',\n",
    "    'damping_ratio': r'$D$',\n",
    "    'frequency_damped': r'$f_d$',\n",
    "    'frequency_undamped': r'$f_0$',\n",
    "}\n",
    "\n",
    "# Funktion zur Erstellung der Modellgüte-Kennzahlen für alle Variablen\n",
    "def create_model_metrics_table(variables, results):\n",
    "    metrics_data = {\n",
    "        \"Kennzahl\": [\"R²\", \"Adj. R²\", \"F-St.\", \"AIC\", \"N\"]\n",
    "    }\n",
    "\n",
    "    for var in variables:\n",
    "        col_name = column_rename_map.get(var, var)  # Verwende gekürzten Namen, falls vorhanden\n",
    "        if var not in results or 'error' in results[var]:\n",
    "            metrics_data[col_name] = [\"n/a\"] * 5\n",
    "        else:\n",
    "            model = results[var]['model']\n",
    "            metrics_data[col_name] = [\n",
    "                f\"{model.rsquared:.4f}\",\n",
    "                f\"{model.rsquared_adj:.4f}\",\n",
    "                f\"{model.fvalue:.4f}\",\n",
    "                f\"{model.aic:.4f}\",\n",
    "                f\"{model.nobs:.0f}\"\n",
    "            ]\n",
    "\n",
    "    # Erstelle die Tabelle mit tabulate\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    return tabulate(\n",
    "        metrics_df,\n",
    "        headers=\"keys\",\n",
    "        tablefmt=\"latex_raw\",\n",
    "        floatfmt=\".4f\",\n",
    "        showindex=False)\n",
    "\n",
    "# Funktion zur Erstellung einer LaTeX-Tabelle für die Koeffizienten einer Variable\n",
    "def create_latex_table_for_variable(var, results):\n",
    "    if var not in results:\n",
    "        return f\"%% Keine Ergebnisse für Variable {var} vorhanden.\"\n",
    "    \n",
    "    model_result = results[var]\n",
    "    if 'error' in model_result:\n",
    "        return f\"%% Fehler beim Anpassen des Modells für {var}: {model_result['error']}\"\n",
    "    \n",
    "    model = model_result['model']\n",
    "    summary = model.summary2().tables[1]  # Zugriff auf die Tabelle der Koeffizienten\n",
    "\n",
    "    # Erstelle eine LaTeX-Tabelle mit tabulate für die Koeffizienten\n",
    "    latex_table = tabulate(\n",
    "        summary,\n",
    "        headers=summary.columns,\n",
    "        tablefmt=\"latex_booktabs\",\n",
    "        floatfmt=\".4f\",\n",
    "        showindex=True\n",
    "    )\n",
    "\n",
    "    # Escape Unterstriche in der Variable für LaTeX\n",
    "    escaped_var = re.sub(r'_', r'\\_', var)\n",
    "    shortened_var = column_rename_map.get(var, escaped_var)\n",
    "\n",
    "    # Füge die LaTeX-Caption zur Tabelle hinzu\n",
    "    return f\"\"\"\n",
    "\\\\begin{{table}}[ht]\n",
    "    \\\\centering\n",
    "    \\\\caption{{Modellzusammenfassung für {escaped_var} ({shortened_var})}}\n",
    "    \\\\begin{{adjustbox}}{{max width=\\\\textwidth}}\n",
    "    {latex_table}\n",
    "    \\\\end{{adjustbox}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "# Erstelle die Modellgüte-Tabelle für alle Variablen\n",
    "latex_metrics_table = create_model_metrics_table(variables_spec, results)\n",
    "print(\"\"\"\n",
    "\\\\begin{table}[ht]\n",
    "    \\\\centering\n",
    "    \\\\caption{Modellgüte für alle Variablen}\n",
    "    \\\\begin{adjustbox}{max width=\\\\textwidth}\n",
    "\"\"\")\n",
    "print(latex_metrics_table)\n",
    "print(\"\"\"\n",
    "    \\\\end{adjustbox}\n",
    "\\\\end{table}\n",
    "\n",
    "\\\\vspace{1cm}\n",
    "\"\"\")\n",
    "\n",
    "# Erstelle und print die LaTeX-Tabellen für die Koeffizienten jeder Variable\n",
    "for var in variables_spec:\n",
    "    latex_output = create_latex_table_for_variable(var, results)\n",
    "    print(latex_output)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables), 2, (len(variables) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_with_rope_release\", subdir=\"combined\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Für die betroffenen Parameter wird der Einfluss von `rope_release` mithilfe der bereits angepassten Modelle (`Parameter ~ C(treatment) + rope_release`) entfernt. Dazu werden Vorhersagen für einen konstanten `rope_release`-Wert (den Mittelwert) berechnet und mit den tatsächlichen Werten verglichen. Die daraus resultierenden bereinigten Werte sind frei von Variation, die auf `rope_release` zurückzuführen wäre."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_adjusted_df = grouped_df.copy()\n",
    "\n",
    "# Bereinigung: Wir setzen rope_release auf seinen Mittelwert\n",
    "rope_mean = grouped_df[\"rope_release\"].mean()\n",
    "\n",
    "for var in relevant_vars_rope_release:\n",
    "    # Zugehöriges Modellobjekt abrufen\n",
    "    model = results[var][\"model\"]\n",
    "\n",
    "    # Vorhersage mit tatsächlichen rope_release-Werten\n",
    "    predicted_current = model.predict(grouped_df)\n",
    "\n",
    "    # Vorhersage, wenn rope_release = rope_mean gesetzt wird\n",
    "    df_mean_rope = grouped_df.copy()\n",
    "    df_mean_rope[\"rope_release\"] = rope_mean\n",
    "    predicted_mean = model.predict(df_mean_rope)\n",
    "\n",
    "    # Angepasste Werte berechnen:\n",
    "    actual = grouped_df[var].values\n",
    "    adjusted = actual + (predicted_mean - predicted_current)\n",
    "    grouped_adjusted_df[var] = adjusted"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_adjusted_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Latex Tabelle Output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DataFrame mit den relevanten Spalten erstellen\n",
    "variables_latex = [\n",
    "    'm_amplitude', \n",
    "    'm_amplitude_2',\n",
    "    'initial_amplitude',\n",
    "    'damping_coeff', \n",
    "    'damping_ratio', \n",
    "    'frequency_damped', \n",
    "    'frequency_undamped',\n",
    "    'pearson_r',\n",
    "    'nmae'\n",
    "]\n",
    "df_latex = grouped_adjusted_df[variables_latex + ['treatment']].copy()\n",
    "df_latex.columns"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Spaltennamen entsprechend der LaTeX-Notation umbenennen\n",
    "df_latex.rename(columns=data_dict, inplace=True)\n",
    "\n",
    "# Erstellung deskriptiver Statistiken für alle Beobachtungen\n",
    "overall_stats = df_latex.describe().drop(index=['count', '25%', '75%'])\n",
    "overall_stats.rename(index={'50%': 'median'}, inplace=True)\n",
    "\n",
    "# Erstellung der deskriptiven Statistiken für jede Gruppe\n",
    "grouped_stats = {\n",
    "    'overall': overall_stats\n",
    "}\n",
    "\n",
    "for treatment, group in df_latex.groupby('treatment', observed=True):\n",
    "    group_stats = group.describe().drop(index=['count', '25%', '75%'])\n",
    "    group_stats.rename(index={'50%': 'median'}, inplace=True)\n",
    "    grouped_stats[treatment] = group_stats\n",
    "\n",
    "# Zusammenführen der Statistiken in einer Tabelle\n",
    "combined_stats = pd.concat(grouped_stats, names=['Treatment'])\n",
    "\n",
    "# LaTeX-Export des kombinierten DataFrames\n",
    "df_latex_string = combined_stats.to_latex(\n",
    "    escape=False,\n",
    "    multirow=True,\n",
    "    multicolumn=True,\n",
    "    column_format=\"l|lrrrrrrrrr\", \n",
    "    float_format=\"{:0.2f}\".format\n",
    ")\n",
    "\n",
    "# LaTeX-Tabellencode erstellen\n",
    "latex_table = f\"\"\"\n",
    "\\\\begin{{table}}[h]\n",
    "    \\\\centering\n",
    "    \\\\caption{{Feldversuch 2 - Ergebnisse, Schwingungsparameter deskriptive Statistiken (Gesamt und gruppiert über Treatment), Amplituden korrigiert über \\\\texttt{{rope\\\\_release}}, 9 Beobachtung je Gruppe, jeweils Mittelwert für 4 Elastometer}}\n",
    "    \\\\begin{{adjustbox}}{{max width=\\\\textwidth}}\n",
    "    {df_latex_string}\n",
    "    \\\\end{{adjustbox}}\n",
    "    \\\\label{{tab:Feldversuch_2_Deskriptive_Statistiken_Schwingungsparameter}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualisierung der bereinigten Ergebnisse\n",
    "\n",
    "Abschließend werden die bereinigten Werte grafisch dargestellt, um die Unterschiede zwischen den Behandlungen in Abwesenheit des `rope_release`-Einflusses zu verdeutlichen. Dies zeigt, wie sich die Treatments auf die Parameter auswirken würden, wenn für alle Einheiten die gleiche mittlere Vorspannung gelten würde."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "relevant_vars_rope_release = ['m_amplitude', 'm_amplitude_2', 'max_strain', 'max_compression']\n",
    "\n",
    "n_vars = len(relevant_vars_rope_release)\n",
    "n_cols = 2  # Links Original, rechts angepasst\n",
    "n_rows = n_vars  # Eine Zeile pro Variable\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "\n",
    "for i, var in enumerate(relevant_vars_rope_release):\n",
    "    # Linke Spalte: Original (grouped_df)\n",
    "    sns.boxplot(ax=axes[i,0], x=\"treatment\", y=var, data=grouped_df, \n",
    "                palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i,0], x=\"treatment\", y=var, data=grouped_df, \n",
    "                  dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i,0].set_title(f\"original: {var}\")\n",
    "    axes[i,0].set_ylabel(var)\n",
    "\n",
    "    # Rechte Spalte: Angepasst (grouped_adjusted_df)\n",
    "    sns.boxplot(ax=axes[i,1], x=\"treatment\", y=var, data=grouped_adjusted_df, \n",
    "                palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i,1], x=\"treatment\", y=var, data=grouped_adjusted_df, \n",
    "                  dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i,1].set_title(f\"adjusted : {var}\")\n",
    "    axes[i,1].set_ylabel(var)\n",
    "    \n",
    "    # Y-Limits von links holen\n",
    "    y_min, y_max = axes[i,0].get_ylim()\n",
    "    # Y-Limits auf rechts anwenden\n",
    "    axes[i,1].set_ylim(y_min, y_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_comparison\", subdir=\"combined\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Schritt 2: Durchführung von Post-hoc-Tests\n",
    "\n",
    "Festzustellen welche paarweisen Unterschiede zwischen den Treatments signifikant sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Wir gehen davon aus, dass grouped_adjusted_df existiert und die Spalten 'treatment' sowie die Variablen aus 'variables' enthält.\n",
    "\n",
    "for var in variables_spec:\n",
    "    # Tukey HSD Test durchführen\n",
    "    # Annahme: Die Spalte 'treatment' enthält die Gruppennamen z.B. 'free', 'gefa_dynamic', 'cobra_static'\n",
    "    # pairwise_tukeyhsd benötigt die abhängige Variable und die Gruppen.\n",
    "    tukey_results = pairwise_tukeyhsd(endog=grouped_adjusted_df[var],\n",
    "                                      groups=grouped_adjusted_df['treatment'],\n",
    "                                      alpha=0.05)\n",
    "    \n",
    "    print(f\"--- Post-Hoc Test (Tukey HSD) für Variable: {var} ---\")\n",
    "    print(tukey_results.summary())\n",
    "    print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables_spec), 2, (len(variables_spec) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables_spec):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_without_rope_release\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables_spec), 2, (len(variables_spec) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables_spec):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_without_rope_release_spec\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vorhergesagte Werte extrahieren und Boxplots für die Sensoren erstellen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Vorhergesagte Werte aus den Modellen extrahieren\n",
    "for variable in variables:\n",
    "    df[f'predicted_{variable}'] = models[variable].fittedvalues\n",
    "\n",
    "# Boxplots erstellen mit den vorhergesagten Werten\n",
    "fig, axes = plt.subplots(4, 2, figsize=(8, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    sns.boxplot(ax=axes[i], x='treatment', y=f'predicted_{variable}', data=df, palette=treatment_color_dict, hue='treatment', dodge=False, legend=False)\n",
    "    axes[i].set_title(f'{variable} by Treatment')\n",
    "    axes[i].set_xlabel('Treatment')\n",
    "    axes[i].set_ylabel(f'Predicted {variable}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"predicted_effect_for_treatment\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def annotate_tukey(ax, tukey_result, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Fügt eine Textbox mit den Tukey-Test-Ergebnissen und dem festgelegten Signifikanzniveau in den Plot ein.\n",
    "    \n",
    "    Parameters:\n",
    "    ax (matplotlib.axes): Die Achse, auf der der Plot gezeichnet wird.\n",
    "    tukey_result (TukeyHSDResults): Die Ergebnisse des Tukey HSD Tests.\n",
    "    significance_level (float): Das Signifikanzniveau, standardmäßig 0.05.\n",
    "    \"\"\"\n",
    "    # Definiere die gewünschte Reihenfolge der Vergleiche\n",
    "    comparisons_order = [('free', 'gefa_dynamic'), ('free', 'cobra_static'), ('gefa_dynamic', 'cobra_static')]\n",
    "\n",
    "    # Text für die Annotation zusammenstellen\n",
    "    text_str = f\"Tukey HSD Results: \\n(Significance level = {significance_level:.2f})\\n\\n\"\n",
    "    \n",
    "    # Durchlaufe die gewünschte Vergleichsreihenfolge\n",
    "    for group1, group2 in comparisons_order:\n",
    "        # Filtere die korrekte Paarung aus den Tukey-Ergebnissen\n",
    "        for i in range(len(tukey_result._results_table.data[1:])):\n",
    "            pair = tukey_result._results_table.data[i + 1]\n",
    "            if (pair[0] == group1 and pair[1] == group2) or (pair[0] == group2 and pair[1] == group1):\n",
    "                p_value = tukey_result.pvalues[i]\n",
    "                significance = \"*\" if p_value < significance_level else \"n.s.\"\n",
    "                text_str += f\"\\n{group1} vs {group2}: \\np = {p_value:.4f} ({significance})\\n\\n\"\n",
    "    \n",
    "    # Textbox am Rand des Plots hinzufügen\n",
    "    ax.annotate(text_str, xy=(1.01, 0.1), xycoords='axes fraction', va='center', ha='left')\n",
    "\n",
    "# Einzelne Plots für jede Variable erstellen und speichern\n",
    "for variable in variables:\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    # Boxplot für die aktuelle Variable\n",
    "    sns.boxplot(ax=ax, x='treatment', y=f'predicted_{variable}', data=df, \n",
    "                palette=treatment_color_dict, hue='treatment', dodge=False, legend=False)\n",
    "    \n",
    "    # Tukey-Test für die aktuelle Variable\n",
    "    tukey_result = tukey_results[variable]\n",
    "    \n",
    "    # Tukey-Ergebnisse annotieren\n",
    "    annotate_tukey(ax, tukey_result)\n",
    "    \n",
    "    ax.set_title(f'{variable} by Treatment')\n",
    "    ax.set_xlabel('Treatment')\n",
    "    ax.set_ylabel(f'Predicted {variable}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot speichern\n",
    "    plot_filename = f\"{variable}_effect_for_treatment\"\n",
    "    PLOT_MANAGER.save_plot(fig, filename=plot_filename, subdir=\"osc_variables_box\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames nach 'treatment' und Entfernen unnötiger Spalten\n",
    "df_treatment_describe = (df.drop(['id', 'ptq_sensor_name'], axis=1)\n",
    "                         .groupby('treatment', observed=True)\n",
    "                         .describe())\n",
    "\n",
    "df_treatment_describe = df_treatment_describe.reset_index()\n",
    "df_treatment_describe.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames nach 'treatment' und Entfernen unnötiger Spalten\n",
    "df_sensor = (df.drop(['id', 'release_force_target', 'ls3_rope_release', 'ls3_cable_max', 'location', 'height', 'diameter', 'direction'], axis=1).\n",
    "             groupby(['treatment', 'ptq_sensor_name'], observed=True).\n",
    "             mean())  #.T\n",
    "#df_sensor.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames und Anwenden von mean für ptq_sensor_name \n",
    "df_id = ((df.drop(['ptq_sensor_name', 'location', 'height', 'diameter', 'direction'], axis=1)\n",
    "          .groupby(['treatment', 'id'], observed=True)\n",
    "          .mean())\n",
    "         .reset_index())\n",
    "\n",
    "df_id.round(4).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zusammenhangsanalyse für LS3 und PTQ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Auswahl der neuen Spaltennamen für die Korrelationsmatrix\n",
    "columns_corr = ['ptq_m_amplitude',\n",
    "                'ptq_m_amplitude_2',\n",
    "                'ptq_initial_amplitude',\n",
    "                'ptq_damping_coeff',\n",
    "                'ptq_angular_frequency',\n",
    "                'ptq_y_shift',\n",
    "                'ptq_pearson_r',\n",
    "                #'ptq_nrmse',\n",
    "                'ptq_nmae',\n",
    "                'release_force_target',\n",
    "                'ls3_rope_release',\n",
    "                'ls3_cable_max']\n",
    "df_corr = df_id.copy()[columns_corr]\n",
    "\n",
    "# Berechnung der Korrelationsmatrix\n",
    "correlation_matrix = df_corr.corr()\n",
    "\n",
    "# Visualisierung der Korrelationsmatrix mit Seaborn\n",
    "fig1, ax = plt.subplots(figsize=(8, 8))  # Anpassen der Größe der Grafik\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', ax=ax, annot_kws={'size': 10})\n",
    "\n",
    "# Titel und Schriftgrößen anpassen\n",
    "#plt.title('Correlation Matrix for LS3 and PTQ', fontsize=18)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=12, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize=12, rotation=45, ha='right')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig1, filename=\"correlation_matrix\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# ANOVA für 'ls3_rope_release'\n",
    "model_rope_release = smf.ols('ls3_rope_release ~ treatment', data=df_id).fit()\n",
    "anova_rope_release = sm.stats.anova_lm(model_rope_release, typ=2)\n",
    "\n",
    "# ANOVA für 'ls3_cable_max'\n",
    "model_cable_max = smf.ols('ls3_cable_max ~ treatment', data=df_id).fit()\n",
    "anova_cable_max = sm.stats.anova_lm(model_cable_max, typ=2)\n",
    "\n",
    "# Zusammenfassungen der Modelle\n",
    "summary_rope_release = model_rope_release.summary()\n",
    "summary_cable_max = model_cable_max.summary()\n",
    "# Zusammenfassungen der Modelle\n",
    "summary_rope_release_latex = model_rope_release.summary().as_latex()\n",
    "summary_cable_max_latex = model_cable_max.summary().as_latex()\n",
    "\n",
    "#print(summary_rope_release_latex)\n",
    "#print(summary_cable_max_latex)\n",
    "\n",
    "anova_rope_release, summary_rope_release, anova_cable_max, summary_cable_max"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Zusammenhang Vorspannung und resultierende Lastspitzen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ptq_m_amplitude'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ptq_m_amplitude', data=subset, ax=ax1, color=color, label=treatment,\n",
    "                ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ptq_m_amplitude'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Elongation Amplitude')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Elongation Amplitude [$\\mu$m] (mean for all Sensors)')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"ls3_release_force_vs_ptq_m_amplitude\", subdir=\"combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ptq_m_amplitude_2'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ptq_m_amplitude_2', data=subset, ax=ax1, color=color, label=treatment,\n",
    "                ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ptq_m_amplitude_2'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Elongation Amplitude 2')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Elongation Amplitude 2 [$\\mu$m] (mean for all Sensors)')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"ls3_release_force_vs_ptq_m_amplitude_2\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Durchführung des ANOVA-Tests und Berechnung der Effektstärke (Eta Squared)\n",
    "def perform_anova_and_effect_size(df: pd.DataFrame, variable: str, treatments: List[str]) -> str:\n",
    "    groups = [df[df['treatment'] == treatment][variable].dropna() for treatment in treatments]\n",
    "    f_stat, p_value = f_oneway(*groups)\n",
    "\n",
    "    # Berechnung der Effektstärke (Eta Squared)\n",
    "    n = sum([len(g) for g in groups])\n",
    "    ss_total = sum([(x - df[variable].mean()) ** 2 for g in groups for x in g])\n",
    "    eta_squared = f_stat * len(groups) / (f_stat * len(groups) + (n - len(groups)))\n",
    "\n",
    "    # Überprüfung der Signifikanz\n",
    "    significance = \"*\" if p_value < 0.05 else \"\"\n",
    "\n",
    "    return f\"{variable}: {significance}\\nF-statistic = {f_stat:.2f}\\np-value = {p_value:.2e}\\nEta Squared = {eta_squared:.2f}\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung von Boxplots\n",
    "def create_boxplot(df: pd.DataFrame, variable: str, group_by: str, ax: plt.Axes, color_dict: Dict[str, str], perform_stats: bool) -> None:\n",
    "    valid_df = df.dropna(subset=[variable])\n",
    "    sns.boxplot(x=group_by, y=variable, hue=group_by, data=valid_df, ax=ax, palette=color_dict, dodge=False)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.axis('off')\n",
    "    if perform_stats:\n",
    "        stats_text = perform_anova_and_effect_size(valid_df, variable, valid_df[group_by].unique())\n",
    "        ax2.annotate(stats_text, xy=(1.01, 0.1), xycoords='axes fraction')\n",
    "    ax.set_title(f'Einfluss von {group_by} auf {variable}')\n",
    "    ax.set_xlabel(group_by)\n",
    "    ax.set_ylabel(variable)\n",
    "\n",
    "# Funktion zur Erstellung kombinierter Plots\n",
    "def create_combined_plot(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], num_columns: int = 3, perform_stats: bool = False) -> None:\n",
    "    num_rows = len(columns) // num_columns + (len(columns) % num_columns > 0)\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(16, 4 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, variable in enumerate(columns):\n",
    "        create_boxplot(df, variable, group_by, axes[idx], color_dict, perform_stats)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"combined_plot_{group_by}\", subdir=\"combined\")\n",
    "\n",
    "# Funktion zur Erstellung einzelner Plots\n",
    "def create_individual_plots(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], perform_stats: bool = False) -> None:\n",
    "    for variable in columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        create_boxplot(df, variable, group_by, ax, color_dict, perform_stats)\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        PLOT_MANAGER.save_plot(fig, filename=f\"{group_by}_{variable}\", subdir=\"individual_plots\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "columns = ['ptq_m_amplitude',\n",
    "           'ptq_m_amplitude_2',\n",
    "           'ptq_initial_amplitude',\n",
    "           'ptq_damping_coeff',\n",
    "           'ptq_angular_frequency',\n",
    "           'ptq_y_shift',\n",
    "           'ptq_pearson_r',\n",
    "           #'ptq_nrmse',\n",
    "           #'ptq_nmae',\n",
    "           #'release_force_target',\n",
    "           'ls3_rope_release',\n",
    "           'ls3_cable_max'\n",
    "           ]\n",
    "\n",
    "# Beispiel: Erstellen von Plots gruppiert nach 'treatment'\n",
    "create_combined_plot(df, columns, 'treatment', treatment_color_dict, perform_stats=True)\n",
    "create_individual_plots(df, columns, 'treatment', treatment_color_dict, perform_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Beispiel: Erstellen von Plots gruppiert nach 'ptq_sensor_name'\n",
    "columns = ['ptq_m_amplitude', 'ptq_m_amplitude_2', 'ptq_initial_amplitude', 'ptq_damping_coeff', 'ptq_angular_frequency', 'ptq_pearson_r']\n",
    "\n",
    "create_combined_plot(df, columns, 'ptq_sensor_name', sensor_color_dict)\n",
    "create_individual_plots(df, columns, 'ptq_sensor_name', sensor_color_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
