{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"2023_Kronensicherung_Plesse_Combined_Analyse\"\n",
    "author: \"Kyell Jensen\"\n",
    "date: \"2024-08-06\"\n",
    "format: pdf\n",
    "editor: visual\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2023_Kronensicherung_Plesse_Combined_Analyse\n",
    "\n",
    "## Kombinierte Analyse LineScale3, TreeQinetic und Versuchsaufzeichung\n",
    "\n",
    "Nutze eine geeignete Python 3.11 Umgebung (z. B. virtuelle Environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Arbeitsumgebung vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### IMPORT: Importieren von Standardbibliotheken\n",
    "\n",
    "Die folgenden Bibliotheken werden importiert, um grundlegende Funktionen für Strukturierung, Datenverarbeitung, Plotting und statistische Auswertung bereit zu stellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.557549600Z",
     "start_time": "2025-03-28T12:55:07.223235100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Struktur\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "# Datenverarbeitung\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from slugify import slugify  # Slugify ums strings in standard Formate zu überführen\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistik\n",
    "from scipy.stats import linregress, f_oneway\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.multicomp as mc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORT: Importiere eigene Packete (hier nur für Plotter und Logger)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from kj_core.utils.latex_export import (\n",
    "    save_latex_table,\n",
    "    build_data_dict_df\n",
    ")\n",
    "\n",
    "from kj_core.utils.labeling import get_label_from_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.573135600Z",
     "start_time": "2025-03-28T12:55:07.598008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from kj_core import CoreConfig, PlotManager, get_logger"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.604426500Z",
     "start_time": "2025-03-28T12:55:08.010352200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Importiere alle Einstellungen aus der project_config.py\n",
    "from project_config import (\n",
    "    working_directory,\n",
    "    data_export_directory,\n",
    "    latex_export_directory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.604426500Z",
     "start_time": "2025-03-28T12:55:08.015678400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "CONFIG = CoreConfig(working_directory=f\"{working_directory}/combined\")\n",
    "PLOT_MANAGER = PlotManager(CONFIG)\n",
    "# CONFIG\n",
    "# PLOT_MANAGER"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.604426500Z",
     "start_time": "2025-03-28T12:55:08.028786600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## IMPORT: Daten Import\n",
    "\n",
    "Lege Pfade für Daten-Importe, Daten-Exporte etc. fest (ggf. anpassen an eigene Verzeichnisstruktur), ausgelagert in gemeinsame Config für verschiedene Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "filename_dataset = \"_dataset_clean.feather\"\n",
    "filename_data_dict = \"_data_dict_clean.json\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.604426500Z",
     "start_time": "2025-03-28T12:55:08.034274900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Dateien laden\n",
    "df = pd.read_feather(data_export_directory / filename_dataset)\n",
    "\n",
    "with open(data_export_directory / filename_data_dict, \"r\", encoding=\"utf-8\") as f:\n",
    "    data_dict = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.604426500Z",
     "start_time": "2025-03-28T12:55:08.034274900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ANALYSE: Explorative Datenanalyse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|    | Variable                | Kategorie       | Zeichen                           | Deutsch                              | Datentyp   | Einheit   | Beschreibung                                                              |\n|----|-------------------------|-----------------|-----------------------------------|--------------------------------------|------------|-----------|---------------------------------------------------------------------------|\n|  0 | id                      | ptq             | ID                                | ID Messung                           | int64      | -         | Eindeutige ID der Messung                                                 |\n|  1 | rope_datetime           | ls3             | $t$                               | Zeitstempel                          | object     | -         | Startzeitpunkt der Messung laut Gerät                                     |\n|  2 | treatment               | series          | treatment                         | Behandlungsvariante                  | category   | -         | Art der KS: \\texttt{free}, \\texttt{gefa\\_dynamic}, \\texttt{cobra\\_static} |\n|  3 | release_force_target    | series          | $F_{\\mathrm{release,target}}$     | Vorspannkraft Soll                   | float64    | kN        | Geplante Vorspannkraft im Zugseil bei Release                             |\n|  4 | rope_release            | ls3             | $F_{\\mathrm{release}}$            | Vorspannkraft Ist                    | float64    | kN        | Tatsächlich realisierte Vorspannkraft im Zugseil bei Release              |\n|  5 | cable_max               | ls3             | $F_{\\mathrm{cable, max}}$         | Kraftspitze KS                       | object     | kN        | Maximale gemessene Kraftspitze in der KS                                  |\n|  6 | sensor_name             | ptq             | sensor                            | Sensorname                           | object     | -         | Bezeichnung des Elastometers                                              |\n|  7 | location                | sensor_position | location                          | Position                             | string     | -         | Position des Sensors am Stamm                                             |\n|  8 | direction               | sensor_position | direction                         | Richtung                             | string     | -         | Zug- oder Druckseite                                                      |\n|  9 | height                  | sensor_position | $h$                               | Höhe                                 | Float64    | m         | Höhe des Sensors am Stamm                                                 |\n| 10 | diameter                | sensor_position | $d$                               | Durchmesser                          | Float64    | cm        | Durchmesser des Stammes                                                   |\n| 11 | max_strain              | ptq             | $\\Delta l_{\\mathrm{max}}$         | Dehnung max. gemessen                | float64    | $\\mu$m    | Gemessene maximale absolute Randfaserdehnung                              |\n| 12 | max_compression         | ptq             | $\\Delta l_{\\mathrm{comp,max}}$    | Stauchung max. gemessen              | float64    | $\\mu$m    | Gemessene maximale absolute Randfaserstauchung                            |\n| 13 | m_amplitude             | ptq_osc         | $mA$                              | Manuelle Amplitude                   | float64    | $\\mu$m    | Manuell berechnete Amplitude über den Schwingungsabschnitt                |\n| 14 | m_amplitude_2           | ptq_osc         | $mA_2$                            | Manuelle Amplitude 2                 | float64    | $\\mu$m    | Manuell berechnete Amplitude zwischen 2. Peak und Minimum                 |\n| 15 | initial_amplitude       | ptq_osc         | $A$                               | Anfangsamplitude                     | float64    | $\\mu$m    | Initiale Amplitude der angepassten Schwingung                             |\n| 16 | damping_coeff           | ptq_osc         | $\\delta$                          | Dämpfungskoeffizient                 | float64    | 1/s       | Koeffizient der exponentiellen Dämpfung                                   |\n| 17 | frequency_damped        | ptq_osc         | $f_{\\mathrm{d}}$                  | Gedämpfte Frequenz                   | float64    | Hz        | Frequenz der gedämpften Schwingung                                        |\n| 18 | phase_angle             | ptq_osc         | $\\varphi$                         | Phasenwinkel                         | float64    | rad       | Anfangsphase der Schwingung                                               |\n| 19 | y_shift                 | ptq_osc         | $y_0$                             | Vertikaler Versatz                   | float64    | $\\mu$m    | Vertikaler Offset der Schwingung                                          |\n| 20 | x_shift                 | ptq_osc         | $t_0$                             | Zeitverschiebung                     | float64    | s         | Horizontale Verschiebung der Schwingung                                   |\n| 21 | frequency_undamped      | ptq_osc         | $f_0$                             | Ungedämpfte Frequenz                 | float64    | Hz        | Frequenz der ungedämpften Schwingung                                      |\n| 22 | damping_ratio           | ptq_osc         | $D$                               | Dämpfungsgrad                        | float64    | -         | Verhältnis von Dämpfung zu Frequenz                                       |\n| 23 | metrics_warning         | ptq_osc         | warning                           | Fit-Warnung                          | bool       | -         | Warnung, wenn Qualitätsmetrik Schwellenwerte unterschreitet               |\n| 24 | pearson_r               | ptq_osc_metric  | $r$                               | Pearson-Korrelation                  | float64    | -         | Korrelationskoeffizient der Anpassung                                     |\n| 25 | nrmse                   | ptq_osc_metric  | $\\mathrm{NRMSE}$                  | Normalisierter RMSE                  | float64    | -         | Normalisierter mittlerer quadratischer Fehler                             |\n| 26 | nmae                    | ptq_osc_metric  | $\\mathrm{NMAE}$                   | Normalisierter MAE                   | float64    | -         | Normalisierter mittlerer absoluter Fehler                                 |\n| 27 | calc_max_strain         | calc_strain     | $\\varepsilon_{\\mathrm{calc,max}}$ | Dehnung max. berechnet               | float64    | $\\mu$m    | Berechnete maximale Randfaserdehnung                                      |\n| 28 | calc_max_strain_relativ | calc_strain     | $\\varepsilon_{\\mathrm{calc,rel}}$ | Berechnete maximale Randfaserdehnung | float64    | $\\mu$m    | Differenz gemessene und berechnete maximale Randfaserdehnung              |\n| 29 | strain_difference       | calc_strain     | $\\Delta \\varepsilon$              | Differenz der Faserdehnung           | float64    | \\%        | Relative Differenz der berechneten und gemessenen max. Dehnung            |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In DataFrame umwandeln\n",
    "data_dict_df= build_data_dict_df(data_dict)\n",
    "\n",
    "# In Markdown umwandeln und anzeigen\n",
    "md_text = data_dict_df.to_markdown(tablefmt=\"github\")\n",
    "display(Markdown(md_text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.604426500Z",
     "start_time": "2025-03-28T12:55:08.123221500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "    id       rope_datetime treatment  release_force_target  rope_release  \\\n4    2 2022-03-23 11:24:23      free                   2.8       2.72310   \n5    2 2022-03-23 11:24:23      free                   2.8       2.72310   \n6    2 2022-03-23 11:24:23      free                   2.8       2.72310   \n7    2 2022-03-23 11:24:23      free                   2.8       2.72310   \n8    3 2022-03-23 11:31:12      free                   2.8       2.76205   \n9    3 2022-03-23 11:31:12      free                   2.8       2.76205   \n10   3 2022-03-23 11:31:12      free                   2.8       2.76205   \n11   3 2022-03-23 11:31:12      free                   2.8       2.76205   \n12   4 2022-03-23 11:54:33      free                   2.8       2.73950   \n13   4 2022-03-23 11:54:33      free                   2.8       2.73950   \n\n    cable_max sensor_name location   direction  height  ...  frequency_damped  \\\n4         NaN  Elasto(90)      StB  elongation   16.55  ...          0.441518   \n5         NaN  Elasto(92)      StB  elongation    11.6  ...          0.432441   \n6         NaN  Elasto(95)      StA  elongation    11.6  ...          0.422702   \n7         NaN  Elasto(98)      StA  elongation   16.85  ...          0.443529   \n8         NaN  Elasto(90)      StB  elongation   16.55  ...          0.440654   \n9         NaN  Elasto(92)      StB  elongation    11.6  ...          0.439249   \n10        NaN  Elasto(95)      StA  elongation    11.6  ...          0.436023   \n11        NaN  Elasto(98)      StA  elongation   16.85  ...          0.441350   \n12        NaN  Elasto(90)      StB  elongation   16.55  ...          0.439065   \n13        NaN  Elasto(92)      StB  elongation    11.6  ...          0.436850   \n\n    phase_angle    y_shift   x_shift  frequency_undamped  damping_ratio  \\\n4      0.200000  -5.287164  0.116641            0.442936       0.503994   \n5     -0.200000 -14.233643 -0.009730            0.436601       0.873595   \n6     -0.200000 -19.011253 -0.123043            0.426319       0.823806   \n7     -0.065967  -1.099515  0.118608            0.445993       0.663224   \n8      0.200000   7.775263  0.097887            0.441317       0.344954   \n9     -0.200000   7.070001  0.049121            0.441269       0.603287   \n10    -0.200000  -3.785755 -0.075741            0.438127       0.618021   \n11    -0.200000 -17.747289 -0.203345            0.442888       0.525070   \n12     0.200000 -23.445975  0.120929            0.439764       0.354677   \n13    -0.200000 -19.454721  0.061912            0.438829       0.598701   \n\n    metrics_warning  pearson_r     nrmse      nmae  \n4             False   0.943158  0.038866  0.018011  \n5             False   0.929554  0.034560  0.016183  \n6             False   0.908058  0.044873  0.024274  \n7             False   0.980663  0.029621  0.021087  \n8             False   0.957381  0.043035  0.018619  \n9             False   0.932950  0.043734  0.021138  \n10            False   0.938307  0.039020  0.022498  \n11            False   0.974139  0.028693  0.020715  \n12            False   0.945320  0.049764  0.021509  \n13            False   0.922665  0.050822  0.020659  \n\n[10 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rope_datetime</th>\n      <th>treatment</th>\n      <th>release_force_target</th>\n      <th>rope_release</th>\n      <th>cable_max</th>\n      <th>sensor_name</th>\n      <th>location</th>\n      <th>direction</th>\n      <th>height</th>\n      <th>...</th>\n      <th>frequency_damped</th>\n      <th>phase_angle</th>\n      <th>y_shift</th>\n      <th>x_shift</th>\n      <th>frequency_undamped</th>\n      <th>damping_ratio</th>\n      <th>metrics_warning</th>\n      <th>pearson_r</th>\n      <th>nrmse</th>\n      <th>nmae</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2022-03-23 11:24:23</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.72310</td>\n      <td>NaN</td>\n      <td>Elasto(90)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>16.55</td>\n      <td>...</td>\n      <td>0.441518</td>\n      <td>0.200000</td>\n      <td>-5.287164</td>\n      <td>0.116641</td>\n      <td>0.442936</td>\n      <td>0.503994</td>\n      <td>False</td>\n      <td>0.943158</td>\n      <td>0.038866</td>\n      <td>0.018011</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>2022-03-23 11:24:23</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.72310</td>\n      <td>NaN</td>\n      <td>Elasto(92)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.432441</td>\n      <td>-0.200000</td>\n      <td>-14.233643</td>\n      <td>-0.009730</td>\n      <td>0.436601</td>\n      <td>0.873595</td>\n      <td>False</td>\n      <td>0.929554</td>\n      <td>0.034560</td>\n      <td>0.016183</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>2022-03-23 11:24:23</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.72310</td>\n      <td>NaN</td>\n      <td>Elasto(95)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.422702</td>\n      <td>-0.200000</td>\n      <td>-19.011253</td>\n      <td>-0.123043</td>\n      <td>0.426319</td>\n      <td>0.823806</td>\n      <td>False</td>\n      <td>0.908058</td>\n      <td>0.044873</td>\n      <td>0.024274</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>2022-03-23 11:24:23</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.72310</td>\n      <td>NaN</td>\n      <td>Elasto(98)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>16.85</td>\n      <td>...</td>\n      <td>0.443529</td>\n      <td>-0.065967</td>\n      <td>-1.099515</td>\n      <td>0.118608</td>\n      <td>0.445993</td>\n      <td>0.663224</td>\n      <td>False</td>\n      <td>0.980663</td>\n      <td>0.029621</td>\n      <td>0.021087</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>2022-03-23 11:31:12</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.76205</td>\n      <td>NaN</td>\n      <td>Elasto(90)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>16.55</td>\n      <td>...</td>\n      <td>0.440654</td>\n      <td>0.200000</td>\n      <td>7.775263</td>\n      <td>0.097887</td>\n      <td>0.441317</td>\n      <td>0.344954</td>\n      <td>False</td>\n      <td>0.957381</td>\n      <td>0.043035</td>\n      <td>0.018619</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>2022-03-23 11:31:12</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.76205</td>\n      <td>NaN</td>\n      <td>Elasto(92)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.439249</td>\n      <td>-0.200000</td>\n      <td>7.070001</td>\n      <td>0.049121</td>\n      <td>0.441269</td>\n      <td>0.603287</td>\n      <td>False</td>\n      <td>0.932950</td>\n      <td>0.043734</td>\n      <td>0.021138</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>2022-03-23 11:31:12</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.76205</td>\n      <td>NaN</td>\n      <td>Elasto(95)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.436023</td>\n      <td>-0.200000</td>\n      <td>-3.785755</td>\n      <td>-0.075741</td>\n      <td>0.438127</td>\n      <td>0.618021</td>\n      <td>False</td>\n      <td>0.938307</td>\n      <td>0.039020</td>\n      <td>0.022498</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>2022-03-23 11:31:12</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.76205</td>\n      <td>NaN</td>\n      <td>Elasto(98)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>16.85</td>\n      <td>...</td>\n      <td>0.441350</td>\n      <td>-0.200000</td>\n      <td>-17.747289</td>\n      <td>-0.203345</td>\n      <td>0.442888</td>\n      <td>0.525070</td>\n      <td>False</td>\n      <td>0.974139</td>\n      <td>0.028693</td>\n      <td>0.020715</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4</td>\n      <td>2022-03-23 11:54:33</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.73950</td>\n      <td>NaN</td>\n      <td>Elasto(90)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>16.55</td>\n      <td>...</td>\n      <td>0.439065</td>\n      <td>0.200000</td>\n      <td>-23.445975</td>\n      <td>0.120929</td>\n      <td>0.439764</td>\n      <td>0.354677</td>\n      <td>False</td>\n      <td>0.945320</td>\n      <td>0.049764</td>\n      <td>0.021509</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4</td>\n      <td>2022-03-23 11:54:33</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.73950</td>\n      <td>NaN</td>\n      <td>Elasto(92)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.436850</td>\n      <td>-0.200000</td>\n      <td>-19.454721</td>\n      <td>0.061912</td>\n      <td>0.438829</td>\n      <td>0.598701</td>\n      <td>False</td>\n      <td>0.922665</td>\n      <td>0.050822</td>\n      <td>0.020659</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.604426500Z",
     "start_time": "2025-03-28T12:55:08.125071400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'rope_datetime', 'treatment', 'release_force_target',\n       'rope_release', 'cable_max', 'sensor_name', 'location', 'direction',\n       'height', 'diameter', 'max_strain', 'max_compression', 'm_amplitude',\n       'm_amplitude_2', 'initial_amplitude', 'damping_coeff',\n       'frequency_damped', 'phase_angle', 'y_shift', 'x_shift',\n       'frequency_undamped', 'damping_ratio', 'metrics_warning', 'pearson_r',\n       'nrmse', 'nmae'],\n      dtype='object')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.604426500Z",
     "start_time": "2025-03-28T12:55:08.162970400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined: Definition von Darstellungsstandards\n",
    "Festlegen von Farbcodes für einheitliche Darstellung von Sensoren und Behandlungsvarianten für alle nachfolgenden Plots."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['free', 'gefa_dynamic', 'cobra_static'], dtype='object')\n",
      "Index(['Elasto(90)', 'Elasto(92)', 'Elasto(95)', 'Elasto(98)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "treatment_order = df[\"treatment\"].cat.categories\n",
    "sensor_name_order = df[\"sensor_name\"].cat.categories\n",
    "print(treatment_order)\n",
    "print(sensor_name_order)\n",
    "\n",
    "color_palette = PLOT_MANAGER.color_palette\n",
    "\n",
    "# Zuweisen von Farben aus der Palette an die Sensoren\n",
    "sensor_color_dict = {sensor: color for sensor, color in zip(sensor_name_order, color_palette[:len(sensor_name_order)])}\n",
    "\n",
    "# Zuweisen von Farben aus der Palette an die Treatments\n",
    "treatment_color_dict = {treatment: color for treatment, color in zip(treatment_order, color_palette[:len(treatment_order)])}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:08.604426500Z",
     "start_time": "2025-03-28T12:55:08.162970400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LS3: Analyse Spitzenlasten in der KS\n",
    "\n",
    "Analyse der Spitzenlasten in der KS gruppiert nach Ziel-Vorspannung und Treatment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Daten filtern\n",
    "filtered_df = df.query('treatment in [\"gefa_dynamic\", \"cobra_static\"]')[[\"release_force_target\", \"treatment\", \"cable_max\"]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:10.470549600Z",
     "start_time": "2025-03-28T12:55:10.379983300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "release_force_target  2.00                  2.40              2.80            \\\n                       min      mean   max   min  mean   max   min      mean   \ntreatment                                                                      \ngefa_dynamic          1.01  1.063333  1.15  1.01  1.11  1.16  1.33  1.416667   \ncobra_static          2.30  2.330000  2.36  2.76  2.80  2.84  2.59  2.906667   \n\nrelease_force_target        \n                       max  \ntreatment                   \ngefa_dynamic          1.48  \ncobra_static          3.09  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>release_force_target</th>\n      <th colspan=\"3\" halign=\"left\">2.00</th>\n      <th colspan=\"3\" halign=\"left\">2.40</th>\n      <th colspan=\"3\" halign=\"left\">2.80</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>min</th>\n      <th>mean</th>\n      <th>max</th>\n      <th>min</th>\n      <th>mean</th>\n      <th>max</th>\n      <th>min</th>\n      <th>mean</th>\n      <th>max</th>\n    </tr>\n    <tr>\n      <th>treatment</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>gefa_dynamic</th>\n      <td>1.01</td>\n      <td>1.063333</td>\n      <td>1.15</td>\n      <td>1.01</td>\n      <td>1.11</td>\n      <td>1.16</td>\n      <td>1.33</td>\n      <td>1.416667</td>\n      <td>1.48</td>\n    </tr>\n    <tr>\n      <th>cobra_static</th>\n      <td>2.30</td>\n      <td>2.330000</td>\n      <td>2.36</td>\n      <td>2.76</td>\n      <td>2.80</td>\n      <td>2.84</td>\n      <td>2.59</td>\n      <td>2.906667</td>\n      <td>3.09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gruppieren, Aggregieren und Pivotieren\n",
    "pivoted = (\n",
    "    filtered_df\n",
    "    .groupby(['release_force_target', 'treatment'], observed=True)['cable_max']\n",
    "    .agg(['min', 'mean', 'max'])\n",
    "    .unstack(level=0)\n",
    "    .swaplevel(axis=1)\n",
    "    .sort_index(axis=1, level=[0, 1], ascending=[True, False])\n",
    ")\n",
    "\n",
    "# Spaltennamen formatieren (Index Level 0: zwei Nachkommastellen)\n",
    "pivoted.columns = pd.MultiIndex.from_tuples(\n",
    "    [(f\"{lvl0:.2f}\", lvl1) if isinstance(lvl0, float) else (lvl0, lvl1)\n",
    "     for lvl0, lvl1 in pivoted.columns],\n",
    "    names=pivoted.columns.names\n",
    ")\n",
    "pivoted"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:26.492538200Z",
     "start_time": "2025-03-28T12:55:26.347276500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Achsenbeschriftungen setzen\n",
    "pivoted.columns.set_names(\n",
    "    [get_label_from_dict(\"release_force_target\", data_dict, template=\"{Zeichen}\"), None],\n",
    "    inplace=True\n",
    ")\n",
    "pivoted.index.set_names(\n",
    "    get_label_from_dict(\"treatment\", data_dict),\n",
    "    inplace=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:55:36.775082600Z",
     "start_time": "2025-03-28T12:55:36.653975500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content saved to: C:\\kyellsen\\005_Projekte\\2024_BA\\032_Feldversuch_2023_Plesse\\030_Analysen\\2023_Kronensicherung_Plesse_Kraefte_Schwingungen\\working_directory\\export_latex\\feldversuch_2_ergebnisse_kraftspitze_in_der_ks.tex\n"
     ]
    }
   ],
   "source": [
    "latex_string = pivoted.to_latex(index=True, escape=True, float_format=\"{:0.2f}\".format, column_format=\"l|rrr|rrr|rrr\", multicolumn=True,\n",
    "    multicolumn_format=\"c\")\n",
    "\n",
    "# Beschriftung erstellen\n",
    "caption = \"Feldversuch 2 - Ergebnisse, Kraftspitze in der KS\"\n",
    "caption_long = (\n",
    "    f\"Feldversuch 2 - {get_label_from_dict('cable_max', data_dict, full=True)} \"\n",
    "    f\"gruppiert über {get_label_from_dict('release_force_target', data_dict, full=True)} und \"\n",
    "    f\"{get_label_from_dict('treatment', data_dict)}. \"\n",
    "    f\"Angegeben ist jeweils pro Gruppe das Minimum, der Mittelwert und das Maximum. \"\n",
    "    f\"Die Variante 'free' ist nicht aufgeführt, da hier keine KS eingesetzt wurde.\"\n",
    ")\n",
    "\n",
    "# LaTeX-Tabelle speichern\n",
    "save_latex_table(latex_string, caption, latex_export_directory, caption_long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:56:13.118417900Z",
     "start_time": "2025-03-28T12:56:12.894776300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filtern der Einträge mit dem maximalen Wert in 'cable_max'\n",
    "max_cable_max = df['cable_max'].max()\n",
    "filtered_df = df[df['cable_max'] == max_cable_max]\n",
    "\n",
    "# Innerhalb der gefilterten Einträge den maximalen 'max_strain' finden\n",
    "max_value_row = filtered_df.loc[filtered_df['max_strain'].idxmax()]\n",
    "#max_value_row"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Liste der gewünschten Spalten in der gewünschten Reihenfolge\n",
    "columns_to_display = [\n",
    "    'id', 'treatment', 'release_force_target', 'rope_release', \n",
    "    'cable_max', 'sensor_name', 'max_strain', 'max_compression'\n",
    "]\n",
    "\n",
    "# Zeile auf die gewünschten Spalten in der angegebenen Reihenfolge beschränken\n",
    "max_value_row_filtered = max_value_row[columns_to_display]\n",
    "\n",
    "max_value_row_filtered['treatment'] = slugify(max_value_row_filtered['treatment'])\n",
    "\n",
    "# Erstelle ein DataFrame mit den zusätzlichen Informationen aus `data_dict`\n",
    "expanded_data = []\n",
    "for col in columns_to_display:\n",
    "    expanded_data.append({\n",
    "        \"Zeichen\": data_dict[col][\"Zeichen\"],\n",
    "        \"Deutsch\": data_dict[col][\"Deutsch\"],\n",
    "        \"Wert\": max_value_row_filtered[col],\n",
    "        \"Einheit\": data_dict[col][\"Einheit\"],\n",
    "    })\n",
    "\n",
    "# Neues DataFrame erstellen\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "\n",
    "# LaTeX-String erstellen\n",
    "latex_string = expanded_df.to_latex(\n",
    "    index=False, \n",
    "    escape=False, \n",
    "    column_format=\"llrr\",  # Spaltenformat angepasst\n",
    "    float_format=\"{:0.2f}\".format\n",
    ")\n",
    "\n",
    "# LaTeX-Tabelle mit Beschriftung versehen\n",
    "caption = \"Feldversuch 2 - Ergebnisse, Werte der Messung mit Spitzenlast\"\n",
    "caption_long = \"Feldversuch 2 - Ergebnisse, Messung mit der höchsten Last in der KS (nur maximale Messwerte des Elastometers mit der höchsten Faserdehnung)\"\n",
    "\n",
    "# Funktion zum Speichern aufrufen (angenommen save_latex_table ist definiert)\n",
    "save_latex_table(latex_string, caption, latex_export_directory, caption_long)\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "expanded_df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined: Vergleichende Berechnung der Randfaserdehnung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Berechnung der Randfaserdehnung (in Dezimalschreibweise)\n",
    "def calculate_epsilon(force: float, H: float, h: float, d: float, E: float) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet die Randfaserdehnung epsilon (dimensionslos, nicht in %).\n",
    "    \n",
    "    Parameters:\n",
    "        force (float): Zugkraft im Seil (in kN)\n",
    "        H (float): Höhe des Angriffspunktes der Zugkraft über dem Stammfuß (in m)\n",
    "        h (float): Höhe des Berechnungspunktes über dem Boden (in m)\n",
    "        d (float): Durchmesser des Stammquerschnitts auf Höhe h (in m)\n",
    "        E (float): Elastizitätsmodul des Holzes (in MPa)\n",
    "    \n",
    "    Returns:\n",
    "        float: Berechnete Randfaserdehnung epsilon (dimensionslos)\n",
    "    \"\"\"\n",
    "    force_N = force * 1000  # Umrechnung der Zugkraft von kN in N\n",
    "    M = force_N * (H - h)  # Biegemoment in N·m\n",
    "    y_max = d / 2  # maximaler Abstand zur neutralen Achse in m\n",
    "    I = (np.pi / 64) * d**4  # Flächenträgheitsmoment in m^4\n",
    "    E_Pa = E * 1e6  # Umrechnung des Elastizitätsmoduls von MPa in N/m^2\n",
    "    epsilon = (M * y_max) / (E_Pa * I)  # Dehnung in Dezimalschreibweise\n",
    "    return epsilon\n",
    "\n",
    "# Funktion zur Berechnung der absoluten Längenänderung\n",
    "def calculate_delta_l(epsilon: float, l0: float) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet die absolute Längenänderung Delta L in Mikrometer.\n",
    "    \n",
    "    Parameters:\n",
    "        epsilon (float): Relative Dehnung (dimensionslos)\n",
    "        l0 (float): Ausgangslänge des Elastometers (in mm)\n",
    "    \n",
    "    Returns:\n",
    "        float: Absolute Längenänderung Delta L in Mikrometer (µm)\n",
    "    \"\"\"\n",
    "    l0_m = l0 / 1000  # Umrechnung der Ausgangslänge von mm in m\n",
    "    delta_L = epsilon * l0_m * 1e6  # Umrechnung der Längenänderung in µm\n",
    "    return delta_L\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fixwerte\n",
    "l0 = 200  # mm, Ausgangslänge Elastometer\n",
    "E = 8500  # Elastizitätsmodul Buche in MPa\n",
    "height_rope = 18.30  # m, Höhe des Angriffspunktes der Zugkraft\n",
    "\n",
    "# Berechnung der neuen Spalten\n",
    "df['calc_max_strain_relativ'] = df.apply(lambda row: calculate_epsilon(\n",
    "    row['rope_release'], height_rope, row['height'], row['diameter'], E), axis=1)\n",
    "df['calc_max_strain'] = df['calc_max_strain_relativ'].apply(lambda epsilon: calculate_delta_l(epsilon, l0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Berechnung der Differenz und der absoluten Differenz in Prozent\n",
    "df['strain_difference'] = (df['calc_max_strain'] - df['max_strain']) / df['max_strain'] * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grouping DataFrame by 'ptq_sensor_name'\n",
    "grouped = df.groupby('sensor_name')\n",
    "\n",
    "# Perform linear regression and plot for each group\n",
    "for name, group in grouped:\n",
    "    # Linear Regression with statsmodels\n",
    "    X = sm.add_constant(group['max_strain'])  # Adding a constant for the intercept\n",
    "    y = group['calc_max_strain']\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    # Print the summary of the linear regression model\n",
    "    print(f\"Linear Regression Summary for {name}:\\n\")\n",
    "    print(model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Achsenvariablen definieren\n",
    "x_key = 'max_strain'\n",
    "y_key = 'calc_max_strain'\n",
    "\n",
    "# Dynamische Labels und Titel erzeugen\n",
    "x_label = get_axis_label(x_key, data_dict)\n",
    "y_label = get_axis_label(y_key, data_dict)\n",
    "plot_title = get_plot_title(x_key, y_key, data_dict, prefix=\"Regression\")\n",
    "filename = get_filename(x_key, y_key, prefix=\"regression\")\n",
    "legend_title = get_legend_title(\"sensor_name\", data_dict)\n",
    "\n",
    "# Plot erstellen\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, group in df.groupby('sensor_name', observed=False):\n",
    "    sns.regplot(\n",
    "        x=group[x_key],\n",
    "        y=group[y_key],\n",
    "        color=sensor_color_dict.get(name, \"gray\"),\n",
    "        label=name,\n",
    "        scatter_kws={\"s\": 40}\n",
    "    )\n",
    "\n",
    "plt.title(plot_title)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.legend(title=legend_title)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot speichern\n",
    "PLOT_MANAGER.save_plot(fig, filename=filename, subdir=\"measured_vs_calc_strain\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Berechnung von Mittelwerten und Standardabweichungen\n",
    "df_strain_stats = df.groupby('sensor_name').agg(\n",
    "    calc_max_strain_mean=('calc_max_strain', 'mean'),\n",
    "    calc_max_strain_sd=('calc_max_strain', 'std'),\n",
    "    ptq_max_strain_mean=('max_strain', 'mean'),\n",
    "    ptq_max_strain_sd=('max_strain', 'std'),\n",
    "    strain_difference_mean=('strain_difference', 'mean'),\n",
    "    strain_difference_sd=('strain_difference', 'std')\n",
    ")\n",
    "# Automatische Umbenennung der Spalten basierend auf data_dict\n",
    "columns_new = [(data_dict[var]['Zeichen'], stat) for var, stat in zip(\n",
    "    ['calc_max_strain', 'calc_max_strain', 'max_strain', 'max_strain', 'strain_difference', 'strain_difference'],\n",
    "    ['mean', 'sd', 'mean', 'sd', 'mean', 'sd']\n",
    ")]\n",
    "df_strain_stats.columns = pd.MultiIndex.from_tuples(columns_new)\n",
    "df_strain_stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Berechnung des MAPE\n",
    "strain_difference_mape = df['strain_difference'].abs().mean().round(2)\n",
    "strain_difference_mape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Automatische Einheitenzuweisung\n",
    "df_units = pd.DataFrame([[data_dict[var]['Einheit'] for var in ['calc_max_strain', 'calc_max_strain', 'max_strain', 'max_strain', 'strain_difference', 'strain_difference']]],\n",
    "                        columns=df_strain_stats.columns, index=['Einheit'])\n",
    "\n",
    "# MAPE als eigene Zeile hinzufügen\n",
    "df_mape = pd.DataFrame([['', '', '', '', strain_difference_mape, '']], \n",
    "                        columns=df_strain_stats.columns, index=['MAPE'])\n",
    "\n",
    "# DataFrames zusammenführen\n",
    "df_strain_stats_add = pd.concat([df_units, df_strain_stats, df_mape])\n",
    "df_strain_stats_add"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Konvertierung des DataFrames mit Multi-Index-Spalten in einen LaTeX-String\n",
    "latex_string = df_strain_stats_add.to_latex(\n",
    "    index=True,\n",
    "    escape=False,\n",
    "    float_format=\"{:0.2f}\".format,\n",
    "    multicolumn=True,\n",
    "    multicolumn_format=\"c\",\n",
    "    column_format=\"l|rr|rr|rr\"\n",
    ")\n",
    "\n",
    "# Definition der Beschriftung für die LaTeX-Tabelle\n",
    "caption = \"Feldversuch 2 - Ergebnisse, Zusammenfassung Vergleich gemessene und rechnerische Faserdehnung \"\n",
    "caption_long = \"Feldversuch 2 - Ergebnisse, Zusammenfassung Vergleich gemessene und rechnerische Faserdehnung, Mittelwerte und Standardabweichungen der Abweichung der rechnerischen von der gemessenen maximalen Dehnung, gruppiert über Elastometer bzw. Position\"\n",
    "\n",
    "save_latex_table(latex_string, caption, latex_export_directory, caption_long)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create violin plot for strain_difference grouped by sensor_name\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='sensor_name', y='strain_difference', hue='sensor_name', palette=sensor_color_dict, data=df)\n",
    "plt.title('Difference between measured and calculated strain')\n",
    "plt.xlabel('PTQ Sensor Name / Position')\n",
    "plt.ylabel('Strain Difference (%)')\n",
    "# Layout anpassen und Plot anzeigen\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"diff_measured_vs_calc_strain\", subdir=\"measured_vs_calc_strain\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Theoretische Berechnungen der Belastung der KS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_force(epsilon: float, H: float, h: float, d: float, E: float) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet die Zugkraft force (in kN) basierend auf der Randfaserdehnung epsilon bzw. der Dehnung an der Elastizitätsgrenze.\n",
    "    \n",
    "    Parameters:\n",
    "        epsilon (float): Randfaserdehnung (dimensionslos, nicht in %)\n",
    "        H (float): Höhe des Angriffspunktes der Zugkraft über dem Stammfuß (m)\n",
    "        h (float): Höhe des Berechnungspunktes über dem Boden (m)\n",
    "        d (float): Durchmesser des Stammquerschnitts auf Höhe h (m)\n",
    "        E (float): Elastizitätsmodul des Holzes (in MPa)\n",
    "    \n",
    "    Returns:\n",
    "        float: Berechnete Zugkraft force (in kN)\n",
    "    \"\"\"\n",
    "    y_max = d / 2  # maximaler Abstand zur neutralen Achse in m\n",
    "    I = (np.pi / 64) * d**4  # Flächenträgheitsmoment in m^4\n",
    "    E_Pa = E * 1e6  # Umrechnung des Elastizitätsmoduls von MPa in N/m^2\n",
    "    force_N = (epsilon * E_Pa * I) / ((H - h) * y_max)  # Zugkraft in N\n",
    "    force_kN = force_N / 1000  # Umrechnung in kN\n",
    "    return force_kN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fixwerte\n",
    "epsilon = 0.0026  # Elastizitätsgrenze Buche\n",
    "E = 8500  # Elastizitätsmodul Buche in MPa\n",
    "height_ks = 17.40  # m, Höhe des Angriffspunktes der KS\n",
    "height_forke = 10.31  # m, Höhe des Zwiesels\n",
    "stem_diameter = 0.35  # m, Durchmesser des Stammes knapp über dem Zwiesel\n",
    "\n",
    "# Berechnung der Zugkraft\n",
    "force = calculate_force(epsilon, height_ks, height_forke, stem_diameter, E)\n",
    "force"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_height = (26.15 + 27.2)/2\n",
    "optimal_ks_height = ((tree_height - height_forke) * (2/3)) + height_forke\n",
    "optimal_ks_height"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "force = calculate_force(epsilon, optimal_ks_height, height_forke, stem_diameter, E)\n",
    "force"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PTQ: Analyse der Dehnungswerte nach Elastometer und Behandlungsvarianten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotten der Maximalwerte der Vorspannung für Dehnung und Stauchung. Für jede Messung werden erst die maximalen Werte berechnet und dann getrennt nach Elasto die Verteilung im Boxplot dargestellt.\n",
    "Auffällig ist Elasto(90) mit den höchsten Dehnungswerten. Dieses Gerät ist am geringfügig dünneren Stämmling angebracht. Die Vorspannung wurde aufgrund der maximalen Messwerte von 429 µm nicht weiter erhöht."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Erstelle die Subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Boxplot für die minimalen Werte (maximale Compression)\n",
    "sns.boxplot(data=df, x='sensor_name', y='max_compression', hue='sensor_name', palette=sensor_color_dict, ax=axs[0], legend=False)\n",
    "axs[0].set_title(\"Maximum Compression per Elasto\")\n",
    "axs[0].set_xlabel(\"Elasto Name\")\n",
    "axs[0].set_ylabel(\"fiber compression [µm]\")\n",
    "\n",
    "# Boxplot für die maximalen Werte (maximale Strain)\n",
    "sns.boxplot(data=df, x='sensor_name', y='max_strain', hue='sensor_name', palette=sensor_color_dict, ax=axs[1], legend=False)\n",
    "axs[1].set_title(\"Maximum Strain per Elasto\")\n",
    "axs[1].set_xlabel(\"Elasto Name\")\n",
    "axs[1].set_ylabel(\"fiber strain [µm]\")\n",
    "\n",
    "# Layout anpassen und Plot anzeigen\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"strain_max_per_elasto\", subdir=\"strain_max_per_elasto\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Mixed-Effects Model\n",
    "# model = smf.mixedlm(\n",
    "#     \"max_compression ~ C(treatment) + C(sensor_name) + rope_release\",\n",
    "#     data=df,\n",
    "#     groups=df[\"id\"]  # Gruppierung nach Beobachtungsgruppe\n",
    "# ).fit()\n",
    "# \n",
    "# # Ergebnisse\n",
    "# print(model.summary())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Tukey HSD Test für die 'treatment' Gruppe\n",
    "# tukey_treatment = mc.pairwise_tukeyhsd(endog=df['max_compression'],\n",
    "#                                     groups=df['treatment'],\n",
    "#                                     alpha=0.05)\n",
    "# print(tukey_treatment)\n",
    "# \n",
    "# # Tukey HSD Test für die 'sensor_name' Gruppe\n",
    "# tukey_sensor = mc.pairwise_tukeyhsd(endog=df['max_compression'],\n",
    "#                                  groups=df['sensor_name'],\n",
    "#                                  alpha=0.05)\n",
    "# print(tukey_sensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined: Latex-Export von Daten für Anhang"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_grouped_latex_tables(df_latex: pd.DataFrame, caption: str, column_format: str, group_by: str, latex_export_directory: Path) -> None:\n",
    "    \"\"\"\n",
    "    Generate grouped LaTeX tables for each unique value in a specified column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df_latex (pd.DataFrame): The DataFrame with already formatted columns.\n",
    "        caption (str): The caption for the LaTeX tables.\n",
    "        column_format (str): The format for the LaTeX tables.\n",
    "        group_by (str): The column name to group by.\n",
    "        latex_export_directory (Path): The directory to save the LaTeX tables.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # DataFrame grouped by specified column\n",
    "        grouped = df_latex.groupby(group_by, observed=True)\n",
    "\n",
    "        # LaTeX tables to be combined in a single file\n",
    "        combined_tables = []\n",
    "\n",
    "        for group, group_df in grouped:\n",
    "            # Drop the group_by column\n",
    "            group_df = group_df.drop(columns=[group_by])\n",
    "\n",
    "            # Format 'id' column as string if it exists\n",
    "            if 'id' in group_df.columns:\n",
    "                group_df['id'] = group_df['id'].astype(str)\n",
    "\n",
    "            # Calculate statistics\n",
    "            mean_row = group_df.mean(numeric_only=True).rename('Mean')\n",
    "            median_row = group_df.median(numeric_only=True).rename('Median')\n",
    "            sd_row = group_df.std(numeric_only=True).rename('SD')\n",
    "\n",
    "            # Combine stats with original DataFrame\n",
    "            stats_df = pd.concat([group_df, mean_row.to_frame().T, median_row.to_frame().T, sd_row.to_frame().T])\n",
    "\n",
    "            # Generate LaTeX string from DataFrame\n",
    "            df_latex_string = stats_df.to_latex(\n",
    "                index=True,\n",
    "                escape=False,\n",
    "                column_format=column_format,\n",
    "                float_format=\"{:0.2f}\".format\n",
    "            )\n",
    "\n",
    "            # Create caption and label for the group\n",
    "            caption_text = create_caption(caption, f\"{caption} für {slugify(group, separator=' ')}\")\n",
    "            label_clean = create_label(caption=caption, additional_label=group)\n",
    "\n",
    "            # Generate LaTeX table\n",
    "            latex_table = generate_latex_table(df_latex_string, caption_text, label_clean)\n",
    "\n",
    "            combined_tables.append(latex_table)\n",
    "\n",
    "        # Combine all tables and save to a single file\n",
    "        if combined_tables:\n",
    "            final_output = \"\\n\\n\".join(combined_tables)\n",
    "            file_name = create_label(caption) + \".tex\"\n",
    "            save_to_file(final_output, latex_export_directory / file_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating grouped LaTeX tables: {e}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Liste der benötigten Variablen\n",
    "variables = [\"id\", \"treatment\", \"sensor_name\", \"location\", \"height\", \"diameter\", \"rope_release\", \"max_strain\", \"calc_max_strain\", \"strain_difference\"]\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Vergleich gemessene und rechnerische Faserdehnung\",\n",
    "    column_format=\"lll|lrrr|rrr\",\n",
    "    group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variables = ['id', 'sensor_name', 'treatment', 'release_force_target', 'rope_release', 'cable_max', 'max_strain', 'max_compression',]\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Kräfte und Dehnungen\",\n",
    "    column_format=\"lrl|rrr|rr\",\n",
    "        group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variables_2 = ['id', 'sensor_name', 'treatment', 'm_amplitude', 'm_amplitude_2', 'initial_amplitude', 'damping_coeff', 'damping_ratio', 'frequency_damped', 'frequency_undamped', 'y_shift', 'pearson_r', 'nmae']\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables_2]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables_2})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Schwingungsparameter\",\n",
    "    column_format=\"lrl|rrr|rr|rr|r|rr\",\n",
    "    group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PTQ: Analyse der Schwingungsparameter\n",
    "\n",
    "In diesem Abschnitt werden die Schwingungsparameter statistisch ausgewertet. Ziel ist es, den Einfluss verschiedener Behandlungsvarianten (treatment) auf die gemessenen Schwingungsparameter zu untersuchen und dabei auch den potenziellen Einfluss der Vorspannung (rope_release) und Sensorposition (sensor_name) zu berücksichtigen.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'm_amplitude', \n",
    "    'm_amplitude_2',\n",
    "    'max_strain',\n",
    "    'max_compression',\n",
    "    'initial_amplitude',\n",
    "    'damping_coeff', \n",
    "    'damping_ratio', \n",
    "    'frequency_damped', \n",
    "    'frequency_undamped',\n",
    "    'pearson_r',\n",
    "    #'nrmse', \n",
    "    'nmae'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Systematischer Einfluss der Sensorposition\n",
    "\n",
    "Ziel: Visuell erkennen, ob unterschiedliche Sensoren konsistent andere Werte liefern und ob dieser Effekt die Interpretation der treatment-Effekte erschwert."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "for var in variables:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"sensor_name\", y=var, data=df, hue=\"treatment\", palette=treatment_color_dict,  dodge=True)\n",
    "    # Stripplot: Punkte zur Veranschaulichung der Verteilung\n",
    "    sns.stripplot(x=\"sensor_name\", y=var, data=df, hue=\"treatment\", palette=treatment_color_dict, dodge=True, alpha=1, jitter=True, size=5, legend=False)\n",
    "    # Titel und Achsentitel setzen\n",
    "    plt.title(f\"Einfluss von treatment auf {var} gruppiert über sensor_name\")\n",
    "    plt.xlabel(\"Sensor Name\")\n",
    "    plt.ylabel(var)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_sensor_treatment_{var}\", subdir=\"combined/sensor\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Systematischer Einfluss der Behandlungsvariante\n",
    "\n",
    "Ziel: Feststellen, ob die Variation durch unterschiedliche Behandlungen relativ zur sensorbedingten Variation unterscheidbar ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "for var in variables:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"treatment\", y=var, data=df, palette=sensor_color_dict, hue='sensor_name')\n",
    "    sns.stripplot(x=\"treatment\", y=var, data=df, palette=sensor_color_dict, hue='sensor_name', dodge=True, alpha=1, jitter=True, size=5, legend=False)\n",
    "    plt.title(f\"Einfluss von sensor_name auf {var} gruppiert über treatment\")\n",
    "    plt.xlabel(\"treatment\")\n",
    "    plt.ylabel(var)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_treatment_sensor_{var}\", subdir=\"combined/treatment\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Versuche Mixed-Linear Model\n",
    "Die Daten sind hierarchisch: Mehrere Messungen (vier Sensoren) pro Beobachtungseinheit (`id`). Ein Mixed-Effects Modell könnte diese Struktur abbilden, indem zufällige Effekte für `id` und feste Effekte für `treatment` sowie `sensor_name` genutzt werden. Zusätzlich könnte `rope_release` als Kovariate eingeführt werden.\n",
    "\n",
    "Diese Modelle wären theoretisch präziser, aber aufgrund der geringen Stichprobengröße und der komplexen Datenstruktur treten Konvergenzprobleme auf.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ergebnisse als Dictionary speichern\n",
    "results_dict = {}\n",
    "\n",
    "for var in variables:\n",
    "    # Formel für MixedLM: Parameter ~ C(treatment) + C(sensor_name) + rope_release + (1|id)\n",
    "    formula = f\"{var} ~ C(treatment) + C(sensor_name)\" #  +  rope_release\n",
    "    model = smf.mixedlm(formula, data=df, groups=df[\"id\"])\n",
    "    \n",
    "    # Modell fitten\n",
    "    fit = model.fit(reml=True)  # REML ist Standard für gemischte Modelle\n",
    "    \n",
    "    # Ergebnisse ausgeben\n",
    "    print(f\"\\n### Ergebnisse für {var} ###\")\n",
    "    print(fit.summary())\n",
    "    \n",
    "    # Überprüfen, ob das Modell konvergiert ist\n",
    "    if not fit.converged:\n",
    "        print(\"Achtung: Das Modell ist nicht konvergiert. Erwägen Sie Anpassungen (z.B. Skalierung der Daten).\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vereinfachtes Vorgehen durch Aggregation (Mittelung über Sensoren)\n",
    "\n",
    "Um dennoch aussagekräftige Aussagen zu erhalten, werden die Messungen pro `id` über alle Sensoren gemittelt. Dadurch geht zwar die Variation aufgrund unterschiedlicher Sensoren verloren, aber es entsteht ein stabileres Datenset, in dem jede `id` einen aggregierten Wert pro Parameter hat.\n",
    "\n",
    "Auf dieser Basis können einfache OLS-Modelle geschätzt werden, z. B. `Parameter ~ C(treatment) + rope_release`. Diese Modelle sind einfacher und sollten stabil konvergieren."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Placeholder for results\n",
    "results = {}\n",
    "\n",
    "# Step 1: Compute the mean of each variable for each id\n",
    "grouped_df = df.groupby(\"id\").agg(\n",
    "    {var: \"mean\" for var in variables}\n",
    ").reset_index()\n",
    "\n",
    "# Add additional variables (e.g., treatment and rope_release) to the aggregated data\n",
    "grouped_df = grouped_df.merge(\n",
    "    df[[\"id\", \"treatment\", \"rope_release\"]].drop_duplicates(), on=\"id\"\n",
    ")\n",
    "\n",
    "# Step 2: Fit linear models to the aggregated data\n",
    "for var in variables:\n",
    "    try:\n",
    "        # Fit a linear model\n",
    "        model = smf.ols(f\"{var} ~ C(treatment) + rope_release\", grouped_df).fit()\n",
    "\n",
    "        # Store relevant results\n",
    "        results[var] = {\n",
    "            \"p_value_treatment\": model.pvalues.get(\"treatment[T.statisch]\", None),\n",
    "            \"p_value_rope_release\": model.pvalues.get(\"rope_release\", None),\n",
    "            \"summary\": model.summary()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        results[var] = {\"error\": str(e)}\n",
    "\n",
    "# Display results\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nicht jeder Parameter wird durch `rope_release` beeinflusst. Nur für jene Parameter, bei denen ein signifikanter Einfluss von `rope_release` festgestellt wird, soll dieser Effekt herausgerechnet werden. Auf diese Weise entstehen \"bereinigte\" Werte, in denen der lineare Einfluss von `rope_release` entfernt ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Placeholder for results\n",
    "# Dieses Dictionary wird nun sowohl die Modellobjekte als auch die Kennwerte speichern.\n",
    "results = {}\n",
    "\n",
    "# Liste der Variablen, für die rope_release berücksichtigt wird\n",
    "relevant_vars_rope_release = ['m_amplitude', 'm_amplitude_2', 'max_strain', 'max_compression']\n",
    "\n",
    "# Step 1: Compute the mean of each variable for each id\n",
    "grouped_df = df.groupby(\"id\").agg(\n",
    "    {var: \"mean\" for var in variables}\n",
    ").reset_index()\n",
    "\n",
    "# Add additional variables (e.g., treatment and rope_release) to the aggregated data\n",
    "grouped_df = grouped_df.merge(\n",
    "    df[[\"id\", \"treatment\", \"rope_release\"]].drop_duplicates(), on=\"id\"\n",
    ")\n",
    "\n",
    "# Step 2: Fit linear models to the aggregated data and store model objects and p-Werte in results\n",
    "for var in variables:\n",
    "    # Formuliere das Modell dynamisch, abhängig davon, ob rope_release relevant ist\n",
    "    if var in relevant_vars_rope_release:\n",
    "        formula = f\"{var} ~ C(treatment) + rope_release\"\n",
    "    else:\n",
    "        formula = f\"{var} ~ C(treatment)\"\n",
    "\n",
    "    try:\n",
    "        # Fit a linear model\n",
    "        model = smf.ols(formula, grouped_df).fit()\n",
    "\n",
    "        # Store model and relevant results directly in results\n",
    "        results[var] = {\n",
    "            \"model\": model,\n",
    "            \"p_value_treatment\": model.pvalues.get(\"treatment[T.statisch]\", None),\n",
    "            \"p_value_rope_release\": model.pvalues.get(\"rope_release\", None) if var in relevant_vars_rope_release else None,\n",
    "            \"summary\": model.summary()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        results[var] = {\"error\": str(e)}\n",
    "\n",
    "# Display results\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Beispiel für m_amplitude\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=grouped_df, x='rope_release', y='m_amplitude_2', hue='treatment', ci=95)\n",
    "plt.title('Einfluss von rope_release auf m_amplitude für verschiedene Treatments')\n",
    "plt.xlabel('rope_release (kN)')\n",
    "plt.ylabel('m_amplitude')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=grouped_df, x='treatment', y='m_amplitude')\n",
    "plt.title('Vergleich von m_amplitude zwischen den Treatments')\n",
    "plt.xlabel('Treatment')\n",
    "plt.ylabel('m_amplitude')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "\n",
    "# Liste der Variablen, die in die Tabelle übernommen werden sollen\n",
    "variables_spec = [\n",
    "    'm_amplitude_2',\n",
    "    'max_compression',\n",
    "    'damping_coeff',\n",
    "    'damping_ratio',\n",
    "    'frequency_damped',\n",
    "    'frequency_undamped',\n",
    "]\n",
    "\n",
    "# Umbenennung der Spalten für LaTeX-Notation\n",
    "column_rename_map = {\n",
    "    'm_amplitude_2': r'$mA_2$',\n",
    "    'max_compression': r'$\\text{max\\_C}$',\n",
    "    'damping_coeff': r'$\\delta$',\n",
    "    'damping_ratio': r'$D$',\n",
    "    'frequency_damped': r'$f_d$',\n",
    "    'frequency_undamped': r'$f_0$',\n",
    "}\n",
    "\n",
    "# Funktion zur Erstellung der Modellgüte-Kennzahlen für alle Variablen\n",
    "def create_model_metrics_table(variables, results):\n",
    "    metrics_data = {\n",
    "        \"Kennzahl\": [\"R²\", \"Adj. R²\", \"F-St.\", \"AIC\", \"N\"]\n",
    "    }\n",
    "\n",
    "    for var in variables:\n",
    "        col_name = column_rename_map.get(var, var)  # Verwende gekürzten Namen, falls vorhanden\n",
    "        if var not in results or 'error' in results[var]:\n",
    "            metrics_data[col_name] = [\"n/a\"] * 5\n",
    "        else:\n",
    "            model = results[var]['model']\n",
    "            metrics_data[col_name] = [\n",
    "                f\"{model.rsquared:.4f}\",\n",
    "                f\"{model.rsquared_adj:.4f}\",\n",
    "                f\"{model.fvalue:.4f}\",\n",
    "                f\"{model.aic:.4f}\",\n",
    "                f\"{model.nobs:.0f}\"\n",
    "            ]\n",
    "\n",
    "    # Erstelle die Tabelle mit tabulate\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    return tabulate(\n",
    "        metrics_df,\n",
    "        headers=\"keys\",\n",
    "        tablefmt=\"latex_raw\",\n",
    "        floatfmt=\".4f\",\n",
    "        showindex=False)\n",
    "\n",
    "# Funktion zur Erstellung einer LaTeX-Tabelle für die Koeffizienten einer Variable\n",
    "def create_latex_table_for_variable(var, results):\n",
    "    if var not in results:\n",
    "        return f\"%% Keine Ergebnisse für Variable {var} vorhanden.\"\n",
    "    \n",
    "    model_result = results[var]\n",
    "    if 'error' in model_result:\n",
    "        return f\"%% Fehler beim Anpassen des Modells für {var}: {model_result['error']}\"\n",
    "    \n",
    "    model = model_result['model']\n",
    "    summary = model.summary2().tables[1]  # Zugriff auf die Tabelle der Koeffizienten\n",
    "\n",
    "    # Erstelle eine LaTeX-Tabelle mit tabulate für die Koeffizienten\n",
    "    latex_table = tabulate(\n",
    "        summary,\n",
    "        headers=summary.columns,\n",
    "        tablefmt=\"latex_booktabs\",\n",
    "        floatfmt=\".4f\",\n",
    "        showindex=True\n",
    "    )\n",
    "\n",
    "    # Escape Unterstriche in der Variable für LaTeX\n",
    "    escaped_var = re.sub(r'_', r'\\_', var)\n",
    "    shortened_var = column_rename_map.get(var, escaped_var)\n",
    "\n",
    "    # Füge die LaTeX-Caption zur Tabelle hinzu\n",
    "    return f\"\"\"\n",
    "\\\\begin{{table}}[ht]\n",
    "    \\\\centering\n",
    "    \\\\caption{{Modellzusammenfassung für {escaped_var} ({shortened_var})}}\n",
    "    \\\\begin{{adjustbox}}{{max width=\\\\textwidth}}\n",
    "    {latex_table}\n",
    "    \\\\end{{adjustbox}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "# Erstelle die Modellgüte-Tabelle für alle Variablen\n",
    "latex_metrics_table = create_model_metrics_table(variables_spec, results)\n",
    "print(\"\"\"\n",
    "\\\\begin{table}[ht]\n",
    "    \\\\centering\n",
    "    \\\\caption{Modellgüte für alle Variablen}\n",
    "    \\\\begin{adjustbox}{max width=\\\\textwidth}\n",
    "\"\"\")\n",
    "print(latex_metrics_table)\n",
    "print(\"\"\"\n",
    "    \\\\end{adjustbox}\n",
    "\\\\end{table}\n",
    "\n",
    "\\\\vspace{1cm}\n",
    "\"\"\")\n",
    "\n",
    "# Erstelle und print die LaTeX-Tabellen für die Koeffizienten jeder Variable\n",
    "for var in variables_spec:\n",
    "    latex_output = create_latex_table_for_variable(var, results)\n",
    "    print(latex_output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables), 2, (len(variables) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_with_rope_release\", subdir=\"combined\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Für die betroffenen Parameter wird der Einfluss von `rope_release` mithilfe der bereits angepassten Modelle (`Parameter ~ C(treatment) + rope_release`) entfernt. Dazu werden Vorhersagen für einen konstanten `rope_release`-Wert (den Mittelwert) berechnet und mit den tatsächlichen Werten verglichen. Die daraus resultierenden bereinigten Werte sind frei von Variation, die auf `rope_release` zurückzuführen wäre."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_adjusted_df = grouped_df.copy()\n",
    "\n",
    "# Bereinigung: Wir setzen rope_release auf seinen Mittelwert\n",
    "rope_mean = grouped_df[\"rope_release\"].mean()\n",
    "\n",
    "for var in relevant_vars_rope_release:\n",
    "    # Zugehöriges Modellobjekt abrufen\n",
    "    model = results[var][\"model\"]\n",
    "\n",
    "    # Vorhersage mit tatsächlichen rope_release-Werten\n",
    "    predicted_current = model.predict(grouped_df)\n",
    "\n",
    "    # Vorhersage, wenn rope_release = rope_mean gesetzt wird\n",
    "    df_mean_rope = grouped_df.copy()\n",
    "    df_mean_rope[\"rope_release\"] = rope_mean\n",
    "    predicted_mean = model.predict(df_mean_rope)\n",
    "\n",
    "    # Angepasste Werte berechnen:\n",
    "    actual = grouped_df[var].values\n",
    "    adjusted = actual + (predicted_mean - predicted_current)\n",
    "    grouped_adjusted_df[var] = adjusted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_adjusted_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Latex Tabelle Output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DataFrame mit den relevanten Spalten erstellen\n",
    "variables_latex = [\n",
    "    'm_amplitude', \n",
    "    'm_amplitude_2',\n",
    "    'initial_amplitude',\n",
    "    'damping_coeff', \n",
    "    'damping_ratio', \n",
    "    'frequency_damped', \n",
    "    'frequency_undamped',\n",
    "    'pearson_r',\n",
    "    'nmae'\n",
    "]\n",
    "df_latex = grouped_adjusted_df[variables_latex + ['treatment']].copy()\n",
    "df_latex.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Spaltennamen entsprechend der LaTeX-Notation umbenennen\n",
    "df_latex.rename(columns=data_dict, inplace=True)\n",
    "\n",
    "# Erstellung deskriptiver Statistiken für alle Beobachtungen\n",
    "overall_stats = df_latex.describe().drop(index=['count', '25%', '75%'])\n",
    "overall_stats.rename(index={'50%': 'median'}, inplace=True)\n",
    "\n",
    "# Erstellung der deskriptiven Statistiken für jede Gruppe\n",
    "grouped_stats = {\n",
    "    'overall': overall_stats\n",
    "}\n",
    "\n",
    "for treatment, group in df_latex.groupby('treatment', observed=True):\n",
    "    group_stats = group.describe().drop(index=['count', '25%', '75%'])\n",
    "    group_stats.rename(index={'50%': 'median'}, inplace=True)\n",
    "    grouped_stats[treatment] = group_stats\n",
    "\n",
    "# Zusammenführen der Statistiken in einer Tabelle\n",
    "combined_stats = pd.concat(grouped_stats, names=['Treatment'])\n",
    "\n",
    "# LaTeX-Export des kombinierten DataFrames\n",
    "df_latex_string = combined_stats.to_latex(\n",
    "    escape=False,\n",
    "    multirow=True,\n",
    "    multicolumn=True,\n",
    "    column_format=\"l|lrrrrrrrrr\", \n",
    "    float_format=\"{:0.2f}\".format\n",
    ")\n",
    "\n",
    "# LaTeX-Tabellencode erstellen\n",
    "latex_table = f\"\"\"\n",
    "\\\\begin{{table}}[h]\n",
    "    \\\\centering\n",
    "    \\\\caption{{Feldversuch 2 - Ergebnisse, Schwingungsparameter deskriptive Statistiken (Gesamt und gruppiert über Treatment), Amplituden korrigiert über \\\\texttt{{rope\\\\_release}}, 9 Beobachtung je Gruppe, jeweils Mittelwert für 4 Elastometer}}\n",
    "    \\\\begin{{adjustbox}}{{max width=\\\\textwidth}}\n",
    "    {df_latex_string}\n",
    "    \\\\end{{adjustbox}}\n",
    "    \\\\label{{tab:Feldversuch_2_Deskriptive_Statistiken_Schwingungsparameter}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualisierung der bereinigten Ergebnisse\n",
    "\n",
    "Abschließend werden die bereinigten Werte grafisch dargestellt, um die Unterschiede zwischen den Behandlungen in Abwesenheit des `rope_release`-Einflusses zu verdeutlichen. Dies zeigt, wie sich die Treatments auf die Parameter auswirken würden, wenn für alle Einheiten die gleiche mittlere Vorspannung gelten würde."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "relevant_vars_rope_release = ['m_amplitude', 'm_amplitude_2', 'max_strain', 'max_compression']\n",
    "\n",
    "n_vars = len(relevant_vars_rope_release)\n",
    "n_cols = 2  # Links Original, rechts angepasst\n",
    "n_rows = n_vars  # Eine Zeile pro Variable\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "\n",
    "for i, var in enumerate(relevant_vars_rope_release):\n",
    "    # Linke Spalte: Original (grouped_df)\n",
    "    sns.boxplot(ax=axes[i,0], x=\"treatment\", y=var, data=grouped_df, \n",
    "                palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i,0], x=\"treatment\", y=var, data=grouped_df, \n",
    "                  dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i,0].set_title(f\"original: {var}\")\n",
    "    axes[i,0].set_ylabel(var)\n",
    "\n",
    "    # Rechte Spalte: Angepasst (grouped_adjusted_df)\n",
    "    sns.boxplot(ax=axes[i,1], x=\"treatment\", y=var, data=grouped_adjusted_df, \n",
    "                palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i,1], x=\"treatment\", y=var, data=grouped_adjusted_df, \n",
    "                  dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i,1].set_title(f\"adjusted : {var}\")\n",
    "    axes[i,1].set_ylabel(var)\n",
    "    \n",
    "    # Y-Limits von links holen\n",
    "    y_min, y_max = axes[i,0].get_ylim()\n",
    "    # Y-Limits auf rechts anwenden\n",
    "    axes[i,1].set_ylim(y_min, y_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_comparison\", subdir=\"combined\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Schritt 2: Durchführung von Post-hoc-Tests\n",
    "\n",
    "Festzustellen welche paarweisen Unterschiede zwischen den Treatments signifikant sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Wir gehen davon aus, dass grouped_adjusted_df existiert und die Spalten 'treatment' sowie die Variablen aus 'variables' enthält.\n",
    "\n",
    "for var in variables_spec:\n",
    "    # Tukey HSD Test durchführen\n",
    "    # Annahme: Die Spalte 'treatment' enthält die Gruppennamen z.B. 'free', 'gefa_dynamic', 'cobra_static'\n",
    "    # pairwise_tukeyhsd benötigt die abhängige Variable und die Gruppen.\n",
    "    tukey_results = pairwise_tukeyhsd(endog=grouped_adjusted_df[var],\n",
    "                                      groups=grouped_adjusted_df['treatment'],\n",
    "                                      alpha=0.05)\n",
    "    \n",
    "    print(f\"--- Post-Hoc Test (Tukey HSD) für Variable: {var} ---\")\n",
    "    print(tukey_results.summary())\n",
    "    print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables_spec), 2, (len(variables_spec) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables_spec):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_without_rope_release\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables_spec), 2, (len(variables_spec) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables_spec):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_without_rope_release_spec\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vorhergesagte Werte extrahieren und Boxplots für die Sensoren erstellen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vorhergesagte Werte aus den Modellen extrahieren\n",
    "for variable in variables:\n",
    "    df[f'predicted_{variable}'] = models[variable].fittedvalues\n",
    "\n",
    "# Boxplots erstellen mit den vorhergesagten Werten\n",
    "fig, axes = plt.subplots(4, 2, figsize=(8, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    sns.boxplot(ax=axes[i], x='treatment', y=f'predicted_{variable}', data=df, palette=treatment_color_dict, hue='treatment', dodge=False, legend=False)\n",
    "    axes[i].set_title(f'{variable} by Treatment')\n",
    "    axes[i].set_xlabel('Treatment')\n",
    "    axes[i].set_ylabel(f'Predicted {variable}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"predicted_effect_for_treatment\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def annotate_tukey(ax, tukey_result, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Fügt eine Textbox mit den Tukey-Test-Ergebnissen und dem festgelegten Signifikanzniveau in den Plot ein.\n",
    "    \n",
    "    Parameters:\n",
    "    ax (matplotlib.axes): Die Achse, auf der der Plot gezeichnet wird.\n",
    "    tukey_result (TukeyHSDResults): Die Ergebnisse des Tukey HSD Tests.\n",
    "    significance_level (float): Das Signifikanzniveau, standardmäßig 0.05.\n",
    "    \"\"\"\n",
    "    # Definiere die gewünschte Reihenfolge der Vergleiche\n",
    "    comparisons_order = [('free', 'gefa_dynamic'), ('free', 'cobra_static'), ('gefa_dynamic', 'cobra_static')]\n",
    "\n",
    "    # Text für die Annotation zusammenstellen\n",
    "    text_str = f\"Tukey HSD Results: \\n(Significance level = {significance_level:.2f})\\n\\n\"\n",
    "    \n",
    "    # Durchlaufe die gewünschte Vergleichsreihenfolge\n",
    "    for group1, group2 in comparisons_order:\n",
    "        # Filtere die korrekte Paarung aus den Tukey-Ergebnissen\n",
    "        for i in range(len(tukey_result._results_table.data[1:])):\n",
    "            pair = tukey_result._results_table.data[i + 1]\n",
    "            if (pair[0] == group1 and pair[1] == group2) or (pair[0] == group2 and pair[1] == group1):\n",
    "                p_value = tukey_result.pvalues[i]\n",
    "                significance = \"*\" if p_value < significance_level else \"n.s.\"\n",
    "                text_str += f\"\\n{group1} vs {group2}: \\np = {p_value:.4f} ({significance})\\n\\n\"\n",
    "    \n",
    "    # Textbox am Rand des Plots hinzufügen\n",
    "    ax.annotate(text_str, xy=(1.01, 0.1), xycoords='axes fraction', va='center', ha='left')\n",
    "\n",
    "# Einzelne Plots für jede Variable erstellen und speichern\n",
    "for variable in variables:\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    # Boxplot für die aktuelle Variable\n",
    "    sns.boxplot(ax=ax, x='treatment', y=f'predicted_{variable}', data=df, \n",
    "                palette=treatment_color_dict, hue='treatment', dodge=False, legend=False)\n",
    "    \n",
    "    # Tukey-Test für die aktuelle Variable\n",
    "    tukey_result = tukey_results[variable]\n",
    "    \n",
    "    # Tukey-Ergebnisse annotieren\n",
    "    annotate_tukey(ax, tukey_result)\n",
    "    \n",
    "    ax.set_title(f'{variable} by Treatment')\n",
    "    ax.set_xlabel('Treatment')\n",
    "    ax.set_ylabel(f'Predicted {variable}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot speichern\n",
    "    plot_filename = f\"{variable}_effect_for_treatment\"\n",
    "    PLOT_MANAGER.save_plot(fig, filename=plot_filename, subdir=\"osc_variables_box\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames nach 'treatment' und Entfernen unnötiger Spalten\n",
    "df_treatment_describe = (df.drop(['id', 'ptq_sensor_name'], axis=1)\n",
    "                         .groupby('treatment', observed=True)\n",
    "                         .describe())\n",
    "\n",
    "df_treatment_describe = df_treatment_describe.reset_index()\n",
    "df_treatment_describe.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames nach 'treatment' und Entfernen unnötiger Spalten\n",
    "df_sensor = (df.drop(['id', 'release_force_target', 'ls3_rope_release', 'ls3_cable_max', 'location', 'height', 'diameter', 'direction'], axis=1).\n",
    "             groupby(['treatment', 'ptq_sensor_name'], observed=True).\n",
    "             mean())  #.T\n",
    "#df_sensor.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames und Anwenden von mean für ptq_sensor_name \n",
    "df_id = ((df.drop(['ptq_sensor_name', 'location', 'height', 'diameter', 'direction'], axis=1)\n",
    "          .groupby(['treatment', 'id'], observed=True)\n",
    "          .mean())\n",
    "         .reset_index())\n",
    "\n",
    "df_id.round(4).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zusammenhangsanalyse für LS3 und PTQ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Auswahl der neuen Spaltennamen für die Korrelationsmatrix\n",
    "columns_corr = ['ptq_m_amplitude',\n",
    "                'ptq_m_amplitude_2',\n",
    "                'ptq_initial_amplitude',\n",
    "                'ptq_damping_coeff',\n",
    "                'ptq_angular_frequency',\n",
    "                'ptq_y_shift',\n",
    "                'ptq_pearson_r',\n",
    "                #'ptq_nrmse',\n",
    "                'ptq_nmae',\n",
    "                'release_force_target',\n",
    "                'ls3_rope_release',\n",
    "                'ls3_cable_max']\n",
    "df_corr = df_id.copy()[columns_corr]\n",
    "\n",
    "# Berechnung der Korrelationsmatrix\n",
    "correlation_matrix = df_corr.corr()\n",
    "\n",
    "# Visualisierung der Korrelationsmatrix mit Seaborn\n",
    "fig1, ax = plt.subplots(figsize=(8, 8))  # Anpassen der Größe der Grafik\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', ax=ax, annot_kws={'size': 10})\n",
    "\n",
    "# Titel und Schriftgrößen anpassen\n",
    "#plt.title('Correlation Matrix for LS3 and PTQ', fontsize=18)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=12, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize=12, rotation=45, ha='right')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig1, filename=\"correlation_matrix\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ANOVA für 'ls3_rope_release'\n",
    "model_rope_release = smf.ols('ls3_rope_release ~ treatment', data=df_id).fit()\n",
    "anova_rope_release = sm.stats.anova_lm(model_rope_release, typ=2)\n",
    "\n",
    "# ANOVA für 'ls3_cable_max'\n",
    "model_cable_max = smf.ols('ls3_cable_max ~ treatment', data=df_id).fit()\n",
    "anova_cable_max = sm.stats.anova_lm(model_cable_max, typ=2)\n",
    "\n",
    "# Zusammenfassungen der Modelle\n",
    "summary_rope_release = model_rope_release.summary()\n",
    "summary_cable_max = model_cable_max.summary()\n",
    "# Zusammenfassungen der Modelle\n",
    "summary_rope_release_latex = model_rope_release.summary().as_latex()\n",
    "summary_cable_max_latex = model_cable_max.summary().as_latex()\n",
    "\n",
    "#print(summary_rope_release_latex)\n",
    "#print(summary_cable_max_latex)\n",
    "\n",
    "anova_rope_release, summary_rope_release, anova_cable_max, summary_cable_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung des Text-Strings für die statistischen Parameter\n",
    "def annotate_stats(x, y):\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "    text_str = f\"R = {r_value:.2f}\\nSlope = {slope:.2f}\\nIntercept = {intercept:.2f}\\np-value = {p_value:.2e}\\nStd Err = {std_err:.2f}\"\n",
    "    return text_str"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Zusammenhang Ziel- und Ist-Vorspannung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig2, ax1 = plt.subplots(figsize=(8, 5))\n",
    "sns.regplot(x='release_force_target', y='ls3_rope_release', data=df_id, ax=ax1, color='b', ci=95)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "stats_text = annotate_stats(df_id['release_force_target'], df_id['ls3_rope_release'])\n",
    "ax2.annotate(stats_text, xy=(1.01, 0.1), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Target and Actual Release Forces\"')\n",
    "ax1.set_xlabel('Release Force Target [kN]')\n",
    "ax1.set_ylabel('Release Force [kN]')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig2, filename=f\"release_force_target_vs_ls3_rope_release\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Zusammenhang Vorspannung und resultierende Lastspitzen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ls3_cable_max'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ls3_cable_max', data=subset, ax=ax1, color=color, label=treatment, ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ls3_cable_max'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Peak Cable Force')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Peak Force in Cable [kN]')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"release_force_vs_ls3_cable_max\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ptq_m_amplitude'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ptq_m_amplitude', data=subset, ax=ax1, color=color, label=treatment,\n",
    "                ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ptq_m_amplitude'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Elongation Amplitude')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Elongation Amplitude [$\\mu$m] (mean for all Sensors)')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"ls3_release_force_vs_ptq_m_amplitude\", subdir=\"combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ptq_m_amplitude_2'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ptq_m_amplitude_2', data=subset, ax=ax1, color=color, label=treatment,\n",
    "                ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ptq_m_amplitude_2'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Elongation Amplitude 2')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Elongation Amplitude 2 [$\\mu$m] (mean for all Sensors)')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"ls3_release_force_vs_ptq_m_amplitude_2\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Durchführung des ANOVA-Tests und Berechnung der Effektstärke (Eta Squared)\n",
    "def perform_anova_and_effect_size(df: pd.DataFrame, variable: str, treatments: List[str]) -> str:\n",
    "    groups = [df[df['treatment'] == treatment][variable].dropna() for treatment in treatments]\n",
    "    f_stat, p_value = f_oneway(*groups)\n",
    "\n",
    "    # Berechnung der Effektstärke (Eta Squared)\n",
    "    n = sum([len(g) for g in groups])\n",
    "    ss_total = sum([(x - df[variable].mean()) ** 2 for g in groups for x in g])\n",
    "    eta_squared = f_stat * len(groups) / (f_stat * len(groups) + (n - len(groups)))\n",
    "\n",
    "    # Überprüfung der Signifikanz\n",
    "    significance = \"*\" if p_value < 0.05 else \"\"\n",
    "\n",
    "    return f\"{variable}: {significance}\\nF-statistic = {f_stat:.2f}\\np-value = {p_value:.2e}\\nEta Squared = {eta_squared:.2f}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung von Boxplots\n",
    "def create_boxplot(df: pd.DataFrame, variable: str, group_by: str, ax: plt.Axes, color_dict: Dict[str, str], perform_stats: bool) -> None:\n",
    "    valid_df = df.dropna(subset=[variable])\n",
    "    sns.boxplot(x=group_by, y=variable, hue=group_by, data=valid_df, ax=ax, palette=color_dict, dodge=False)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.axis('off')\n",
    "    if perform_stats:\n",
    "        stats_text = perform_anova_and_effect_size(valid_df, variable, valid_df[group_by].unique())\n",
    "        ax2.annotate(stats_text, xy=(1.01, 0.1), xycoords='axes fraction')\n",
    "    ax.set_title(f'Einfluss von {group_by} auf {variable}')\n",
    "    ax.set_xlabel(group_by)\n",
    "    ax.set_ylabel(variable)\n",
    "\n",
    "# Funktion zur Erstellung kombinierter Plots\n",
    "def create_combined_plot(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], num_columns: int = 3, perform_stats: bool = False) -> None:\n",
    "    num_rows = len(columns) // num_columns + (len(columns) % num_columns > 0)\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(16, 4 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, variable in enumerate(columns):\n",
    "        create_boxplot(df, variable, group_by, axes[idx], color_dict, perform_stats)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"combined_plot_{group_by}\", subdir=\"combined\")\n",
    "\n",
    "# Funktion zur Erstellung einzelner Plots\n",
    "def create_individual_plots(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], perform_stats: bool = False) -> None:\n",
    "    for variable in columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        create_boxplot(df, variable, group_by, ax, color_dict, perform_stats)\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        PLOT_MANAGER.save_plot(fig, filename=f\"{group_by}_{variable}\", subdir=\"individual_plots\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['ptq_m_amplitude',\n",
    "           'ptq_m_amplitude_2',\n",
    "           'ptq_initial_amplitude',\n",
    "           'ptq_damping_coeff',\n",
    "           'ptq_angular_frequency',\n",
    "           'ptq_y_shift',\n",
    "           'ptq_pearson_r',\n",
    "           #'ptq_nrmse',\n",
    "           #'ptq_nmae',\n",
    "           #'release_force_target',\n",
    "           'ls3_rope_release',\n",
    "           'ls3_cable_max'\n",
    "           ]\n",
    "\n",
    "# Beispiel: Erstellen von Plots gruppiert nach 'treatment'\n",
    "create_combined_plot(df, columns, 'treatment', treatment_color_dict, perform_stats=True)\n",
    "create_individual_plots(df, columns, 'treatment', treatment_color_dict, perform_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Beispiel: Erstellen von Plots gruppiert nach 'ptq_sensor_name'\n",
    "columns = ['ptq_m_amplitude', 'ptq_m_amplitude_2', 'ptq_initial_amplitude', 'ptq_damping_coeff', 'ptq_angular_frequency', 'ptq_pearson_r']\n",
    "\n",
    "create_combined_plot(df, columns, 'ptq_sensor_name', sensor_color_dict)\n",
    "create_individual_plots(df, columns, 'ptq_sensor_name', sensor_color_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
