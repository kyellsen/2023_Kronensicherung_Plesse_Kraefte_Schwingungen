{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"2023_Kronensicherung_Plesse_Combined_Analyse\"\n",
    "author: \"Kyell Jensen\"\n",
    "date: \"2024-08-06\"\n",
    "format: pdf\n",
    "editor: visual\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2023_Kronensicherung_Plesse_Combined_Analyse\n",
    "\n",
    "## Kombinierte Analyse LineScale3, TreeQinetic und Versuchsaufzeichung\n",
    "\n",
    "Nutze eine geeignete Python 3.11 Umgebung (z. B. virtuelle Environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Arbeitsumgebung vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### IMPORT: Importieren von Standardbibliotheken\n",
    "\n",
    "Die folgenden Bibliotheken werden importiert, um grundlegende Funktionen für Strukturierung, Datenverarbeitung, Plotting und statistische Auswertung bereit zu stellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:19.802260500Z",
     "start_time": "2025-03-26T08:36:18.648149600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Struktur\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "# Datenverarbeitung\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from slugify import slugify  # Slugify ums strings in standard Formate zu überführen\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistik\n",
    "from scipy.stats import linregress, f_oneway\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.multicomp as mc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## IMPORT: Daten Import\n",
    "\n",
    "Lege Pfade für Daten-Importe, Daten-Exporte etc. fest (ggf. anpassen an eigene Verzeichnisstruktur), ausgelagert in gemeinsame Config für verschiedene Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:19.802260500Z",
     "start_time": "2025-03-26T08:36:19.790071100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importiere alle Einstellungen aus der project_config.py\n",
    "from project_config import (\n",
    "    main_path,\n",
    "    analyse_name,\n",
    "    data_path,\n",
    "    working_directory,\n",
    "    data_export_directory,\n",
    "    latex_export_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from utils.latex_export import (\n",
    "    save_latex_table,\n",
    "    create_df_from_data_dict\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T10:53:15.670726600Z",
     "start_time": "2025-03-26T10:53:15.649656700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Liste aller Dateinamen\n",
    "filenames = [\n",
    "    \"tree.feather\",\n",
    "    \"sensor.feather\",\n",
    "    \"sensor_data_dict.json\",\n",
    "    \"series.feather\",\n",
    "    \"series_data_dict.json\",\n",
    "    \"ls3_data_dict.json\",\n",
    "    \"ls3.feather\",\n",
    "    \"ptq_data_dict.json\",\n",
    "    \"ptq.feather\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:19.860719600Z",
     "start_time": "2025-03-26T08:36:19.800154700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_file(path: Path):\n",
    "    try:\n",
    "        if path.suffix == \".feather\":\n",
    "            df_now = pd.read_feather(path)\n",
    "            print(f\"[Info] Feather geladen: {path.name}\")\n",
    "            return \"df\", path.stem, df_now\n",
    "        elif path.suffix == \".json\":\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data_dict_now = json.load(f)\n",
    "                print(f\"[Info] JSON geladen: {path.name}\")\n",
    "                return \"dict\", path.stem, data_dict_now\n",
    "        else:\n",
    "            print(f\"[Warnung] Unbekannter Dateityp übersprungen: {path.name}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"[Fehler] Laden fehlgeschlagen für '{path.name}': {e}\")\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:19.893182300Z",
     "start_time": "2025-03-26T08:36:19.802260500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Feather geladen: tree.feather\n",
      "[Info] Feather geladen: sensor.feather\n",
      "[Info] JSON geladen: sensor_data_dict.json\n",
      "[Info] Feather geladen: series.feather\n",
      "[Info] JSON geladen: series_data_dict.json\n",
      "[Info] JSON geladen: ls3_data_dict.json\n",
      "[Info] Feather geladen: ls3.feather\n",
      "[Info] JSON geladen: ptq_data_dict.json\n",
      "[Info] Feather geladen: ptq.feather\n"
     ]
    }
   ],
   "source": [
    "# Container\n",
    "dfs = {}\n",
    "data_dicts = {}\n",
    "\n",
    "for file in filenames:\n",
    "    result = load_file(data_export_directory / file)\n",
    "    if result:\n",
    "        kind, name_stem, content = result\n",
    "        if kind == \"df\":\n",
    "            dfs[f\"{name_stem}_df\"] = content\n",
    "        elif kind == \"dict\":\n",
    "            data_dicts[f\"{name_stem}\"] = content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.176743200Z",
     "start_time": "2025-03-26T08:36:19.812327200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['tree_df', 'sensor_df', 'series_df', 'ls3_df', 'ptq_df'])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.176743200Z",
     "start_time": "2025-03-26T08:36:19.974024600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['sensor_data_dict', 'series_data_dict', 'ls3_data_dict', 'ptq_data_dict'])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dicts.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.186826Z",
     "start_time": "2025-03-26T08:36:19.992175500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# IDE-Hints: Feather-Dateien (DataFrames)\n",
    "tree_df: pd.DataFrame = dfs.get(\"tree_df\")\n",
    "sensor_df: pd.DataFrame = dfs.get(\"sensor_df\")\n",
    "series_df: pd.DataFrame = dfs.get(\"series_df\")\n",
    "ls3_df: pd.DataFrame = dfs.get(\"ls3_df\")\n",
    "ptq_df: pd.DataFrame = dfs.get(\"ptq_df\")\n",
    "\n",
    "# IDE-Hints: Data Dictionary Dateien (JSON → dict)\n",
    "sensor_data_dict: dict = data_dicts.get(\"sensor_data_dict\")\n",
    "series_data_dict: dict = data_dicts.get(\"series_data_dict\")\n",
    "ls3_data_dict: dict = data_dicts.get(\"ls3_data_dict\")\n",
    "ptq_data_dict: dict = data_dicts.get(\"ptq_data_dict\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.186826Z",
     "start_time": "2025-03-26T08:36:20.005538700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MERGE: Zusammenführen der Daten von LS3, PTQ und Versuchsprotokoll"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Beginne mit PTQ-Daten, füge dann schrittweise die Daten des Versuchsablaufes, der Sensorpositionierung und Kraftmessung hinzu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df = pd.merge(ptq_df, series_df, on='id', how='left')\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.196951900Z",
     "start_time": "2025-03-26T08:36:20.047065Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ergänze die Daten der Sensorpositionierung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Merging df and elasto_df\n",
    "# Geräte vom Typ Elastometer auswählen aus dem sensor_df\n",
    "elasto_df = sensor_df[sensor_df[\"type\"] == \"Elasto\"].copy()\n",
    "\n",
    "# Passe die sensor_namen einheitlich für beide DataFrames an\n",
    "elasto_df[\"sensor_name\"] = elasto_df[\"type\"].astype(str) + \"(\" + elasto_df[\"sensor_id\"].astype(str) + \")\"\n",
    "\n",
    "# Perform the left join on sensor_name\n",
    "df = df.merge(elasto_df, on=\"sensor_name\", how=\"left\")\n",
    "\n",
    "# Gewünschte Reihenfolge\n",
    "elasto_names = [\"Elasto(90)\", \"Elasto(92)\", \"Elasto(95)\", \"Elasto(98)\"]\n",
    "# Definieren als geordneter CategoricalDtype\n",
    "elasto_cat_type = CategoricalDtype(categories=elasto_names, ordered=True)\n",
    "# Setzen des Typs auf die Spalte\n",
    "df[\"sensor_name\"] = df[\"sensor_name\"].astype(elasto_cat_type)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.196951900Z",
     "start_time": "2025-03-26T08:36:20.065434500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ergänze die LS3-Daten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Function to prepare ls3_metadata\n",
    "def extract_ls3_subset(df, sensor_id, new_prefix):\n",
    "    return (df.query(f\"sensor_id == '{sensor_id}'\")\n",
    "            .drop('sensor_id', axis=1)\n",
    "            .add_prefix(new_prefix)\n",
    "            .rename(columns={f'{new_prefix}measurement_id': sensor_id}))\n",
    "\n",
    "# Merging ls3_metadata with the main DataFrame\n",
    "df = df.merge(extract_ls3_subset(ls3_df, '14:BF:E6', 'rope_'), on='14:BF:E6', how='left')     \n",
    "df = df.merge(extract_ls3_subset(ls3_df, '14:99:1E', 'cable_'), on='14:99:1E', how='left')     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.196951900Z",
     "start_time": "2025-03-26T08:36:20.085508200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "    id            file_name sensor_name  sample_rate  max_strain  \\\n0    1  PTQ_Meas_100346.txt  Elasto(95)     4.003157       190.2   \n1    1  PTQ_Meas_100346.txt  Elasto(98)     3.941160       141.6   \n2    1  PTQ_Meas_100346.txt  Elasto(92)     3.941160       239.9   \n3    1  PTQ_Meas_100346.txt  Elasto(90)     4.003157       363.5   \n4    2  PTQ_Meas_101814.txt  Elasto(95)     3.447691       226.9   \n..  ..                  ...         ...          ...         ...   \n95  24  PTQ_Meas_153334.txt  Elasto(90)     3.696858       377.6   \n96  25  PTQ_Meas_153817.txt  Elasto(95)     3.949052       180.2   \n97  25  PTQ_Meas_153817.txt  Elasto(98)     3.946552       181.6   \n98  25  PTQ_Meas_153817.txt  Elasto(92)     3.949052       217.7   \n99  25  PTQ_Meas_153817.txt  Elasto(90)     4.001804       350.3   \n\n    max_compression  max_strain_osc  max_compression_osc  m_amplitude  \\\n0            -119.1           190.2               -119.1       154.65   \n1            -132.8           141.6               -132.8       137.20   \n2             -86.6           239.9                -86.6       163.25   \n3            -168.1           363.5               -168.1       265.80   \n4             -90.4           226.9                -90.4       158.65   \n..              ...             ...                  ...          ...   \n95            -57.7           377.6                -57.7       217.65   \n96            -22.5           180.2                -22.5       101.35   \n97           -108.4           181.6               -108.4       145.00   \n98            -13.0           217.7                -13.0       115.35   \n99           -111.5           350.3               -111.5       230.90   \n\n    m_amplitude_2  ...  cable_timing_correction_factor  cable_datetime_start  \\\n0           82.25  ...                             NaN                   NaT   \n1           92.50  ...                             NaN                   NaT   \n2           76.00  ...                             NaN                   NaT   \n3          162.10  ...                             NaN                   NaT   \n4           82.05  ...                             NaN                   NaT   \n..            ...  ...                             ...                   ...   \n95          87.50  ...                             0.9   2022-03-23 16:41:28   \n96          23.90  ...                             0.9   2022-03-23 16:46:46   \n97         109.55  ...                             0.9   2022-03-23 16:46:46   \n98          15.05  ...                             0.9   2022-03-23 16:46:46   \n99          99.40  ...                             0.9   2022-03-23 16:46:46   \n\n              cable_datetime_end  cable_duration  cable_length  \\\n0                            NaT             NaN           NaN   \n1                            NaT             NaN           NaN   \n2                            NaT             NaN           NaN   \n3                            NaT             NaN           NaN   \n4                            NaT             NaN           NaN   \n..                           ...             ...           ...   \n95 2022-03-23 16:41:44.199296875       16.199296       23040.0   \n96 2022-03-23 16:47:02.199296875       16.199296       23040.0   \n97 2022-03-23 16:47:02.199296875       16.199296       23040.0   \n98 2022-03-23 16:47:02.199296875       16.199296       23040.0   \n99 2022-03-23 16:47:02.199296875       16.199296       23040.0   \n\n         cable_max  cable_mean  cable_median     cable_min  cable_release  \n0              NaN         NaN           NaN           NaN            NaN  \n1              NaN         NaN           NaN           NaN            NaN  \n2              NaN         NaN           NaN           NaN            NaN  \n3              NaN         NaN           NaN           NaN            NaN  \n4              NaN         NaN           NaN           NaN            NaN  \n..             ...         ...           ...           ...            ...  \n95  [3877.0, 2.76]    0.329963          0.33  [520.0, 0.0]            NaN  \n96   [3876.0, 2.8]    0.324260          0.32  [260.0, 0.0]            NaN  \n97   [3876.0, 2.8]    0.324260          0.32  [260.0, 0.0]            NaN  \n98   [3876.0, 2.8]    0.324260          0.32  [260.0, 0.0]            NaN  \n99   [3876.0, 2.8]    0.324260          0.32  [260.0, 0.0]            NaN  \n\n[100 rows x 84 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>file_name</th>\n      <th>sensor_name</th>\n      <th>sample_rate</th>\n      <th>max_strain</th>\n      <th>max_compression</th>\n      <th>max_strain_osc</th>\n      <th>max_compression_osc</th>\n      <th>m_amplitude</th>\n      <th>m_amplitude_2</th>\n      <th>...</th>\n      <th>cable_timing_correction_factor</th>\n      <th>cable_datetime_start</th>\n      <th>cable_datetime_end</th>\n      <th>cable_duration</th>\n      <th>cable_length</th>\n      <th>cable_max</th>\n      <th>cable_mean</th>\n      <th>cable_median</th>\n      <th>cable_min</th>\n      <th>cable_release</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>PTQ_Meas_100346.txt</td>\n      <td>Elasto(95)</td>\n      <td>4.003157</td>\n      <td>190.2</td>\n      <td>-119.1</td>\n      <td>190.2</td>\n      <td>-119.1</td>\n      <td>154.65</td>\n      <td>82.25</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>PTQ_Meas_100346.txt</td>\n      <td>Elasto(98)</td>\n      <td>3.941160</td>\n      <td>141.6</td>\n      <td>-132.8</td>\n      <td>141.6</td>\n      <td>-132.8</td>\n      <td>137.20</td>\n      <td>92.50</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>PTQ_Meas_100346.txt</td>\n      <td>Elasto(92)</td>\n      <td>3.941160</td>\n      <td>239.9</td>\n      <td>-86.6</td>\n      <td>239.9</td>\n      <td>-86.6</td>\n      <td>163.25</td>\n      <td>76.00</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>PTQ_Meas_100346.txt</td>\n      <td>Elasto(90)</td>\n      <td>4.003157</td>\n      <td>363.5</td>\n      <td>-168.1</td>\n      <td>363.5</td>\n      <td>-168.1</td>\n      <td>265.80</td>\n      <td>162.10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>PTQ_Meas_101814.txt</td>\n      <td>Elasto(95)</td>\n      <td>3.447691</td>\n      <td>226.9</td>\n      <td>-90.4</td>\n      <td>226.9</td>\n      <td>-90.4</td>\n      <td>158.65</td>\n      <td>82.05</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>24</td>\n      <td>PTQ_Meas_153334.txt</td>\n      <td>Elasto(90)</td>\n      <td>3.696858</td>\n      <td>377.6</td>\n      <td>-57.7</td>\n      <td>377.6</td>\n      <td>-57.7</td>\n      <td>217.65</td>\n      <td>87.50</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>2022-03-23 16:41:28</td>\n      <td>2022-03-23 16:41:44.199296875</td>\n      <td>16.199296</td>\n      <td>23040.0</td>\n      <td>[3877.0, 2.76]</td>\n      <td>0.329963</td>\n      <td>0.33</td>\n      <td>[520.0, 0.0]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>25</td>\n      <td>PTQ_Meas_153817.txt</td>\n      <td>Elasto(95)</td>\n      <td>3.949052</td>\n      <td>180.2</td>\n      <td>-22.5</td>\n      <td>180.2</td>\n      <td>-22.5</td>\n      <td>101.35</td>\n      <td>23.90</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>2022-03-23 16:46:46</td>\n      <td>2022-03-23 16:47:02.199296875</td>\n      <td>16.199296</td>\n      <td>23040.0</td>\n      <td>[3876.0, 2.8]</td>\n      <td>0.324260</td>\n      <td>0.32</td>\n      <td>[260.0, 0.0]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>25</td>\n      <td>PTQ_Meas_153817.txt</td>\n      <td>Elasto(98)</td>\n      <td>3.946552</td>\n      <td>181.6</td>\n      <td>-108.4</td>\n      <td>181.6</td>\n      <td>-108.4</td>\n      <td>145.00</td>\n      <td>109.55</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>2022-03-23 16:46:46</td>\n      <td>2022-03-23 16:47:02.199296875</td>\n      <td>16.199296</td>\n      <td>23040.0</td>\n      <td>[3876.0, 2.8]</td>\n      <td>0.324260</td>\n      <td>0.32</td>\n      <td>[260.0, 0.0]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>25</td>\n      <td>PTQ_Meas_153817.txt</td>\n      <td>Elasto(92)</td>\n      <td>3.949052</td>\n      <td>217.7</td>\n      <td>-13.0</td>\n      <td>217.7</td>\n      <td>-13.0</td>\n      <td>115.35</td>\n      <td>15.05</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>2022-03-23 16:46:46</td>\n      <td>2022-03-23 16:47:02.199296875</td>\n      <td>16.199296</td>\n      <td>23040.0</td>\n      <td>[3876.0, 2.8]</td>\n      <td>0.324260</td>\n      <td>0.32</td>\n      <td>[260.0, 0.0]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>25</td>\n      <td>PTQ_Meas_153817.txt</td>\n      <td>Elasto(90)</td>\n      <td>4.001804</td>\n      <td>350.3</td>\n      <td>-111.5</td>\n      <td>350.3</td>\n      <td>-111.5</td>\n      <td>230.90</td>\n      <td>99.40</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>2022-03-23 16:46:46</td>\n      <td>2022-03-23 16:47:02.199296875</td>\n      <td>16.199296</td>\n      <td>23040.0</td>\n      <td>[3876.0, 2.8]</td>\n      <td>0.324260</td>\n      <td>0.32</td>\n      <td>[260.0, 0.0]</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 84 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.264881700Z",
     "start_time": "2025-03-26T08:36:20.126121100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EXPORT: Ungefilterte Daten exportieren für Externe (.feather, .csv)\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df.to_feather(data_export_directory / \"_dataset_full.feather\")\n",
    "df.to_csv(data_export_directory / \"_dataset_full.csv\", sep=\";\", index=True, encoding=\"utf-8\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.959818200Z",
     "start_time": "2025-03-26T08:36:20.166609500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CLEANING: Daten bereinigen und Filtern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Liste der Spalten, die beibehalten werden sollen\n",
    "select_cols = ['id', 'rope_datetime', 'treatment', 'release_force_target', \n",
    "               'rope_release', 'cable_max',\n",
    "               'sensor_name', 'location', 'direction', 'height', 'diameter',\n",
    "               'max_strain', 'max_compression',\n",
    "               'm_amplitude', 'm_amplitude_2', \n",
    "               'initial_amplitude', 'damping_coeff', 'frequency_damped', 'phase_angle', 'y_shift', 'x_shift', 'frequency_undamped', 'damping_ratio', \n",
    "               'metrics_warning', 'pearson_r', 'nrmse', 'nmae'\n",
    "               ]\n",
    "\n",
    "# DataFrame filtern\n",
    "df = (\n",
    "    df[select_cols]\n",
    "    .query(\"release_force_target in [2.0, 2.4, 2.8] and treatment in ['free', 'gefa_dynamic', 'cobra_static']\")\n",
    "    .copy()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:20.959818200Z",
     "start_time": "2025-03-26T08:36:20.237306100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Nicht verwendete Kategorien entfernen\n",
    "df[\"treatment\"] = df[\"treatment\"].cat.remove_unused_categories()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:21.006713200Z",
     "start_time": "2025-03-26T08:36:20.257987400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# cable_max enthält noch ein np.ndarray mit index etc., nur Messwerte F benötigt\n",
    "df['cable_max'] = df['cable_max'].apply(\n",
    "    lambda x: float(x[1]) if isinstance(x, (tuple, list, np.ndarray)) and len(x) > 1 else x\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:21.006713200Z",
     "start_time": "2025-03-26T08:36:20.267721Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "    id       rope_datetime treatment  release_force_target  rope_release  \\\n4    2 2022-03-23 11:24:23      free                   2.8       2.72310   \n5    2 2022-03-23 11:24:23      free                   2.8       2.72310   \n6    2 2022-03-23 11:24:23      free                   2.8       2.72310   \n7    2 2022-03-23 11:24:23      free                   2.8       2.72310   \n8    3 2022-03-23 11:31:12      free                   2.8       2.76205   \n9    3 2022-03-23 11:31:12      free                   2.8       2.76205   \n10   3 2022-03-23 11:31:12      free                   2.8       2.76205   \n11   3 2022-03-23 11:31:12      free                   2.8       2.76205   \n12   4 2022-03-23 11:54:33      free                   2.8       2.73950   \n13   4 2022-03-23 11:54:33      free                   2.8       2.73950   \n\n    cable_max sensor_name location   direction  height  ...  frequency_damped  \\\n4         NaN  Elasto(95)      StA  elongation    11.6  ...          0.422702   \n5         NaN  Elasto(98)      StA  elongation   16.85  ...          0.443529   \n6         NaN  Elasto(92)      StB  elongation    11.6  ...          0.432441   \n7         NaN  Elasto(90)      StB  elongation   16.55  ...          0.441518   \n8         NaN  Elasto(95)      StA  elongation    11.6  ...          0.436023   \n9         NaN  Elasto(98)      StA  elongation   16.85  ...          0.441350   \n10        NaN  Elasto(92)      StB  elongation    11.6  ...          0.439249   \n11        NaN  Elasto(90)      StB  elongation   16.55  ...          0.440654   \n12        NaN  Elasto(95)      StA  elongation    11.6  ...          0.437440   \n13        NaN  Elasto(98)      StA  elongation   16.85  ...          0.440944   \n\n    phase_angle    y_shift   x_shift  frequency_undamped  damping_ratio  \\\n4     -0.200000 -19.011253 -0.123043            0.426319       0.823806   \n5     -0.065967  -1.099515  0.118608            0.445993       0.663224   \n6     -0.200000 -14.233643 -0.009730            0.436601       0.873595   \n7      0.200000  -5.287164  0.116641            0.442936       0.503994   \n8     -0.200000  -3.785755 -0.075741            0.438127       0.618021   \n9     -0.200000 -17.747289 -0.203345            0.442888       0.525070   \n10    -0.200000   7.070001  0.049121            0.441269       0.603287   \n11     0.200000   7.775263  0.097887            0.441317       0.344954   \n12    -0.200000 -12.213652 -0.009980            0.439409       0.596808   \n13     0.200000  -1.474443  0.020621            0.442057       0.446759   \n\n    metrics_warning  pearson_r     nrmse      nmae  \n4             False   0.908058  0.044873  0.024274  \n5             False   0.980663  0.029621  0.021087  \n6             False   0.929554  0.034560  0.016183  \n7             False   0.943158  0.038866  0.018011  \n8             False   0.938307  0.039020  0.022498  \n9             False   0.974139  0.028693  0.020715  \n10            False   0.932950  0.043734  0.021138  \n11            False   0.957381  0.043035  0.018619  \n12            False   0.941719  0.040794  0.022777  \n13            False   0.981570  0.033353  0.022201  \n\n[10 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rope_datetime</th>\n      <th>treatment</th>\n      <th>release_force_target</th>\n      <th>rope_release</th>\n      <th>cable_max</th>\n      <th>sensor_name</th>\n      <th>location</th>\n      <th>direction</th>\n      <th>height</th>\n      <th>...</th>\n      <th>frequency_damped</th>\n      <th>phase_angle</th>\n      <th>y_shift</th>\n      <th>x_shift</th>\n      <th>frequency_undamped</th>\n      <th>damping_ratio</th>\n      <th>metrics_warning</th>\n      <th>pearson_r</th>\n      <th>nrmse</th>\n      <th>nmae</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2022-03-23 11:24:23</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.72310</td>\n      <td>NaN</td>\n      <td>Elasto(95)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.422702</td>\n      <td>-0.200000</td>\n      <td>-19.011253</td>\n      <td>-0.123043</td>\n      <td>0.426319</td>\n      <td>0.823806</td>\n      <td>False</td>\n      <td>0.908058</td>\n      <td>0.044873</td>\n      <td>0.024274</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>2022-03-23 11:24:23</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.72310</td>\n      <td>NaN</td>\n      <td>Elasto(98)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>16.85</td>\n      <td>...</td>\n      <td>0.443529</td>\n      <td>-0.065967</td>\n      <td>-1.099515</td>\n      <td>0.118608</td>\n      <td>0.445993</td>\n      <td>0.663224</td>\n      <td>False</td>\n      <td>0.980663</td>\n      <td>0.029621</td>\n      <td>0.021087</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>2022-03-23 11:24:23</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.72310</td>\n      <td>NaN</td>\n      <td>Elasto(92)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.432441</td>\n      <td>-0.200000</td>\n      <td>-14.233643</td>\n      <td>-0.009730</td>\n      <td>0.436601</td>\n      <td>0.873595</td>\n      <td>False</td>\n      <td>0.929554</td>\n      <td>0.034560</td>\n      <td>0.016183</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>2022-03-23 11:24:23</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.72310</td>\n      <td>NaN</td>\n      <td>Elasto(90)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>16.55</td>\n      <td>...</td>\n      <td>0.441518</td>\n      <td>0.200000</td>\n      <td>-5.287164</td>\n      <td>0.116641</td>\n      <td>0.442936</td>\n      <td>0.503994</td>\n      <td>False</td>\n      <td>0.943158</td>\n      <td>0.038866</td>\n      <td>0.018011</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>2022-03-23 11:31:12</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.76205</td>\n      <td>NaN</td>\n      <td>Elasto(95)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.436023</td>\n      <td>-0.200000</td>\n      <td>-3.785755</td>\n      <td>-0.075741</td>\n      <td>0.438127</td>\n      <td>0.618021</td>\n      <td>False</td>\n      <td>0.938307</td>\n      <td>0.039020</td>\n      <td>0.022498</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>2022-03-23 11:31:12</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.76205</td>\n      <td>NaN</td>\n      <td>Elasto(98)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>16.85</td>\n      <td>...</td>\n      <td>0.441350</td>\n      <td>-0.200000</td>\n      <td>-17.747289</td>\n      <td>-0.203345</td>\n      <td>0.442888</td>\n      <td>0.525070</td>\n      <td>False</td>\n      <td>0.974139</td>\n      <td>0.028693</td>\n      <td>0.020715</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>2022-03-23 11:31:12</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.76205</td>\n      <td>NaN</td>\n      <td>Elasto(92)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.439249</td>\n      <td>-0.200000</td>\n      <td>7.070001</td>\n      <td>0.049121</td>\n      <td>0.441269</td>\n      <td>0.603287</td>\n      <td>False</td>\n      <td>0.932950</td>\n      <td>0.043734</td>\n      <td>0.021138</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>2022-03-23 11:31:12</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.76205</td>\n      <td>NaN</td>\n      <td>Elasto(90)</td>\n      <td>StB</td>\n      <td>elongation</td>\n      <td>16.55</td>\n      <td>...</td>\n      <td>0.440654</td>\n      <td>0.200000</td>\n      <td>7.775263</td>\n      <td>0.097887</td>\n      <td>0.441317</td>\n      <td>0.344954</td>\n      <td>False</td>\n      <td>0.957381</td>\n      <td>0.043035</td>\n      <td>0.018619</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4</td>\n      <td>2022-03-23 11:54:33</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.73950</td>\n      <td>NaN</td>\n      <td>Elasto(95)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>11.6</td>\n      <td>...</td>\n      <td>0.437440</td>\n      <td>-0.200000</td>\n      <td>-12.213652</td>\n      <td>-0.009980</td>\n      <td>0.439409</td>\n      <td>0.596808</td>\n      <td>False</td>\n      <td>0.941719</td>\n      <td>0.040794</td>\n      <td>0.022777</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4</td>\n      <td>2022-03-23 11:54:33</td>\n      <td>free</td>\n      <td>2.8</td>\n      <td>2.73950</td>\n      <td>NaN</td>\n      <td>Elasto(98)</td>\n      <td>StA</td>\n      <td>elongation</td>\n      <td>16.85</td>\n      <td>...</td>\n      <td>0.440944</td>\n      <td>0.200000</td>\n      <td>-1.474443</td>\n      <td>0.020621</td>\n      <td>0.442057</td>\n      <td>0.446759</td>\n      <td>False</td>\n      <td>0.981570</td>\n      <td>0.033353</td>\n      <td>0.022201</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:45:43.354222900Z",
     "start_time": "2025-03-26T08:45:43.254053500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EDIT: Datendokumentation an zusammengeführte und gefilterte Daten anpassen\n",
    "\n",
    "Passe Datendokumentation den zusammengeführten und gefilterten Daten an, ergänze weitere später berechnete Features, erstellt vollstände aktuelle Datendokumentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Lade das Dictionary mit der Daten Dokumentation\n",
    "with open(data_path / \"calc_strain_data_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    calc_strain_data_dict = json.load(f)\n",
    "    \n",
    "select_cols += list(calc_strain_data_dict.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:21.006713200Z",
     "start_time": "2025-03-26T08:36:20.287826400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Rope-Keys erzeugen\n",
    "ls3_rope_data_dict = {f\"rope_{k}\": v for k, v in ls3_data_dict.items()}\n",
    "# Cable-Keys erzeugen\n",
    "ls3_cable_data_dict = {    f\"cable_{k}\": v for k, v in ls3_data_dict.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:21.006713200Z",
     "start_time": "2025-03-26T08:36:20.336518600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Alles zusammenführen\n",
    "full_data_dict = {\n",
    "    **sensor_data_dict,\n",
    "    **series_data_dict,\n",
    "    **ls3_rope_data_dict,\n",
    "    **ls3_cable_data_dict,\n",
    "    **ptq_data_dict,\n",
    "    **calc_strain_data_dict\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:21.006713200Z",
     "start_time": "2025-03-26T08:36:20.346792900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# 1. sensor → Deutsch\n",
    "if \"sensor\" in full_data_dict:\n",
    "    full_data_dict[\"sensor\"][\"Deutsch\"] = \"Elastometer\"\n",
    "\n",
    "# 2. cable_max → Beschreibung, Deutsch, Zeichen\n",
    "if \"cable_max\" in full_data_dict:\n",
    "    full_data_dict[\"cable_max\"][\"Beschreibung\"] = \"Maximale gemessene Kraftspitze in der KS\"\n",
    "    full_data_dict[\"cable_max\"][\"Deutsch\"] = \"Kraftspitze KS\"\n",
    "    full_data_dict[\"cable_max\"][\"Zeichen\"] = \"$F_{\\\\mathrm{cable, max}}$\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:36:21.006713200Z",
     "start_time": "2025-03-26T08:36:20.348891700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "data_dict = {key: full_data_dict[key] for key in select_cols if key in full_data_dict}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:38:50.800532100Z",
     "start_time": "2025-03-26T08:38:50.743297700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EXPORT: Gefilterte Daten und Datendokumentation exportieren für Weiterverarbeitung (.feather, .csv, .json)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_feather(data_export_directory / \"_dataset_clean.feather\")\n",
    "df.to_csv(data_export_directory / \"_dataset_clean.csv\", sep=\";\", index=True, encoding=\"utf-8\")\n",
    "\n",
    "with open(data_export_directory / \"_data_dict_clean.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data_dict, f, indent=4, ensure_ascii=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LATEX-EXPORT: Datendokumentation als Latex-Tabelle exportieren (.tex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content saved to: C:\\kyellsen\\005_Projekte\\2024_BA\\032_Feldversuch_2023_Plesse\\030_Analysen\\2023_Kronensicherung_Plesse_Kraefte_Schwingungen\\working_directory\\export_latex\\feldversuch_2_ergebnisse_daten_dokumentation.tex\n"
     ]
    }
   ],
   "source": [
    "# Erzeuge DataFrame für LaTeX mit einheitlichem Aufbau\n",
    "data_dict_df = create_df_from_data_dict(data_dict)\n",
    "\n",
    "# Exportiere als LaTeX\n",
    "latex_string = data_dict_df.to_latex(index=False, escape=False)\n",
    "\n",
    "caption = \"Feldversuch 2 - Ergebnisse, Daten Dokumentation\"\n",
    "caption_long = \"Feldversuch 2 - Ergebnisse, Daten Dokumentation, Kräfte, Dehnungen und Schwingungsparameter\"\n",
    "\n",
    "save_latex_table(latex_string, caption, latex_export_directory, caption_long=caption_long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T08:45:01.293534800Z",
     "start_time": "2025-03-26T08:45:00.962222800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combined: Analyse der zusammengeführten Daten für LS3, PTQ und Versuchsprotkoll"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined: Explorative Datenanalyse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.839903800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.839903800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined: Definition von Darstellungsstandards\n",
    "Festlegen von Farbcodes für einheitliche Darstellung von Sensoren und Behandlungsvarianten für alle nachfolgenden Plots."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PLOT_MANAGER = ptq_series.PLOT_MANAGER\n",
    "\n",
    "# Seaborn \"deep\" Palette holen\n",
    "deep_palette = sns.color_palette(\"deep\", 6)\n",
    "\n",
    "# Zuweisen von Farben aus der \"deep\" Palette an die Sensoren\n",
    "sensor_color_dict = {sensor: color for sensor, color in zip(elasto_names, deep_palette[:len(elasto_names)])}\n",
    "\n",
    "# Zuweisen von Farben aus der \"deep\" Palette an die Treatments\n",
    "treatment_color_dict = {treatment: color for treatment, color in zip(treatment_order, deep_palette[:len(treatment_order)])}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.839903800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting Tite-, Achsen-, Filenamen erzeugen aus Data-Dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_axis_label(key: str, data_dict: Dict[str, Dict[str, str]]) -> str:\n",
    "    return f\"{data_dict[key]['Deutsch']} {data_dict[key]['Zeichen']} [{data_dict[key]['Einheit']}]\"\n",
    "\n",
    "def get_plot_title(x_key: str, y_key: str, data_dict: Dict[str, Dict[str, str]], prefix: str = \"Regression\") -> str:\n",
    "    return (\n",
    "        f\"{prefix}: {data_dict[y_key]['Deutsch']} \"\n",
    "        f\"({data_dict[y_key]['Zeichen']}) vs. \"\n",
    "        f\"{data_dict[x_key]['Deutsch']} \"\n",
    "        f\"({data_dict[x_key]['Zeichen']})\"\n",
    "    )\n",
    "\n",
    "def get_legend_title(key: str, data_dict: Dict[str, Dict[str, str]]) -> str:\n",
    "    return data_dict[key][\"Deutsch\"]\n",
    "\n",
    "def get_filename(x_key: str, y_key: str, prefix: str) -> str:\n",
    "    return slugify(f\"{prefix}_{y_key}_vs_{x_key}\", separator=\"_\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.839903800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LS3: Analyse Spitzenlasten in der KS\n",
    "\n",
    "Analyse der Spitzenlasten in der KS gruppiert nach Ziel-Vorspannung und Treatment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filtern und Umbenennen\n",
    "filtered_df = (\n",
    "    df[df['treatment'].isin(['gefa_dynamic', 'cobra_static'])]\n",
    "    .rename(columns={\n",
    "        'release_force_target': 'Ziel-Vorspannung',\n",
    "        'treatment': 'Behandlungsvariante',\n",
    "        'cable_max': 'Kraftspitze KS'\n",
    "    })[['Behandlungsvariante', 'Ziel-Vorspannung', 'Kraftspitze KS']]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.839903800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Gruppieren, Aggregieren und Pivotieren\n",
    "pivoted_values = (\n",
    "    filtered_df\n",
    "    .groupby(['Ziel-Vorspannung', 'Behandlungsvariante'], observed=True)['Kraftspitze KS']\n",
    "    .agg(['min', 'mean', 'max'])\n",
    "    .unstack(level=0)\n",
    "    .swaplevel(axis=1)\n",
    "    .sort_index(axis=1, level=[0, 1], ascending=[True, False])\n",
    ")\n",
    "# Begrenze die Werte im Index Level 0 auf zwei Nachkommastellen\n",
    "pivoted_values.columns = pd.MultiIndex.from_tuples(\n",
    "    [\n",
    "        (f\"{level_0:.2f}\", level_1) if isinstance(level_0, float) else (level_0, level_1)\n",
    "        for level_0, level_1 in pivoted_values.columns\n",
    "    ],\n",
    "    names=pivoted_values.columns.names\n",
    ")\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "pivoted_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.855544900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latex_string = pivoted_values.to_latex(index=True, escape=True, float_format=\"{:0.2f}\".format, column_format=\"l|rrr|rrr|rrr\", multicolumn=True,\n",
    "    multicolumn_format=\"c\")\n",
    "\n",
    "caption = \"Feldversuch 2 - Ergebnisse, Spitzenlasten in der KS\"\n",
    "caption_long = \"Feldversuch 2 - Spitzenlasten in der KS gruppiert über Ziel-Vorspannung und Behandlungsvariante, angegeben ist jeweils pro Gruppe das Minimum, der Mittelwert und das Maximum, die Variante 'free' ist nicht aufgeführt, da hier keine KS eingesetzt wurde, alle Werte in kN\"\n",
    "\n",
    "save_latex_table(latex_string, caption, latex_export_directory, caption_long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.855544900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filtern der Einträge mit dem maximalen Wert in 'cable_max'\n",
    "max_cable_max = df['cable_max'].max()\n",
    "filtered_df = df[df['cable_max'] == max_cable_max]\n",
    "\n",
    "# Innerhalb der gefilterten Einträge den maximalen 'max_strain' finden\n",
    "max_value_row = filtered_df.loc[filtered_df['max_strain'].idxmax()]\n",
    "#max_value_row"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.855544900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Liste der gewünschten Spalten in der gewünschten Reihenfolge\n",
    "columns_to_display = [\n",
    "    'id', 'treatment', 'release_force_target', 'rope_release', \n",
    "    'cable_max', 'sensor_name', 'max_strain', 'max_compression'\n",
    "]\n",
    "\n",
    "# Zeile auf die gewünschten Spalten in der angegebenen Reihenfolge beschränken\n",
    "max_value_row_filtered = max_value_row[columns_to_display]\n",
    "\n",
    "max_value_row_filtered['treatment'] = slugify(max_value_row_filtered['treatment'])\n",
    "\n",
    "# Erstelle ein DataFrame mit den zusätzlichen Informationen aus `data_dict`\n",
    "expanded_data = []\n",
    "for col in columns_to_display:\n",
    "    expanded_data.append({\n",
    "        \"Zeichen\": data_dict[col][\"Zeichen\"],\n",
    "        \"Deutsch\": data_dict[col][\"Deutsch\"],\n",
    "        \"Wert\": max_value_row_filtered[col],\n",
    "        \"Einheit\": data_dict[col][\"Einheit\"],\n",
    "    })\n",
    "\n",
    "# Neues DataFrame erstellen\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "\n",
    "# LaTeX-String erstellen\n",
    "latex_string = expanded_df.to_latex(\n",
    "    index=False, \n",
    "    escape=False, \n",
    "    column_format=\"llrr\",  # Spaltenformat angepasst\n",
    "    float_format=\"{:0.2f}\".format\n",
    ")\n",
    "\n",
    "# LaTeX-Tabelle mit Beschriftung versehen\n",
    "caption = \"Feldversuch 2 - Ergebnisse, Werte der Messung mit Spitzenlast\"\n",
    "caption_long = \"Feldversuch 2 - Ergebnisse, Messung mit der höchsten Last in der KS (nur maximale Messwerte des Elastometers mit der höchsten Faserdehnung)\"\n",
    "\n",
    "# Funktion zum Speichern aufrufen (angenommen save_latex_table ist definiert)\n",
    "save_latex_table(latex_string, caption, latex_export_directory, caption_long)\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "expanded_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.855544900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined: Vergleichende Berechnung der Randfaserdehnung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Berechnung der Randfaserdehnung (in Dezimalschreibweise)\n",
    "def calculate_epsilon(force: float, H: float, h: float, d: float, E: float) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet die Randfaserdehnung epsilon (dimensionslos, nicht in %).\n",
    "    \n",
    "    Parameters:\n",
    "        force (float): Zugkraft im Seil (in kN)\n",
    "        H (float): Höhe des Angriffspunktes der Zugkraft über dem Stammfuß (in m)\n",
    "        h (float): Höhe des Berechnungspunktes über dem Boden (in m)\n",
    "        d (float): Durchmesser des Stammquerschnitts auf Höhe h (in m)\n",
    "        E (float): Elastizitätsmodul des Holzes (in MPa)\n",
    "    \n",
    "    Returns:\n",
    "        float: Berechnete Randfaserdehnung epsilon (dimensionslos)\n",
    "    \"\"\"\n",
    "    force_N = force * 1000  # Umrechnung der Zugkraft von kN in N\n",
    "    M = force_N * (H - h)  # Biegemoment in N·m\n",
    "    y_max = d / 2  # maximaler Abstand zur neutralen Achse in m\n",
    "    I = (np.pi / 64) * d**4  # Flächenträgheitsmoment in m^4\n",
    "    E_Pa = E * 1e6  # Umrechnung des Elastizitätsmoduls von MPa in N/m^2\n",
    "    epsilon = (M * y_max) / (E_Pa * I)  # Dehnung in Dezimalschreibweise\n",
    "    return epsilon\n",
    "\n",
    "# Funktion zur Berechnung der absoluten Längenänderung\n",
    "def calculate_delta_l(epsilon: float, l0: float) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet die absolute Längenänderung Delta L in Mikrometer.\n",
    "    \n",
    "    Parameters:\n",
    "        epsilon (float): Relative Dehnung (dimensionslos)\n",
    "        l0 (float): Ausgangslänge des Elastometers (in mm)\n",
    "    \n",
    "    Returns:\n",
    "        float: Absolute Längenänderung Delta L in Mikrometer (µm)\n",
    "    \"\"\"\n",
    "    l0_m = l0 / 1000  # Umrechnung der Ausgangslänge von mm in m\n",
    "    delta_L = epsilon * l0_m * 1e6  # Umrechnung der Längenänderung in µm\n",
    "    return delta_L\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.871169800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fixwerte\n",
    "l0 = 200  # mm, Ausgangslänge Elastometer\n",
    "E = 8500  # Elastizitätsmodul Buche in MPa\n",
    "height_rope = 18.30  # m, Höhe des Angriffspunktes der Zugkraft\n",
    "\n",
    "# Berechnung der neuen Spalten\n",
    "df['calc_max_strain_relativ'] = df.apply(lambda row: calculate_epsilon(\n",
    "    row['rope_release'], height_rope, row['height'], row['diameter'], E), axis=1)\n",
    "df['calc_max_strain'] = df['calc_max_strain_relativ'].apply(lambda epsilon: calculate_delta_l(epsilon, l0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.871169800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Berechnung der Differenz und der absoluten Differenz in Prozent\n",
    "df['strain_difference'] = (df['calc_max_strain'] - df['max_strain']) / df['max_strain'] * 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.871169800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.871169800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grouping DataFrame by 'ptq_sensor_name'\n",
    "grouped = df.groupby('sensor_name')\n",
    "\n",
    "# Perform linear regression and plot for each group\n",
    "for name, group in grouped:\n",
    "    # Linear Regression with statsmodels\n",
    "    X = sm.add_constant(group['max_strain'])  # Adding a constant for the intercept\n",
    "    y = group['calc_max_strain']\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    # Print the summary of the linear regression model\n",
    "    print(f\"Linear Regression Summary for {name}:\\n\")\n",
    "    print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.886797100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Achsenvariablen definieren\n",
    "x_key = 'max_strain'\n",
    "y_key = 'calc_max_strain'\n",
    "\n",
    "# Dynamische Labels und Titel erzeugen\n",
    "x_label = get_axis_label(x_key, data_dict)\n",
    "y_label = get_axis_label(y_key, data_dict)\n",
    "plot_title = get_plot_title(x_key, y_key, data_dict, prefix=\"Regression\")\n",
    "filename = get_filename(x_key, y_key, prefix=\"regression\")\n",
    "legend_title = get_legend_title(\"sensor_name\", data_dict)\n",
    "\n",
    "# Plot erstellen\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, group in df.groupby('sensor_name', observed=False):\n",
    "    sns.regplot(\n",
    "        x=group[x_key],\n",
    "        y=group[y_key],\n",
    "        color=sensor_color_dict.get(name, \"gray\"),\n",
    "        label=name,\n",
    "        scatter_kws={\"s\": 40}\n",
    "    )\n",
    "\n",
    "plt.title(plot_title)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.legend(title=legend_title)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot speichern\n",
    "PLOT_MANAGER.save_plot(fig, filename=filename, subdir=\"measured_vs_calc_strain\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.886797100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Berechnung von Mittelwerten und Standardabweichungen\n",
    "df_strain_stats = df.groupby('sensor_name').agg(\n",
    "    calc_max_strain_mean=('calc_max_strain', 'mean'),\n",
    "    calc_max_strain_sd=('calc_max_strain', 'std'),\n",
    "    ptq_max_strain_mean=('max_strain', 'mean'),\n",
    "    ptq_max_strain_sd=('max_strain', 'std'),\n",
    "    strain_difference_mean=('strain_difference', 'mean'),\n",
    "    strain_difference_sd=('strain_difference', 'std')\n",
    ")\n",
    "# Automatische Umbenennung der Spalten basierend auf data_dict\n",
    "columns_new = [(data_dict[var]['Zeichen'], stat) for var, stat in zip(\n",
    "    ['calc_max_strain', 'calc_max_strain', 'max_strain', 'max_strain', 'strain_difference', 'strain_difference'],\n",
    "    ['mean', 'sd', 'mean', 'sd', 'mean', 'sd']\n",
    ")]\n",
    "df_strain_stats.columns = pd.MultiIndex.from_tuples(columns_new)\n",
    "df_strain_stats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.886797100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Berechnung des MAPE\n",
    "strain_difference_mape = df['strain_difference'].abs().mean().round(2)\n",
    "strain_difference_mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.886797100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Automatische Einheitenzuweisung\n",
    "df_units = pd.DataFrame([[data_dict[var]['Einheit'] for var in ['calc_max_strain', 'calc_max_strain', 'max_strain', 'max_strain', 'strain_difference', 'strain_difference']]],\n",
    "                        columns=df_strain_stats.columns, index=['Einheit'])\n",
    "\n",
    "# MAPE als eigene Zeile hinzufügen\n",
    "df_mape = pd.DataFrame([['', '', '', '', strain_difference_mape, '']], \n",
    "                        columns=df_strain_stats.columns, index=['MAPE'])\n",
    "\n",
    "# DataFrames zusammenführen\n",
    "df_strain_stats_add = pd.concat([df_units, df_strain_stats, df_mape])\n",
    "df_strain_stats_add"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.902420800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Konvertierung des DataFrames mit Multi-Index-Spalten in einen LaTeX-String\n",
    "latex_string = df_strain_stats_add.to_latex(\n",
    "    index=True,\n",
    "    escape=False,\n",
    "    float_format=\"{:0.2f}\".format,\n",
    "    multicolumn=True,\n",
    "    multicolumn_format=\"c\",\n",
    "    column_format=\"l|rr|rr|rr\"\n",
    ")\n",
    "\n",
    "# Definition der Beschriftung für die LaTeX-Tabelle\n",
    "caption = \"Feldversuch 2 - Ergebnisse, Zusammenfassung Vergleich gemessene und rechnerische Faserdehnung \"\n",
    "caption_long = \"Feldversuch 2 - Ergebnisse, Zusammenfassung Vergleich gemessene und rechnerische Faserdehnung, Mittelwerte und Standardabweichungen der Abweichung der rechnerischen von der gemessenen maximalen Dehnung, gruppiert über Elastometer bzw. Position\"\n",
    "\n",
    "save_latex_table(latex_string, caption, latex_export_directory, caption_long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.902420800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create violin plot for strain_difference grouped by sensor_name\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='sensor_name', y='strain_difference', hue='sensor_name', palette=sensor_color_dict, data=df)\n",
    "plt.title('Difference between measured and calculated strain')\n",
    "plt.xlabel('PTQ Sensor Name / Position')\n",
    "plt.ylabel('Strain Difference (%)')\n",
    "# Layout anpassen und Plot anzeigen\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"diff_measured_vs_calc_strain\", subdir=\"measured_vs_calc_strain\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.902420800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Theoretische Berechnungen der Belastung der KS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_force(epsilon: float, H: float, h: float, d: float, E: float) -> float:\n",
    "    \"\"\"\n",
    "    Berechnet die Zugkraft force (in kN) basierend auf der Randfaserdehnung epsilon bzw. der Dehnung an der Elastizitätsgrenze.\n",
    "    \n",
    "    Parameters:\n",
    "        epsilon (float): Randfaserdehnung (dimensionslos, nicht in %)\n",
    "        H (float): Höhe des Angriffspunktes der Zugkraft über dem Stammfuß (m)\n",
    "        h (float): Höhe des Berechnungspunktes über dem Boden (m)\n",
    "        d (float): Durchmesser des Stammquerschnitts auf Höhe h (m)\n",
    "        E (float): Elastizitätsmodul des Holzes (in MPa)\n",
    "    \n",
    "    Returns:\n",
    "        float: Berechnete Zugkraft force (in kN)\n",
    "    \"\"\"\n",
    "    y_max = d / 2  # maximaler Abstand zur neutralen Achse in m\n",
    "    I = (np.pi / 64) * d**4  # Flächenträgheitsmoment in m^4\n",
    "    E_Pa = E * 1e6  # Umrechnung des Elastizitätsmoduls von MPa in N/m^2\n",
    "    force_N = (epsilon * E_Pa * I) / ((H - h) * y_max)  # Zugkraft in N\n",
    "    force_kN = force_N / 1000  # Umrechnung in kN\n",
    "    return force_kN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.902420800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fixwerte\n",
    "epsilon = 0.0026  # Elastizitätsgrenze Buche\n",
    "E = 8500  # Elastizitätsmodul Buche in MPa\n",
    "height_ks = 17.40  # m, Höhe des Angriffspunktes der KS\n",
    "height_forke = 10.31  # m, Höhe des Zwiesels\n",
    "stem_diameter = 0.35  # m, Durchmesser des Stammes knapp über dem Zwiesel\n",
    "\n",
    "# Berechnung der Zugkraft\n",
    "force = calculate_force(epsilon, height_ks, height_forke, stem_diameter, E)\n",
    "force"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.918045500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_height = (26.15 + 27.2)/2\n",
    "optimal_ks_height = ((tree_height - height_forke) * (2/3)) + height_forke\n",
    "optimal_ks_height"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.918045500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "force = calculate_force(epsilon, optimal_ks_height, height_forke, stem_diameter, E)\n",
    "force"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.918045500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PTQ: Analyse der Dehnungswerte nach Elastometer und Behandlungsvarianten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotten der Maximalwerte der Vorspannung für Dehnung und Stauchung. Für jede Messung werden erst die maximalen Werte berechnet und dann getrennt nach Elasto die Verteilung im Boxplot dargestellt.\n",
    "Auffällig ist Elasto(90) mit den höchsten Dehnungswerten. Dieses Gerät ist am geringfügig dünneren Stämmling angebracht. Die Vorspannung wurde aufgrund der maximalen Messwerte von 429 µm nicht weiter erhöht."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Erstelle die Subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Boxplot für die minimalen Werte (maximale Compression)\n",
    "sns.boxplot(data=df, x='sensor_name', y='max_compression', hue='sensor_name', palette=sensor_color_dict, ax=axs[0], legend=False)\n",
    "axs[0].set_title(\"Maximum Compression per Elasto\")\n",
    "axs[0].set_xlabel(\"Elasto Name\")\n",
    "axs[0].set_ylabel(\"fiber compression [µm]\")\n",
    "\n",
    "# Boxplot für die maximalen Werte (maximale Strain)\n",
    "sns.boxplot(data=df, x='sensor_name', y='max_strain', hue='sensor_name', palette=sensor_color_dict, ax=axs[1], legend=False)\n",
    "axs[1].set_title(\"Maximum Strain per Elasto\")\n",
    "axs[1].set_xlabel(\"Elasto Name\")\n",
    "axs[1].set_ylabel(\"fiber strain [µm]\")\n",
    "\n",
    "# Layout anpassen und Plot anzeigen\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"strain_max_per_elasto\", subdir=\"strain_max_per_elasto\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.918045500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Mixed-Effects Model\n",
    "# model = smf.mixedlm(\n",
    "#     \"max_compression ~ C(treatment) + C(sensor_name) + rope_release\",\n",
    "#     data=df,\n",
    "#     groups=df[\"id\"]  # Gruppierung nach Beobachtungsgruppe\n",
    "# ).fit()\n",
    "# \n",
    "# # Ergebnisse\n",
    "# print(model.summary())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.933670500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Tukey HSD Test für die 'treatment' Gruppe\n",
    "# tukey_treatment = mc.pairwise_tukeyhsd(endog=df['max_compression'],\n",
    "#                                     groups=df['treatment'],\n",
    "#                                     alpha=0.05)\n",
    "# print(tukey_treatment)\n",
    "# \n",
    "# # Tukey HSD Test für die 'sensor_name' Gruppe\n",
    "# tukey_sensor = mc.pairwise_tukeyhsd(endog=df['max_compression'],\n",
    "#                                  groups=df['sensor_name'],\n",
    "#                                  alpha=0.05)\n",
    "# print(tukey_sensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.933670500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined: Latex-Export von Daten für Anhang"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_grouped_latex_tables(df_latex: pd.DataFrame, caption: str, column_format: str, group_by: str, latex_export_directory: Path) -> None:\n",
    "    \"\"\"\n",
    "    Generate grouped LaTeX tables for each unique value in a specified column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df_latex (pd.DataFrame): The DataFrame with already formatted columns.\n",
    "        caption (str): The caption for the LaTeX tables.\n",
    "        column_format (str): The format for the LaTeX tables.\n",
    "        group_by (str): The column name to group by.\n",
    "        latex_export_directory (Path): The directory to save the LaTeX tables.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # DataFrame grouped by specified column\n",
    "        grouped = df_latex.groupby(group_by, observed=True)\n",
    "\n",
    "        # LaTeX tables to be combined in a single file\n",
    "        combined_tables = []\n",
    "\n",
    "        for group, group_df in grouped:\n",
    "            # Drop the group_by column\n",
    "            group_df = group_df.drop(columns=[group_by])\n",
    "\n",
    "            # Format 'id' column as string if it exists\n",
    "            if 'id' in group_df.columns:\n",
    "                group_df['id'] = group_df['id'].astype(str)\n",
    "\n",
    "            # Calculate statistics\n",
    "            mean_row = group_df.mean(numeric_only=True).rename('Mean')\n",
    "            median_row = group_df.median(numeric_only=True).rename('Median')\n",
    "            sd_row = group_df.std(numeric_only=True).rename('SD')\n",
    "\n",
    "            # Combine stats with original DataFrame\n",
    "            stats_df = pd.concat([group_df, mean_row.to_frame().T, median_row.to_frame().T, sd_row.to_frame().T])\n",
    "\n",
    "            # Generate LaTeX string from DataFrame\n",
    "            df_latex_string = stats_df.to_latex(\n",
    "                index=True,\n",
    "                escape=False,\n",
    "                column_format=column_format,\n",
    "                float_format=\"{:0.2f}\".format\n",
    "            )\n",
    "\n",
    "            # Create caption and label for the group\n",
    "            caption_text = create_caption(caption, f\"{caption} für {slugify(group, separator=' ')}\")\n",
    "            label_clean = create_label(caption=caption, additional_label=group)\n",
    "\n",
    "            # Generate LaTeX table\n",
    "            latex_table = generate_latex_table(df_latex_string, caption_text, label_clean)\n",
    "\n",
    "            combined_tables.append(latex_table)\n",
    "\n",
    "        # Combine all tables and save to a single file\n",
    "        if combined_tables:\n",
    "            final_output = \"\\n\\n\".join(combined_tables)\n",
    "            file_name = create_label(caption) + \".tex\"\n",
    "            save_to_file(final_output, latex_export_directory / file_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating grouped LaTeX tables: {e}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.940235900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Liste der benötigten Variablen\n",
    "variables = [\"id\", \"treatment\", \"sensor_name\", \"location\", \"height\", \"diameter\", \"rope_release\", \"max_strain\", \"calc_max_strain\", \"strain_difference\"]\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Vergleich gemessene und rechnerische Faserdehnung\",\n",
    "    column_format=\"lll|lrrr|rrr\",\n",
    "    group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.942298600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variables = ['id', 'sensor_name', 'treatment', 'release_force_target', 'rope_release', 'cable_max', 'max_strain', 'max_compression',]\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Kräfte und Dehnungen\",\n",
    "    column_format=\"lrl|rrr|rr\",\n",
    "        group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.942298600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variables_2 = ['id', 'sensor_name', 'treatment', 'm_amplitude', 'm_amplitude_2', 'initial_amplitude', 'damping_coeff', 'damping_ratio', 'frequency_damped', 'frequency_undamped', 'y_shift', 'pearson_r', 'nmae']\n",
    "\n",
    "# DataFrame kopieren und die gewünschten Spalten auswählen\n",
    "df_latex = df.copy()[variables_2]\n",
    "\n",
    "# Spaltennamen mit den Kurzbezeichnungen (Zeichen) aus dem data_dict umbenennen\n",
    "df_latex = df_latex.rename(columns={var: data_dict[var][\"Zeichen\"] for var in variables_2})\n",
    "# Funktionsaufruf mit Beispielparametern\n",
    "generate_grouped_latex_tables(\n",
    "    df_latex=df_latex,\n",
    "    caption=\"Feldversuch 2 - Ergebnisse, Schwingungsparameter\",\n",
    "    column_format=\"lrl|rrr|rr|rr|r|rr\",\n",
    "    group_by=\"treatment\",\n",
    "    latex_export_directory=latex_export_directory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.942298600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PTQ: Analyse der Schwingungsparameter\n",
    "\n",
    "In diesem Abschnitt werden die Schwingungsparameter statistisch ausgewertet. Ziel ist es, den Einfluss verschiedener Behandlungsvarianten (treatment) auf die gemessenen Schwingungsparameter zu untersuchen und dabei auch den potenziellen Einfluss der Vorspannung (rope_release) und Sensorposition (sensor_name) zu berücksichtigen.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.952429200Z"
    }
   },
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'm_amplitude', \n",
    "    'm_amplitude_2',\n",
    "    'max_strain',\n",
    "    'max_compression',\n",
    "    'initial_amplitude',\n",
    "    'damping_coeff', \n",
    "    'damping_ratio', \n",
    "    'frequency_damped', \n",
    "    'frequency_undamped',\n",
    "    'pearson_r',\n",
    "    #'nrmse', \n",
    "    'nmae'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Systematischer Einfluss der Sensorposition\n",
    "\n",
    "Ziel: Visuell erkennen, ob unterschiedliche Sensoren konsistent andere Werte liefern und ob dieser Effekt die Interpretation der treatment-Effekte erschwert."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "for var in variables:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"sensor_name\", y=var, data=df, hue=\"treatment\", palette=treatment_color_dict,  dodge=True)\n",
    "    # Stripplot: Punkte zur Veranschaulichung der Verteilung\n",
    "    sns.stripplot(x=\"sensor_name\", y=var, data=df, hue=\"treatment\", palette=treatment_color_dict, dodge=True, alpha=1, jitter=True, size=5, legend=False)\n",
    "    # Titel und Achsentitel setzen\n",
    "    plt.title(f\"Einfluss von treatment auf {var} gruppiert über sensor_name\")\n",
    "    plt.xlabel(\"Sensor Name\")\n",
    "    plt.ylabel(var)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_sensor_treatment_{var}\", subdir=\"combined/sensor\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.952429200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Systematischer Einfluss der Behandlungsvariante\n",
    "\n",
    "Ziel: Feststellen, ob die Variation durch unterschiedliche Behandlungen relativ zur sensorbedingten Variation unterscheidbar ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "for var in variables:\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"treatment\", y=var, data=df, palette=sensor_color_dict, hue='sensor_name')\n",
    "    sns.stripplot(x=\"treatment\", y=var, data=df, palette=sensor_color_dict, hue='sensor_name', dodge=True, alpha=1, jitter=True, size=5, legend=False)\n",
    "    plt.title(f\"Einfluss von sensor_name auf {var} gruppiert über treatment\")\n",
    "    plt.xlabel(\"treatment\")\n",
    "    plt.ylabel(var)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"effect_treatment_sensor_{var}\", subdir=\"combined/treatment\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.952429200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Versuche Mixed-Linear Model\n",
    "Die Daten sind hierarchisch: Mehrere Messungen (vier Sensoren) pro Beobachtungseinheit (`id`). Ein Mixed-Effects Modell könnte diese Struktur abbilden, indem zufällige Effekte für `id` und feste Effekte für `treatment` sowie `sensor_name` genutzt werden. Zusätzlich könnte `rope_release` als Kovariate eingeführt werden.\n",
    "\n",
    "Diese Modelle wären theoretisch präziser, aber aufgrund der geringen Stichprobengröße und der komplexen Datenstruktur treten Konvergenzprobleme auf.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ergebnisse als Dictionary speichern\n",
    "results_dict = {}\n",
    "\n",
    "for var in variables:\n",
    "    # Formel für MixedLM: Parameter ~ C(treatment) + C(sensor_name) + rope_release + (1|id)\n",
    "    formula = f\"{var} ~ C(treatment) + C(sensor_name)\" #  +  rope_release\n",
    "    model = smf.mixedlm(formula, data=df, groups=df[\"id\"])\n",
    "    \n",
    "    # Modell fitten\n",
    "    fit = model.fit(reml=True)  # REML ist Standard für gemischte Modelle\n",
    "    \n",
    "    # Ergebnisse ausgeben\n",
    "    print(f\"\\n### Ergebnisse für {var} ###\")\n",
    "    print(fit.summary())\n",
    "    \n",
    "    # Überprüfen, ob das Modell konvergiert ist\n",
    "    if not fit.converged:\n",
    "        print(\"Achtung: Das Modell ist nicht konvergiert. Erwägen Sie Anpassungen (z.B. Skalierung der Daten).\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.962561700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vereinfachtes Vorgehen durch Aggregation (Mittelung über Sensoren)\n",
    "\n",
    "Um dennoch aussagekräftige Aussagen zu erhalten, werden die Messungen pro `id` über alle Sensoren gemittelt. Dadurch geht zwar die Variation aufgrund unterschiedlicher Sensoren verloren, aber es entsteht ein stabileres Datenset, in dem jede `id` einen aggregierten Wert pro Parameter hat.\n",
    "\n",
    "Auf dieser Basis können einfache OLS-Modelle geschätzt werden, z. B. `Parameter ~ C(treatment) + rope_release`. Diese Modelle sind einfacher und sollten stabil konvergieren."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Placeholder for results\n",
    "results = {}\n",
    "\n",
    "# Step 1: Compute the mean of each variable for each id\n",
    "grouped_df = df.groupby(\"id\").agg(\n",
    "    {var: \"mean\" for var in variables}\n",
    ").reset_index()\n",
    "\n",
    "# Add additional variables (e.g., treatment and rope_release) to the aggregated data\n",
    "grouped_df = grouped_df.merge(\n",
    "    df[[\"id\", \"treatment\", \"rope_release\"]].drop_duplicates(), on=\"id\"\n",
    ")\n",
    "\n",
    "# Step 2: Fit linear models to the aggregated data\n",
    "for var in variables:\n",
    "    try:\n",
    "        # Fit a linear model\n",
    "        model = smf.ols(f\"{var} ~ C(treatment) + rope_release\", grouped_df).fit()\n",
    "\n",
    "        # Store relevant results\n",
    "        results[var] = {\n",
    "            \"p_value_treatment\": model.pvalues.get(\"treatment[T.statisch]\", None),\n",
    "            \"p_value_rope_release\": model.pvalues.get(\"rope_release\", None),\n",
    "            \"summary\": model.summary()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        results[var] = {\"error\": str(e)}\n",
    "\n",
    "# Display results\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.962561700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nicht jeder Parameter wird durch `rope_release` beeinflusst. Nur für jene Parameter, bei denen ein signifikanter Einfluss von `rope_release` festgestellt wird, soll dieser Effekt herausgerechnet werden. Auf diese Weise entstehen \"bereinigte\" Werte, in denen der lineare Einfluss von `rope_release` entfernt ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Placeholder for results\n",
    "# Dieses Dictionary wird nun sowohl die Modellobjekte als auch die Kennwerte speichern.\n",
    "results = {}\n",
    "\n",
    "# Liste der Variablen, für die rope_release berücksichtigt wird\n",
    "relevant_vars_rope_release = ['m_amplitude', 'm_amplitude_2', 'max_strain', 'max_compression']\n",
    "\n",
    "# Step 1: Compute the mean of each variable for each id\n",
    "grouped_df = df.groupby(\"id\").agg(\n",
    "    {var: \"mean\" for var in variables}\n",
    ").reset_index()\n",
    "\n",
    "# Add additional variables (e.g., treatment and rope_release) to the aggregated data\n",
    "grouped_df = grouped_df.merge(\n",
    "    df[[\"id\", \"treatment\", \"rope_release\"]].drop_duplicates(), on=\"id\"\n",
    ")\n",
    "\n",
    "# Step 2: Fit linear models to the aggregated data and store model objects and p-Werte in results\n",
    "for var in variables:\n",
    "    # Formuliere das Modell dynamisch, abhängig davon, ob rope_release relevant ist\n",
    "    if var in relevant_vars_rope_release:\n",
    "        formula = f\"{var} ~ C(treatment) + rope_release\"\n",
    "    else:\n",
    "        formula = f\"{var} ~ C(treatment)\"\n",
    "\n",
    "    try:\n",
    "        # Fit a linear model\n",
    "        model = smf.ols(formula, grouped_df).fit()\n",
    "\n",
    "        # Store model and relevant results directly in results\n",
    "        results[var] = {\n",
    "            \"model\": model,\n",
    "            \"p_value_treatment\": model.pvalues.get(\"treatment[T.statisch]\", None),\n",
    "            \"p_value_rope_release\": model.pvalues.get(\"rope_release\", None) if var in relevant_vars_rope_release else None,\n",
    "            \"summary\": model.summary()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        results[var] = {\"error\": str(e)}\n",
    "\n",
    "# Display results\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.962561700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Beispiel für m_amplitude\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lmplot(data=grouped_df, x='rope_release', y='m_amplitude_2', hue='treatment', ci=95)\n",
    "plt.title('Einfluss von rope_release auf m_amplitude für verschiedene Treatments')\n",
    "plt.xlabel('rope_release (kN)')\n",
    "plt.ylabel('m_amplitude')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.970725400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=grouped_df, x='treatment', y='m_amplitude')\n",
    "plt.title('Vergleich von m_amplitude zwischen den Treatments')\n",
    "plt.xlabel('Treatment')\n",
    "plt.ylabel('m_amplitude')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.972866700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "\n",
    "# Liste der Variablen, die in die Tabelle übernommen werden sollen\n",
    "variables_spec = [\n",
    "    'm_amplitude_2',\n",
    "    'max_compression',\n",
    "    'damping_coeff',\n",
    "    'damping_ratio',\n",
    "    'frequency_damped',\n",
    "    'frequency_undamped',\n",
    "]\n",
    "\n",
    "# Umbenennung der Spalten für LaTeX-Notation\n",
    "column_rename_map = {\n",
    "    'm_amplitude_2': r'$mA_2$',\n",
    "    'max_compression': r'$\\text{max\\_C}$',\n",
    "    'damping_coeff': r'$\\delta$',\n",
    "    'damping_ratio': r'$D$',\n",
    "    'frequency_damped': r'$f_d$',\n",
    "    'frequency_undamped': r'$f_0$',\n",
    "}\n",
    "\n",
    "# Funktion zur Erstellung der Modellgüte-Kennzahlen für alle Variablen\n",
    "def create_model_metrics_table(variables, results):\n",
    "    metrics_data = {\n",
    "        \"Kennzahl\": [\"R²\", \"Adj. R²\", \"F-St.\", \"AIC\", \"N\"]\n",
    "    }\n",
    "\n",
    "    for var in variables:\n",
    "        col_name = column_rename_map.get(var, var)  # Verwende gekürzten Namen, falls vorhanden\n",
    "        if var not in results or 'error' in results[var]:\n",
    "            metrics_data[col_name] = [\"n/a\"] * 5\n",
    "        else:\n",
    "            model = results[var]['model']\n",
    "            metrics_data[col_name] = [\n",
    "                f\"{model.rsquared:.4f}\",\n",
    "                f\"{model.rsquared_adj:.4f}\",\n",
    "                f\"{model.fvalue:.4f}\",\n",
    "                f\"{model.aic:.4f}\",\n",
    "                f\"{model.nobs:.0f}\"\n",
    "            ]\n",
    "\n",
    "    # Erstelle die Tabelle mit tabulate\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    return tabulate(\n",
    "        metrics_df,\n",
    "        headers=\"keys\",\n",
    "        tablefmt=\"latex_raw\",\n",
    "        floatfmt=\".4f\",\n",
    "        showindex=False)\n",
    "\n",
    "# Funktion zur Erstellung einer LaTeX-Tabelle für die Koeffizienten einer Variable\n",
    "def create_latex_table_for_variable(var, results):\n",
    "    if var not in results:\n",
    "        return f\"%% Keine Ergebnisse für Variable {var} vorhanden.\"\n",
    "    \n",
    "    model_result = results[var]\n",
    "    if 'error' in model_result:\n",
    "        return f\"%% Fehler beim Anpassen des Modells für {var}: {model_result['error']}\"\n",
    "    \n",
    "    model = model_result['model']\n",
    "    summary = model.summary2().tables[1]  # Zugriff auf die Tabelle der Koeffizienten\n",
    "\n",
    "    # Erstelle eine LaTeX-Tabelle mit tabulate für die Koeffizienten\n",
    "    latex_table = tabulate(\n",
    "        summary,\n",
    "        headers=summary.columns,\n",
    "        tablefmt=\"latex_booktabs\",\n",
    "        floatfmt=\".4f\",\n",
    "        showindex=True\n",
    "    )\n",
    "\n",
    "    # Escape Unterstriche in der Variable für LaTeX\n",
    "    escaped_var = re.sub(r'_', r'\\_', var)\n",
    "    shortened_var = column_rename_map.get(var, escaped_var)\n",
    "\n",
    "    # Füge die LaTeX-Caption zur Tabelle hinzu\n",
    "    return f\"\"\"\n",
    "\\\\begin{{table}}[ht]\n",
    "    \\\\centering\n",
    "    \\\\caption{{Modellzusammenfassung für {escaped_var} ({shortened_var})}}\n",
    "    \\\\begin{{adjustbox}}{{max width=\\\\textwidth}}\n",
    "    {latex_table}\n",
    "    \\\\end{{adjustbox}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "# Erstelle die Modellgüte-Tabelle für alle Variablen\n",
    "latex_metrics_table = create_model_metrics_table(variables_spec, results)\n",
    "print(\"\"\"\n",
    "\\\\begin{table}[ht]\n",
    "    \\\\centering\n",
    "    \\\\caption{Modellgüte für alle Variablen}\n",
    "    \\\\begin{adjustbox}{max width=\\\\textwidth}\n",
    "\"\"\")\n",
    "print(latex_metrics_table)\n",
    "print(\"\"\"\n",
    "    \\\\end{adjustbox}\n",
    "\\\\end{table}\n",
    "\n",
    "\\\\vspace{1cm}\n",
    "\"\"\")\n",
    "\n",
    "# Erstelle und print die LaTeX-Tabellen für die Koeffizienten jeder Variable\n",
    "for var in variables_spec:\n",
    "    latex_output = create_latex_table_for_variable(var, results)\n",
    "    print(latex_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.972866700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables), 2, (len(variables) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_with_rope_release\", subdir=\"combined\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.972866700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Für die betroffenen Parameter wird der Einfluss von `rope_release` mithilfe der bereits angepassten Modelle (`Parameter ~ C(treatment) + rope_release`) entfernt. Dazu werden Vorhersagen für einen konstanten `rope_release`-Wert (den Mittelwert) berechnet und mit den tatsächlichen Werten verglichen. Die daraus resultierenden bereinigten Werte sind frei von Variation, die auf `rope_release` zurückzuführen wäre."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_adjusted_df = grouped_df.copy()\n",
    "\n",
    "# Bereinigung: Wir setzen rope_release auf seinen Mittelwert\n",
    "rope_mean = grouped_df[\"rope_release\"].mean()\n",
    "\n",
    "for var in relevant_vars_rope_release:\n",
    "    # Zugehöriges Modellobjekt abrufen\n",
    "    model = results[var][\"model\"]\n",
    "\n",
    "    # Vorhersage mit tatsächlichen rope_release-Werten\n",
    "    predicted_current = model.predict(grouped_df)\n",
    "\n",
    "    # Vorhersage, wenn rope_release = rope_mean gesetzt wird\n",
    "    df_mean_rope = grouped_df.copy()\n",
    "    df_mean_rope[\"rope_release\"] = rope_mean\n",
    "    predicted_mean = model.predict(df_mean_rope)\n",
    "\n",
    "    # Angepasste Werte berechnen:\n",
    "    actual = grouped_df[var].values\n",
    "    adjusted = actual + (predicted_mean - predicted_current)\n",
    "    grouped_adjusted_df[var] = adjusted"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.972866700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.981016400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_adjusted_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.983152600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Latex Tabelle Output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.983152600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DataFrame mit den relevanten Spalten erstellen\n",
    "variables_latex = [\n",
    "    'm_amplitude', \n",
    "    'm_amplitude_2',\n",
    "    'initial_amplitude',\n",
    "    'damping_coeff', \n",
    "    'damping_ratio', \n",
    "    'frequency_damped', \n",
    "    'frequency_undamped',\n",
    "    'pearson_r',\n",
    "    'nmae'\n",
    "]\n",
    "df_latex = grouped_adjusted_df[variables_latex + ['treatment']].copy()\n",
    "df_latex.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.983152600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Spaltennamen entsprechend der LaTeX-Notation umbenennen\n",
    "df_latex.rename(columns=data_dict, inplace=True)\n",
    "\n",
    "# Erstellung deskriptiver Statistiken für alle Beobachtungen\n",
    "overall_stats = df_latex.describe().drop(index=['count', '25%', '75%'])\n",
    "overall_stats.rename(index={'50%': 'median'}, inplace=True)\n",
    "\n",
    "# Erstellung der deskriptiven Statistiken für jede Gruppe\n",
    "grouped_stats = {\n",
    "    'overall': overall_stats\n",
    "}\n",
    "\n",
    "for treatment, group in df_latex.groupby('treatment', observed=True):\n",
    "    group_stats = group.describe().drop(index=['count', '25%', '75%'])\n",
    "    group_stats.rename(index={'50%': 'median'}, inplace=True)\n",
    "    grouped_stats[treatment] = group_stats\n",
    "\n",
    "# Zusammenführen der Statistiken in einer Tabelle\n",
    "combined_stats = pd.concat(grouped_stats, names=['Treatment'])\n",
    "\n",
    "# LaTeX-Export des kombinierten DataFrames\n",
    "df_latex_string = combined_stats.to_latex(\n",
    "    escape=False,\n",
    "    multirow=True,\n",
    "    multicolumn=True,\n",
    "    column_format=\"l|lrrrrrrrrr\", \n",
    "    float_format=\"{:0.2f}\".format\n",
    ")\n",
    "\n",
    "# LaTeX-Tabellencode erstellen\n",
    "latex_table = f\"\"\"\n",
    "\\\\begin{{table}}[h]\n",
    "    \\\\centering\n",
    "    \\\\caption{{Feldversuch 2 - Ergebnisse, Schwingungsparameter deskriptive Statistiken (Gesamt und gruppiert über Treatment), Amplituden korrigiert über \\\\texttt{{rope\\\\_release}}, 9 Beobachtung je Gruppe, jeweils Mittelwert für 4 Elastometer}}\n",
    "    \\\\begin{{adjustbox}}{{max width=\\\\textwidth}}\n",
    "    {df_latex_string}\n",
    "    \\\\end{{adjustbox}}\n",
    "    \\\\label{{tab:Feldversuch_2_Deskriptive_Statistiken_Schwingungsparameter}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.983152600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualisierung der bereinigten Ergebnisse\n",
    "\n",
    "Abschließend werden die bereinigten Werte grafisch dargestellt, um die Unterschiede zwischen den Behandlungen in Abwesenheit des `rope_release`-Einflusses zu verdeutlichen. Dies zeigt, wie sich die Treatments auf die Parameter auswirken würden, wenn für alle Einheiten die gleiche mittlere Vorspannung gelten würde."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "relevant_vars_rope_release = ['m_amplitude', 'm_amplitude_2', 'max_strain', 'max_compression']\n",
    "\n",
    "n_vars = len(relevant_vars_rope_release)\n",
    "n_cols = 2  # Links Original, rechts angepasst\n",
    "n_rows = n_vars  # Eine Zeile pro Variable\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "\n",
    "for i, var in enumerate(relevant_vars_rope_release):\n",
    "    # Linke Spalte: Original (grouped_df)\n",
    "    sns.boxplot(ax=axes[i,0], x=\"treatment\", y=var, data=grouped_df, \n",
    "                palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i,0], x=\"treatment\", y=var, data=grouped_df, \n",
    "                  dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i,0].set_title(f\"original: {var}\")\n",
    "    axes[i,0].set_ylabel(var)\n",
    "\n",
    "    # Rechte Spalte: Angepasst (grouped_adjusted_df)\n",
    "    sns.boxplot(ax=axes[i,1], x=\"treatment\", y=var, data=grouped_adjusted_df, \n",
    "                palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i,1], x=\"treatment\", y=var, data=grouped_adjusted_df, \n",
    "                  dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i,1].set_title(f\"adjusted : {var}\")\n",
    "    axes[i,1].set_ylabel(var)\n",
    "    \n",
    "    # Y-Limits von links holen\n",
    "    y_min, y_max = axes[i,0].get_ylim()\n",
    "    # Y-Limits auf rechts anwenden\n",
    "    axes[i,1].set_ylim(y_min, y_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_comparison\", subdir=\"combined\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.991264800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Schritt 2: Durchführung von Post-hoc-Tests\n",
    "\n",
    "Festzustellen welche paarweisen Unterschiede zwischen den Treatments signifikant sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Wir gehen davon aus, dass grouped_adjusted_df existiert und die Spalten 'treatment' sowie die Variablen aus 'variables' enthält.\n",
    "\n",
    "for var in variables_spec:\n",
    "    # Tukey HSD Test durchführen\n",
    "    # Annahme: Die Spalte 'treatment' enthält die Gruppennamen z.B. 'free', 'gefa_dynamic', 'cobra_static'\n",
    "    # pairwise_tukeyhsd benötigt die abhängige Variable und die Gruppen.\n",
    "    tukey_results = pairwise_tukeyhsd(endog=grouped_adjusted_df[var],\n",
    "                                      groups=grouped_adjusted_df['treatment'],\n",
    "                                      alpha=0.05)\n",
    "    \n",
    "    print(f\"--- Post-Hoc Test (Tukey HSD) für Variable: {var} ---\")\n",
    "    print(tukey_results.summary())\n",
    "    print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.993302400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables_spec), 2, (len(variables_spec) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables_spec):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_without_rope_release\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.993302400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Anzahl der relevanten Variablen und Layout für die Subplots definieren\n",
    "n_vars, n_cols, n_rows = len(variables_spec), 2, (len(variables_spec) + 1) // 2\n",
    "\n",
    "# Subplots erstellen\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Für jede relevante Variable einen Plot erstellen\n",
    "for i, var in enumerate(variables_spec):\n",
    "    sns.boxplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, palette=treatment_color_dict, hue=\"treatment\", legend=False, dodge=False)\n",
    "    sns.stripplot(ax=axes[i], x=\"treatment\", y=var, data=grouped_adjusted_df, dodge=False, c=\"black\", jitter=True, size=5)\n",
    "    axes[i].set_title(f\"Einfluss von Treatment auf {var}\")\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "# Layout anpassen, Plot anzeigen und speichern\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"effect_of_treatment_without_rope_release_spec\", subdir=\"combined\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.993302400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vorhergesagte Werte extrahieren und Boxplots für die Sensoren erstellen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:41.993302400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vorhergesagte Werte aus den Modellen extrahieren\n",
    "for variable in variables:\n",
    "    df[f'predicted_{variable}'] = models[variable].fittedvalues\n",
    "\n",
    "# Boxplots erstellen mit den vorhergesagten Werten\n",
    "fig, axes = plt.subplots(4, 2, figsize=(8, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    sns.boxplot(ax=axes[i], x='treatment', y=f'predicted_{variable}', data=df, palette=treatment_color_dict, hue='treatment', dodge=False, legend=False)\n",
    "    axes[i].set_title(f'{variable} by Treatment')\n",
    "    axes[i].set_xlabel('Treatment')\n",
    "    axes[i].set_ylabel(f'Predicted {variable}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig, filename=\"predicted_effect_for_treatment\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def annotate_tukey(ax, tukey_result, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Fügt eine Textbox mit den Tukey-Test-Ergebnissen und dem festgelegten Signifikanzniveau in den Plot ein.\n",
    "    \n",
    "    Parameters:\n",
    "    ax (matplotlib.axes): Die Achse, auf der der Plot gezeichnet wird.\n",
    "    tukey_result (TukeyHSDResults): Die Ergebnisse des Tukey HSD Tests.\n",
    "    significance_level (float): Das Signifikanzniveau, standardmäßig 0.05.\n",
    "    \"\"\"\n",
    "    # Definiere die gewünschte Reihenfolge der Vergleiche\n",
    "    comparisons_order = [('free', 'gefa_dynamic'), ('free', 'cobra_static'), ('gefa_dynamic', 'cobra_static')]\n",
    "\n",
    "    # Text für die Annotation zusammenstellen\n",
    "    text_str = f\"Tukey HSD Results: \\n(Significance level = {significance_level:.2f})\\n\\n\"\n",
    "    \n",
    "    # Durchlaufe die gewünschte Vergleichsreihenfolge\n",
    "    for group1, group2 in comparisons_order:\n",
    "        # Filtere die korrekte Paarung aus den Tukey-Ergebnissen\n",
    "        for i in range(len(tukey_result._results_table.data[1:])):\n",
    "            pair = tukey_result._results_table.data[i + 1]\n",
    "            if (pair[0] == group1 and pair[1] == group2) or (pair[0] == group2 and pair[1] == group1):\n",
    "                p_value = tukey_result.pvalues[i]\n",
    "                significance = \"*\" if p_value < significance_level else \"n.s.\"\n",
    "                text_str += f\"\\n{group1} vs {group2}: \\np = {p_value:.4f} ({significance})\\n\\n\"\n",
    "    \n",
    "    # Textbox am Rand des Plots hinzufügen\n",
    "    ax.annotate(text_str, xy=(1.01, 0.1), xycoords='axes fraction', va='center', ha='left')\n",
    "\n",
    "# Einzelne Plots für jede Variable erstellen und speichern\n",
    "for variable in variables:\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    # Boxplot für die aktuelle Variable\n",
    "    sns.boxplot(ax=ax, x='treatment', y=f'predicted_{variable}', data=df, \n",
    "                palette=treatment_color_dict, hue='treatment', dodge=False, legend=False)\n",
    "    \n",
    "    # Tukey-Test für die aktuelle Variable\n",
    "    tukey_result = tukey_results[variable]\n",
    "    \n",
    "    # Tukey-Ergebnisse annotieren\n",
    "    annotate_tukey(ax, tukey_result)\n",
    "    \n",
    "    ax.set_title(f'{variable} by Treatment')\n",
    "    ax.set_xlabel('Treatment')\n",
    "    ax.set_ylabel(f'Predicted {variable}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot speichern\n",
    "    plot_filename = f\"{variable}_effect_for_treatment\"\n",
    "    PLOT_MANAGER.save_plot(fig, filename=plot_filename, subdir=\"osc_variables_box\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.001370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.003432900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames nach 'treatment' und Entfernen unnötiger Spalten\n",
    "df_treatment_describe = (df.drop(['id', 'ptq_sensor_name'], axis=1)\n",
    "                         .groupby('treatment', observed=True)\n",
    "                         .describe())\n",
    "\n",
    "df_treatment_describe = df_treatment_describe.reset_index()\n",
    "df_treatment_describe.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.003432900Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.003432900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames nach 'treatment' und Entfernen unnötiger Spalten\n",
    "df_sensor = (df.drop(['id', 'release_force_target', 'ls3_rope_release', 'ls3_cable_max', 'location', 'height', 'diameter', 'direction'], axis=1).\n",
    "             groupby(['treatment', 'ptq_sensor_name'], observed=True).\n",
    "             mean())  #.T\n",
    "#df_sensor.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.003432900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gruppieren des DataFrames und Anwenden von mean für ptq_sensor_name \n",
    "df_id = ((df.drop(['ptq_sensor_name', 'location', 'height', 'diameter', 'direction'], axis=1)\n",
    "          .groupby(['treatment', 'id'], observed=True)\n",
    "          .mean())\n",
    "         .reset_index())\n",
    "\n",
    "df_id.round(4).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zusammenhangsanalyse für LS3 und PTQ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.003432900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Auswahl der neuen Spaltennamen für die Korrelationsmatrix\n",
    "columns_corr = ['ptq_m_amplitude',\n",
    "                'ptq_m_amplitude_2',\n",
    "                'ptq_initial_amplitude',\n",
    "                'ptq_damping_coeff',\n",
    "                'ptq_angular_frequency',\n",
    "                'ptq_y_shift',\n",
    "                'ptq_pearson_r',\n",
    "                #'ptq_nrmse',\n",
    "                'ptq_nmae',\n",
    "                'release_force_target',\n",
    "                'ls3_rope_release',\n",
    "                'ls3_cable_max']\n",
    "df_corr = df_id.copy()[columns_corr]\n",
    "\n",
    "# Berechnung der Korrelationsmatrix\n",
    "correlation_matrix = df_corr.corr()\n",
    "\n",
    "# Visualisierung der Korrelationsmatrix mit Seaborn\n",
    "fig1, ax = plt.subplots(figsize=(8, 8))  # Anpassen der Größe der Grafik\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', ax=ax, annot_kws={'size': 10})\n",
    "\n",
    "# Titel und Schriftgrößen anpassen\n",
    "#plt.title('Correlation Matrix for LS3 and PTQ', fontsize=18)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=12, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize=12, rotation=45, ha='right')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig1, filename=\"correlation_matrix\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.011498800Z"
    }
   },
   "outputs": [],
   "source": [
    "# ANOVA für 'ls3_rope_release'\n",
    "model_rope_release = smf.ols('ls3_rope_release ~ treatment', data=df_id).fit()\n",
    "anova_rope_release = sm.stats.anova_lm(model_rope_release, typ=2)\n",
    "\n",
    "# ANOVA für 'ls3_cable_max'\n",
    "model_cable_max = smf.ols('ls3_cable_max ~ treatment', data=df_id).fit()\n",
    "anova_cable_max = sm.stats.anova_lm(model_cable_max, typ=2)\n",
    "\n",
    "# Zusammenfassungen der Modelle\n",
    "summary_rope_release = model_rope_release.summary()\n",
    "summary_cable_max = model_cable_max.summary()\n",
    "# Zusammenfassungen der Modelle\n",
    "summary_rope_release_latex = model_rope_release.summary().as_latex()\n",
    "summary_cable_max_latex = model_cable_max.summary().as_latex()\n",
    "\n",
    "#print(summary_rope_release_latex)\n",
    "#print(summary_cable_max_latex)\n",
    "\n",
    "anova_rope_release, summary_rope_release, anova_cable_max, summary_cable_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.013523100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung des Text-Strings für die statistischen Parameter\n",
    "def annotate_stats(x, y):\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "    text_str = f\"R = {r_value:.2f}\\nSlope = {slope:.2f}\\nIntercept = {intercept:.2f}\\np-value = {p_value:.2e}\\nStd Err = {std_err:.2f}\"\n",
    "    return text_str"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Zusammenhang Ziel- und Ist-Vorspannung"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.013523100Z"
    }
   },
   "outputs": [],
   "source": [
    "fig2, ax1 = plt.subplots(figsize=(8, 5))\n",
    "sns.regplot(x='release_force_target', y='ls3_rope_release', data=df_id, ax=ax1, color='b', ci=95)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "stats_text = annotate_stats(df_id['release_force_target'], df_id['ls3_rope_release'])\n",
    "ax2.annotate(stats_text, xy=(1.01, 0.1), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Target and Actual Release Forces\"')\n",
    "ax1.set_xlabel('Release Force Target [kN]')\n",
    "ax1.set_ylabel('Release Force [kN]')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig2, filename=f\"release_force_target_vs_ls3_rope_release\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Zusammenhang Vorspannung und resultierende Lastspitzen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.013523100Z"
    }
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ls3_cable_max'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ls3_cable_max', data=subset, ax=ax1, color=color, label=treatment, ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ls3_cable_max'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Peak Cable Force')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Peak Force in Cable [kN]')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"release_force_vs_ls3_cable_max\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.013523100Z"
    }
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ptq_m_amplitude'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ptq_m_amplitude', data=subset, ax=ax1, color=color, label=treatment,\n",
    "                ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ptq_m_amplitude'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Elongation Amplitude')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Elongation Amplitude [$\\mu$m] (mean for all Sensors)')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"ls3_release_force_vs_ptq_m_amplitude\", subdir=\"combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.021632700Z"
    }
   },
   "outputs": [],
   "source": [
    "fig3, ax1 = plt.subplots(figsize=(8, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axis('off')\n",
    "y_pos_init = 0.1\n",
    "for idx, (treatment, color) in enumerate(treatment_color_dict.items()):\n",
    "    subset = df_id[df_id['treatment'] == treatment]\n",
    "    if subset['ptq_m_amplitude_2'].isna().all():\n",
    "        continue\n",
    "    sns.regplot(x='ls3_rope_release', y='ptq_m_amplitude_2', data=subset, ax=ax1, color=color, label=treatment,\n",
    "                ci=95)\n",
    "    stats_text = annotate_stats(subset['ls3_rope_release'], subset['ptq_m_amplitude_2'])\n",
    "    ax2.annotate(f\"{treatment}:\\n{stats_text}\", xy=(1.01, y_pos_init + idx * 0.3), xycoords='axes fraction')\n",
    "#ax1.set_title('Correlation Between Release Force and Elongation Amplitude 2')\n",
    "ax1.set_xlabel('Release Force [kN]')\n",
    "ax1.set_ylabel('Elongation Amplitude 2 [$\\mu$m] (mean for all Sensors)')\n",
    "ax1.legend(title='Treatment', loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "PLOT_MANAGER.save_plot(fig3, filename=f\"ls3_release_force_vs_ptq_m_amplitude_2\", subdir=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Durchführung des ANOVA-Tests und Berechnung der Effektstärke (Eta Squared)\n",
    "def perform_anova_and_effect_size(df: pd.DataFrame, variable: str, treatments: List[str]) -> str:\n",
    "    groups = [df[df['treatment'] == treatment][variable].dropna() for treatment in treatments]\n",
    "    f_stat, p_value = f_oneway(*groups)\n",
    "\n",
    "    # Berechnung der Effektstärke (Eta Squared)\n",
    "    n = sum([len(g) for g in groups])\n",
    "    ss_total = sum([(x - df[variable].mean()) ** 2 for g in groups for x in g])\n",
    "    eta_squared = f_stat * len(groups) / (f_stat * len(groups) + (n - len(groups)))\n",
    "\n",
    "    # Überprüfung der Signifikanz\n",
    "    significance = \"*\" if p_value < 0.05 else \"\"\n",
    "\n",
    "    return f\"{variable}: {significance}\\nF-statistic = {f_stat:.2f}\\np-value = {p_value:.2e}\\nEta Squared = {eta_squared:.2f}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.023760Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung von Boxplots\n",
    "def create_boxplot(df: pd.DataFrame, variable: str, group_by: str, ax: plt.Axes, color_dict: Dict[str, str], perform_stats: bool) -> None:\n",
    "    valid_df = df.dropna(subset=[variable])\n",
    "    sns.boxplot(x=group_by, y=variable, hue=group_by, data=valid_df, ax=ax, palette=color_dict, dodge=False)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.axis('off')\n",
    "    if perform_stats:\n",
    "        stats_text = perform_anova_and_effect_size(valid_df, variable, valid_df[group_by].unique())\n",
    "        ax2.annotate(stats_text, xy=(1.01, 0.1), xycoords='axes fraction')\n",
    "    ax.set_title(f'Einfluss von {group_by} auf {variable}')\n",
    "    ax.set_xlabel(group_by)\n",
    "    ax.set_ylabel(variable)\n",
    "\n",
    "# Funktion zur Erstellung kombinierter Plots\n",
    "def create_combined_plot(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], num_columns: int = 3, perform_stats: bool = False) -> None:\n",
    "    num_rows = len(columns) // num_columns + (len(columns) % num_columns > 0)\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(16, 4 * num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, variable in enumerate(columns):\n",
    "        create_boxplot(df, variable, group_by, axes[idx], color_dict, perform_stats)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    PLOT_MANAGER.save_plot(fig, filename=f\"combined_plot_{group_by}\", subdir=\"combined\")\n",
    "\n",
    "# Funktion zur Erstellung einzelner Plots\n",
    "def create_individual_plots(df: pd.DataFrame, columns: List[str], group_by: str, color_dict: Dict[str, str], perform_stats: bool = False) -> None:\n",
    "    for variable in columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        create_boxplot(df, variable, group_by, ax, color_dict, perform_stats)\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        PLOT_MANAGER.save_plot(fig, filename=f\"{group_by}_{variable}\", subdir=\"individual_plots\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.023760Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.023760Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['ptq_m_amplitude',\n",
    "           'ptq_m_amplitude_2',\n",
    "           'ptq_initial_amplitude',\n",
    "           'ptq_damping_coeff',\n",
    "           'ptq_angular_frequency',\n",
    "           'ptq_y_shift',\n",
    "           'ptq_pearson_r',\n",
    "           #'ptq_nrmse',\n",
    "           #'ptq_nmae',\n",
    "           #'release_force_target',\n",
    "           'ls3_rope_release',\n",
    "           'ls3_cable_max'\n",
    "           ]\n",
    "\n",
    "# Beispiel: Erstellen von Plots gruppiert nach 'treatment'\n",
    "create_combined_plot(df, columns, 'treatment', treatment_color_dict, perform_stats=True)\n",
    "create_individual_plots(df, columns, 'treatment', treatment_color_dict, perform_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-25T19:41:42.023760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Beispiel: Erstellen von Plots gruppiert nach 'ptq_sensor_name'\n",
    "columns = ['ptq_m_amplitude', 'ptq_m_amplitude_2', 'ptq_initial_amplitude', 'ptq_damping_coeff', 'ptq_angular_frequency', 'ptq_pearson_r']\n",
    "\n",
    "create_combined_plot(df, columns, 'ptq_sensor_name', sensor_color_dict)\n",
    "create_individual_plots(df, columns, 'ptq_sensor_name', sensor_color_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
